<?xml version="1.0" encoding="UTF-8"?>
<schedule>
  <conference>
    <title>FOSDEM 2015</title>
    <subtitle/>
    <venue>ULB (Université Libre de Bruxelles)</venue>
    <city>Brussels</city>
    <start>2015-01-31</start>
    <end>2015-02-01</end>
    <days>2</days>
    <day_change>09:00:00</day_change>
    <timeslot_duration>00:05:00</timeslot_duration>
  </conference>
  <day index="1" date="2015-01-31">
    <room name="Janson">
      <event id="2632">
        <start>09:30</start>
        <duration>00:25</duration>
        <room>Janson</room>
        <slug>keynotes_welcome</slug>
        <title>Welcome to FOSDEM 2015</title>
        <subtitle/>
        <track>Keynotes</track>
        <type>keynote</type>
        <language/>
        <abstract>&lt;p&gt;FOSDEM welcome and opening talk.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Welcome to FOSDEM 2015!&lt;/p&gt;</description>
        <persons>
          <person id="6">FOSDEM Staff</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2605">
        <start>10:00</start>
        <duration>00:50</duration>
        <room>Janson</room>
        <slug>identity_crisis</slug>
        <title>Identity Crisis: Are we who we say we are? </title>
        <subtitle/>
        <track>Keynotes</track>
        <type>keynote</type>
        <language/>
        <abstract>&lt;p&gt;Karen Sandler, Executive Director of the Software Freedom Conservancy, will discuss the peculiar tension in the intersection of free and open source software and corporate interest. Working in free software often triggers a complicated set of allegiances. When tricky situations arise how do developers decide what their priorities are? As a community how do you know whether a contributor is advocated the best for the project of the best for their employer? How much can governance help? And at the end of the day, how do the ideological components to these projects really play out? And how should they?&lt;/p&gt;</abstract>
        <description>&lt;p&gt;This is a very confusing area in free and open source software communities.  I will use specific examples from a few different free software communities to illustrate the current state of ambiguity. This presentation will shed light on the situation and propose proactive solutions.&lt;/p&gt;</description>
        <persons>
          <person id="448">Karen Sandler</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2629">
        <start>11:00</start>
        <duration>00:50</duration>
        <room>Janson</room>
        <slug>what_is_wrong_with_operating_systems</slug>
        <title>What is wrong with Operating Systems</title>
        <subtitle>(and how do we make things better)</subtitle>
        <track>Keynotes</track>
        <type>keynote</type>
        <language/>
        <abstract>&lt;p&gt;The talk will be a thought-provoking exploration of operating systems and the software/hardware stack.  It will be a high-flying tale of low-level gore, and is intended for everyone with an understanding of programming and/or software systems.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The focus of the talk is in core operating system architecture.  While that is sometimes seen as a highly technical topic, the talk will put the subject into common terms to disband the illusion of magic, and to give the audience an idea of what the purpose of the OS is in 2015 and why they should care beyond just having one installed.&lt;/p&gt;

&lt;p&gt;Some of the subjects that the talk will graze upon include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;the need for an operating system (or lack thereof)&lt;/li&gt;
&lt;li&gt;historical perspective and what has actually changed since time immemorial&lt;/li&gt;
&lt;li&gt;hardware/software interface&lt;/li&gt;
&lt;li&gt;userspace is the new kernelspace (or is it?)&lt;/li&gt;
&lt;li&gt;why actually good ideas fail&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Every discussed subject will not be backed by experimental evidence, nor does the presenter claim that all insights are original.  The intent is to raise awareness of good ideas so that they can be implemented more widely, and to raise awareness of bad ideas so that they can be unimplemented more widely.&lt;/p&gt;</description>
        <persons>
          <person id="1033">Antti Kantee</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2583">
        <start>12:00</start>
        <duration>00:50</duration>
        <room>Janson</room>
        <slug>automating_attribution</slug>
        <title>Automating Attribution</title>
        <subtitle>Giving credit where credit is due</subtitle>
        <track>Miscellaneous</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;From blame logs to authors signing their names on their paintings; everyone appreciates and deserves credit for what they do. This has been codified in open licenses such as those from Creative Commons which put attribution as one of the requirements for re-use. Over the last two years, a number of libraries and tools have been developed to make attribution easier and seamless, and this talk demonstrates how they all fit together, how you can use them in your programs, and how a browser plugin can help you both find and attribute openly licensed works.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Commons Machinery is an initiative supported by the Shuttleworth Foundation to give some much needed attention to metadata support for creative works. First and foremost, the project has worked with images and metadata standards for images. The software developed include a catalog of openly licensed creative works, a browser plugin interacting with that catalog, and several libraries to support the managing of metadata for creative works. In total, this talk will skim across the following technologies and tools:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The Catalog - a free software backend for metadata storage, currently in production and seeded with metadata information about all openly licensed works from Wikimedia Commons, as well as other collections. The catalog API supports querying for images by URL or by a perceptual hash that will help you find images even if they've been resized.&lt;/li&gt;
&lt;li&gt;Blockhash - a JavaScript, Python and C library and utility to calculate basic perceptual hashes of images, with particular emphasis on verbatim reuse scenarios. This means that images that have been rescaled (sometimes heavily) or changed format, should result in identical or near-identical hashes, whereas images that have been modified to create derivative works should result in more different hashes.&lt;/li&gt;
&lt;li&gt;Elog.io - a Firefox and Chromium plugin that can query the Catalog for information about images to determine if they're openly licensed or not, and show you which images on a web page are openly licensed, as well as give you source links and a way to automatically attribute those images when you re-use them.&lt;/li&gt;
&lt;li&gt;hmsearch - A C++ implementation (with Node and Python interface) of hamming distance algorithm HmSearch using Kyoto Cabinet, used in the Catalog to search for hashes which are nearly identical.&lt;/li&gt;
&lt;li&gt;libgetmetadata - a library to retrieve metadata about images based on their URL&lt;/li&gt;
&lt;li&gt;libcredit - formats appropriate credit statements from an RDF graph with metadata&lt;/li&gt;
&lt;/ul&gt;
</description>
        <persons>
          <person id="1550">Jonas Öberg</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2490">
        <start>13:00</start>
        <duration>00:50</duration>
        <room>Janson</room>
        <slug>a_new_version_of_firefox_is_available</slug>
        <title>A new version of Firefox is available</title>
        <subtitle>Releasing Quality Firefox Products</subtitle>
        <track>Miscellaneous</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;Mozilla Firefox is a Web Browser. The red panda just turned 10.
For the last 4 years, we have been releasing a major release every 6 weeks. During this talk, we will explain how we have been able to reach this goal.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Releasing software is hard. Doing it every 6 weeks is harder, especially in an environment like a Web browser in which there are constant evolutions and changes.
We will explain how we have been able to reach a high quality level on a software complex as an operating system while keeping frozen deadlines.
We will present our workflow, our tools and our organization to reach these goals.&lt;/p&gt;</description>
        <persons>
          <person id="720">Sylvestre Ledru</person>
          <person id="2482">Lukas Blakk</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2557">
        <start>14:00</start>
        <duration>00:50</duration>
        <room>Janson</room>
        <slug>building_high_performance_language_implementations</slug>
        <title>Building High-Performance Language Implementations With Low Effort</title>
        <subtitle/>
        <track>Performance</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;This talk shows how languages can be implemented as self-optimizing interpreters, and how Truffle or RPython go about to just-in-time compile these interpreters to efficient native code.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Programming languages are never perfect, so people start building
domain-specific languages to be able to solve their problems more easily.
However, custom languages are often slow, or take enormous amounts of effort to
be made fast by building custom compilers or virtual machines.&lt;/p&gt;

&lt;p&gt;With the notion of self-optimizing interpreters, researchers proposed a way to
implement languages easily and generate a JIT compiler from a simple
interpreter. We explore the idea and experiment with it on top of RPython (of
PyPy fame) with its meta-tracing JIT compiler, as well as Truffle, the JVM
framework of Oracle Labs for self-optimizing interpreters.&lt;/p&gt;

&lt;p&gt;In this talk, we show how a simple interpreter can reach the same order of
magnitude of performance as the highly optimizing JVM for Java. We discuss the
implementation on top of RPython as well as on top of Java with Truffle so that
you can start right away, independent of whether you prefer the Python or JVM
ecosystem.&lt;/p&gt;

&lt;p&gt;While our own experiments focus on SOM, a little Smalltalk variant to keep
things simple, other people have used this approach to improve peek performance
of JRuby, or build languages such as JavaScript, R, and Python 3.&lt;/p&gt;</description>
        <persons>
          <person id="2295">Stefan Marr</person>
        </persons>
        <links>
          <link href="http://som-st.github.io/">SOM Smalltalk homepage</link>
          <link href="http://lafo.ssw.uni-linz.ac.at/papers/2012_DLS_SelfOptimizingASTInterpreters.pdf">Paper on self-optimzing interpreters</link>
          <link href="http://lafo.ssw.uni-linz.ac.at/papers/2013_Onward_OneVMToRuleThemAll.pdf">One VM to Rule Them All, a paper on using partial evaluation to compile self-optimizing interpreters</link>
          <link href="http://stefan-marr.de/papers/ieee-soft-marr-et-al-are-we-there-yet/">Are We There Yet? A Paper on first experiments with RPython and Truffle</link>
        </links>
      </event>
      <event id="2542">
        <start>15:00</start>
        <duration>00:50</duration>
        <room>Janson</room>
        <slug>igprof_the_ignominous_profiler</slug>
        <title>IgProf</title>
        <subtitle>The Ignominous Profiler</subtitle>
        <track>Performance</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;IgProf is a GPL, general purpose, cross platform (x86_64, x86, ARMv7-A, ARM64/AArch64), memory and performance profiling tool originally developed 10 years ago in the context of LHC experiments at CERN (*), to enable optimisation of simulation and data acquisition software. It provides detailed, call-stack level, information on where time / energy is spent and memory allocations happen using a variety of techniques varying from dynamic instrumentation to sampled profiling. While not dissimilar from other similar softwares like Google perftools it was specially tailored to profile extremely large C++ applications comprising millions lines of codes, loading thousands of dynamic libraries and with a very high memory allocation frequency. In addition, ease-of-use and the ability to easily share performance profiles between distributed collaborators are important aspects to enable use by a large community of scientists with varying software development skills.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;We present our experience about profiling and improving performance  of large applications, discuss similarities and differences with other similar tools and show a few of the new features we have been working on lately, in particular ARM64 support and energy profiling via a PAPI add on. We also show how we gave back to the opensource  community by providing patches to libunwind for both x86 and ARM.&lt;/p&gt;

&lt;p&gt;(*) CMS is one of the flagship experiments at CERN, a collaboration of  over 4000 researchers distributed in more than 100 institutes around the world. They use a distributed computing architecture consisting of more than 100K x86-64 cores to answer questions about the origin of the universe and the structure of matter. Given the scale of the computational resources, software performance optimization is a critical need.&lt;/p&gt;</description>
        <persons>
          <person id="2279">Giulio Eulisse</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2622">
        <start>16:00</start>
        <duration>00:50</duration>
        <room>Janson</room>
        <slug>superoptimization</slug>
        <title>Superoptimization</title>
        <subtitle>How fast can your code go?</subtitle>
        <track>Performance</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;Modern compiler optimization can take almost any code and produce a reasonably efficient binary at the end. However compiler "optimization" doesn't make your code "optimal", just better.&lt;/p&gt;

&lt;p&gt;In contrast, superoptimization can produce perfect code - the fastest, the smallest or the most energy efficient code. The technique, first introduced in the late 80s found in some cases it could do 25% better than the best assembly programmer, and 40% better than the best compiler at the time.&lt;/p&gt;

&lt;p&gt;Free software has always played a central role in superoptimization research, with the GNU Superoptimizer being one of the very first tools constructed.&lt;/p&gt;

&lt;p&gt;However there is a downside. Superoptimization today is incredibly demanding of compute time, so currently it is limited to short instruction sequences. At present it is most valuable in optimizing code hotspots and key library routines, and can also be a valuable aid to the compiler writer for peephole optimization. Recent research has developed new techniques that can make superoptimization more applicable to general code.&lt;/p&gt;

&lt;p&gt;In this talk I will introduce superoptimization and give some examples of the weird and wonderfully short sequences of code it produces. I will introduce the GNU superoptimizer and show how it is used, including some of the recent improvements I have contributed. The final part of my talk will look at the latest research including machine learning and constraint solving, and show how in future superoptimizers may be able to optimize much larger programs.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1836">James Pallister</person>
        </persons>
        <links>
          <link href="http://www.superoptimization.org">http://www.superoptimization.org</link>
        </links>
      </event>
      <event id="2598">
        <start>17:00</start>
        <duration>00:50</duration>
        <room>Janson</room>
        <slug>ubiquitous_performance_analysis_and_system_introspection</slug>
        <title>Ubiquitous Performance Analysis and System Introspection</title>
        <subtitle>An introduction to Performance Co-Pilot and Systemtap</subtitle>
        <track>Performance</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;Performance Co-Pilot is a highly adaptable and established toolkit for those
interested in examining the details of system performance.  Similarly,
Systemtap is a powerful tool for digging deep into the innards of a program.
This presentation will go over the basics of the tools, recent developments,
and examples.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Performance Co-Pilot is a highly adaptable and established toolkit for those
interested in examining the details of system performance.  When used in tandem
with Systemtap, an introspection tool, both developers and system administrators
are able to progress from a high level view of the current performance, to detailed
information about a specific subsystem or program. This presentation will go
over the basics of the tools, recent developments, and examples.&lt;/p&gt;</description>
        <persons>
          <person id="2304">Lukas Berk</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="K.1.105 (La Fontaine)">
      <event id="2513">
        <start>12:00</start>
        <duration>00:50</duration>
        <room>K.1.105 (La Fontaine)</room>
        <slug>gps_watch</slug>
        <title>A GPS watch made of free software and hardware</title>
        <subtitle/>
        <track>Hardware</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;F*watch is an infinitely hackable GPS watch with many sensors
based on a 100% Free design. Everything is Free, from the PCB and watch
housing design to the software stack. Moreover, only Free software tools
have been used during the development.&lt;/p&gt;

&lt;p&gt;F*watch. Why should your watch be different?&lt;/p&gt;

&lt;p&gt;The talk describes the development process and shows a first
prototype, along with performance measurements and future plans.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2267">Federico Vaga</person>
          <person id="2961">Matthieu Cattin</person>
        </persons>
        <links>
          <link href="http://www.ohwr.org/projects/f-watch/wiki">F*Watch wiki</link>
        </links>
      </event>
      <event id="2927">
        <start>13:00</start>
        <duration>00:50</duration>
        <room>K.1.105 (La Fontaine)</room>
        <slug>lowrisc</slug>
        <title>lowRISC</title>
        <subtitle>The path to an open-source SoC</subtitle>
        <track>Hardware</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;The &lt;a href="http://www.lowrisc.org"&gt;lowRISC&lt;/a&gt; project was established in the summer of 2014 with the aim of producing a complete open-source System-on-Chip in volume, with low-cost development boards. Alex Bradbury, one of the co-founders of the project will discuss the progress to date and the path to the first test chip. lowRISC implements the open RISC-V instruction set architecture and is exploring ideas on improving security via tagged memory and increasing flexibility through the addition of RISC-V 'Minion' cores to implement soft peripherals. This talk will discuss the potential benefits of a fully open-source hardware ecosystem, the challenges of getting to first silicon, and how the open source community at large can help.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;There has been an explosion in interest in low-cost hardware platforms in recent years with many (e.g. Arduino and BeagleBone Black) having their schematics and PCB layout released under an open hardware license. These platforms are supported by open-source toolchains, applications, and libraries yet the processor this software targets remains closed. We believe there is an opportunity for open source processor and SoC designs to influence industry in a way similar to the successes we've seen in open source software - to help increase the pace of change of development, more easily move ideas from research to real world usage, and to lower the barrier of entry to the market.&lt;/p&gt;

&lt;p&gt;Two features we are focusing on for our first test chip are &lt;a href="http://www.lowrisc.org/docs/memo-2014-001-tagged-memory-and-minion-cores/"&gt;tagged memory and 'minion' cores&lt;/a&gt;. Tagged memory has applications in security, to prevent control-flow hijacking attacks or for debug or performance monitoring. The 'minions' we propose are small cores which also implement the RISC-V instruction set, used for implementation of I/O protocols in software, secure isolated execution, or many other potential uses. This talk will describe the current status of the project, our planned path to production silicon, and how the wider open source community can get involved.&lt;/p&gt;</description>
        <persons>
          <person id="2629">Alex Bradbury</person>
        </persons>
        <links>
          <link href="http://www.lowrisc.org">lowRISC homepage</link>
          <link href="http://www.lowrisc.org/docs/memo-2014-001-tagged-memory-and-minion-cores/">lowRISC memo: tagged memory and minion cores</link>
        </links>
      </event>
      <event id="3455">
        <start>14:00</start>
        <duration>00:50</duration>
        <room>K.1.105 (La Fontaine)</room>
        <slug>beri</slug>
        <title>BERI</title>
        <subtitle>An open RISC softcore for research and experimentation</subtitle>
        <track>Hardware</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;BERI (the Bluespec Extensible RISC Implementation) is a softcore processor jointly developed by SRI International and The University of Cambridge.  It implements a superset of the MIPS III ISA in Bluespec, a high-level HDL and supports a fully open source, permissively licensed, software stack comprising the FreeBSD operating system and the LLVM compiler suite.  This talk will describe the design of the BERI processor and its use.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;BERI was created to facilitate experimentation at the boundaries between CPU architecture, operating systems, and programming languages.  It runs in Altera and Xilinx FPGAs, including the NetFPGA 10G board.  At 100MHz, it is fast enough to use as a real computer (albeit a fairly slow one).  This allows&lt;/p&gt;

&lt;p&gt;There is a close tie between the history of UNIX-like systems and academic use.  The original AT&amp;amp;T UNIX was distributed cheaply to universities and so formed the basis of both research projects and operating systems courses for a long time.  MINIX, originally free for non-commercial use and now BSD licensed, was written primarily as a platform for teaching and research use and the ties between BSD and UCB speak for themselves.  The open source community has benefitted enormously from people passing through university for almost three decades and studying UNIX and related systems.&lt;/p&gt;

&lt;p&gt;Compiler development has seen a similar renaissance in recent years, primarily spurred by LLVM, which provides a set of libraries that are easy to use and to modify for building compilers for new languages and new platforms.&lt;/p&gt;

&lt;p&gt;The one missing part of the puzzle, so far, has been the hardware.  Although we have a plethora of commodity CPUs and even a number of open source designs, these have not typically well integrated into an open source stack.&lt;/p&gt;

&lt;p&gt;This talk will discuss the BERI softcore, jointly developed by The University of Cambridge and SRI International and the associated open source software stack.  BERI, the Bluespec Extensible RISC Implementation, is a 64-bit MIPS implementation in Bluespec, a high-level hardware description language.  It implements the instruction set that debuted in the MIPS R4000 core in 1991, and therefore a set that is free of patents owing to its age.  In spite of this, it is a relatively modern 64-bit architecture and is well supported by open source systems.  The FreeBSD port to BERI required minimal changes, which were shipped as part of the FreeBSD 10.0 release, and runs unmodified userland 64-bit MIPS code.  BERI can run in simulation at a speed acceptable for testing but not for general usage or in an FPGA at 100MHz.  The BERI design supports multiple cores on a single FPGA and work is ongoing to support multicore across boards connected with a low-latency interconnect.&lt;/p&gt;

&lt;p&gt;On top of this runs FreeBSD, a permissively licensed UNIX variant, and the LLVM compiler suite.  This provides a solid platform for experimental use, as users can modify any aspect of the system, from the instruction set upwards.  It is relatively simple, for example, to add a new set of instructions as a coprocessor to BERI, add code to the operating system so that the state is preserved across context switches, and add code generation support in LLVM.&lt;/p&gt;

&lt;p&gt;BERI provides a generic coprocessor interface, which makes it very easy to extend the functionality.  CHERI, Capability Hardware Enhanced RISC Instructions, is a BERI-based CPU that adds a coprocessor providing a capability-oriented memory model.  This demonstrates the extensibility of the BERI stack: the CPU, operating system, and compiler have all been modified to provide support for new functionality.&lt;/p&gt;</description>
        <persons>
          <person id="2936">Jonathan Woodruff</person>
        </persons>
        <links>
          <link href="http://bericpu.org">BERI web site</link>
        </links>
      </event>
      <event id="3412">
        <start>15:00</start>
        <duration>00:50</duration>
        <room>K.1.105 (La Fontaine)</room>
        <slug>freecad</slug>
        <title>FreeCAD</title>
        <subtitle>a hackable design platform</subtitle>
        <track>Hardware</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;FreeCAD is a general purpose, open-source, multiplatform parametric 3D modeling application, geared mainly for product design, in other words anything that is meant to be built in the real world. The project started around 2002, and is today entering a a big momentum with the blossoming of home 3D printing and manufacturing, and thanks to is extreme hackability.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;FreeCAD can be described as a big, modular "collage" between many heavyweight open-source libraries and projects, such as OpenCasCade (our geometry engine), Coin3D (an implementation of OpenInventor, which drives the 3D display), Qt and Python. But it can also, more accurately, be called a "python beast". With a bit of knowledge of the python language, its user is given the powers of a God.&lt;/p&gt;

&lt;p&gt;Although programmed mainly in C++, python is everywhere in FreeCAD: It acts as a "glue" between the "core" part of the application, which handles all the heavy geometric calculations, and the Qt graphical interface. This offers a wealth of interesting features such as the separation of FreeCAD into a non-GUI (server mode) part and a GUI part, possibilities to record, tweak, drive, or interact with the python flow in many ways, and much more. Each of the main libraries used in FreeCAD also has its own python bindings, all usable inside FreeCAD, all connecting to the running application and able to operate on its contents, its objects, its interface, its 3D display.&lt;/p&gt;

&lt;p&gt;Python code in FreeCAD is also constantly exposed to the user, turning the application very pedagogic. It is almost impossible to work with it without learning at least a bit of python. Many have tried.&lt;/p&gt;

&lt;p&gt;This has formed a highly technically knowledgeable community around FreeCAD, where the differences between developer and user have blurred.&lt;/p&gt;

&lt;p&gt;This talk will try to convey some of the amazing social/technical experience we have building this tool that is made to build.&lt;/p&gt;</description>
        <persons>
          <person id="2906">Yorik van Havre</person>
        </persons>
        <links>
          <link href="http://www.freecadweb.org">The FreeCAD project's homepage</link>
        </links>
      </event>
      <event id="3450">
        <start>16:00</start>
        <duration>00:50</duration>
        <room>K.1.105 (La Fontaine)</room>
        <slug>stretching_out_for_trustworthy_reproducible_builds</slug>
        <title>Stretching out for trustworthy reproducible builds</title>
        <subtitle>The status of reproducing byte-for-byte identical binary packages from a given source</subtitle>
        <track>Miscellaneous</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;With free software, anyone can inspect the source code for malicious flaws. But Debian provide
binary packages to its users. The idea of “deterministic” or “reproducible” builds is to empower anyone to
verify that no flaws have been introduced during the build process by reproducing byte-for-byte identical
binary packages from a given source.&lt;/p&gt;

&lt;p&gt;This talk will explain the current status of the Debian Reproducible Builds project, how this is relevant for the complete free software eco system and how you can contribute.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;With free software, anyone can inspect the source code for malicious flaws. But Debian provide
binary packages to its users. The idea of “deterministic” or “reproducible” builds is to empower anyone to
verify that no flaws have been introduced during the build process by reproducing byte-for-byte identical
binary packages from a given source.&lt;/p&gt;

&lt;p&gt;This talk will explain the current status of the Debian Reproducible Builds project,
how this is relevant for the complete free software eco system and how you can contribute.&lt;/p&gt;

&lt;p&gt;see https://wiki.debian.org/ReproducibleBuilds and https://reproducible.debian.net&lt;/p&gt;</description>
        <persons>
          <person id="70">Holger Levsen</person>
        </persons>
        <links>
          <link href="https://wiki.debian.org/ReproducibleBuilds">about Reproducible Builds of Debian</link>
          <link href="https://reproducible.debian.net">shiny graphs about the current state</link>
        </links>
      </event>
    </room>
    <room name="H.2215 (Ferrer)">
      <event id="3407">
        <start>12:55</start>
        <duration>00:05</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>lightning_talks_welcome</slug>
        <title>Lightning Talks Welcome</title>
        <subtitle/>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;Welcome and Introduction to the FOSDEM 2015 Lightning Talks.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="16">Tias Guns</person>
          <person id="466">Alasdair Kergon</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2860">
        <start>13:00</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>developing_fosdem_companion</slug>
        <title>Developing FOSDEM Companion</title>
        <subtitle>How to build a nice, modern schedule app for Android</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;FOSDEM Companion is a mobile schedule app for Android, first released for FOSDEM 2014. Its code is open source and designed as a reference implementation for this kind of application. This track will cover the architecture of the app and its building blocks, the motivation behind its features, and the best practices for designing a modern Android application.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2591">Christophe Beyls</person>
        </persons>
        <links>
          <link href="https://github.com/cbeyls/fosdem-companion-android">GitHub project page</link>
        </links>
      </event>
      <event id="2647">
        <start>13:20</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>ultra_web_server</slug>
        <title>Ultra - Smallest. Web server. Evar.</title>
        <subtitle/>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;This talk introduces a brand new web server - Ultra. With a binary at just 51K it's small, fast, and encompasses an all-in-memory web server with an in-built NoSQL datastore, a data processing language, SSI, multiple configurations, and logging. If you want to learn basic networking programming, its source is small enough for you to learn from. The talk covers the basic architecture and approach in keeping a small footprint, and breaks down the source into easily understandable blocks.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The talk covers the history and development of a unique project - one that tells a classic open source story about a developer scratching an itch, and solving a problem he didn't have! It covers the code from 47 lines of C, to 1500 of C++. It also details how the processing language was governed by code re-use, and how the data store uses convention over configuration to work efficiently. It's one of the few projects that is small enough to do serious work, but small enough to be explained line-by-line in a talk! (Although it won't be that direct!)&lt;/p&gt;</description>
        <persons>
          <person id="392">Steven Goodwin</person>
        </persons>
        <links>
          <link href="http://marquisdegeek.com/code_ultra.php">Ultra - main page</link>
        </links>
      </event>
      <event id="2785">
        <start>13:40</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>how_adblockers_work</slug>
        <title>How adblockers work</title>
        <subtitle/>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;I have worked for the past 1.5 years full-time on Adblock Plus, an open source browser extension which blocks ads. There is an increasing popularity of adblockers, but most people still don't know how an adblocker actually works. Adblock Plus is the most popular adblocker with over 50,000,000 users, and most other adblockers adopted our approach and even our filters. I would like to explain what those filters do, how they are implemented, and what the limitations are.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2529">Sebastian Noack</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2787">
        <start>14:00</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>openui5_introduction</slug>
        <title>A Whirlwind Introduction to OpenUI5</title>
        <subtitle>The Responsive, Enterprise Strength HTML5 Toolkit</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;A whirlwind introductory tour of OpenUI5, the open source, responsive, enterprise strength HTML5 toolkit from SAP.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;SAP open sourced their HTML5 toolkit that is used as the foundation for all SAP's present and planned UI endeavours. It's responsive, enterprise strength, has a ton of features including full MVC support, a powerful data binding system, declarative view mechanics, support for internationalisation, right-to-left and accessibility right out of the box. And it's great to use, too.&lt;/p&gt;

&lt;p&gt;This lightning talk will take you on a whirlwind tour of OpenUI5: no slides, just code and activity in the Chrome Developer Tools console.&lt;/p&gt;</description>
        <persons>
          <person id="2531">DJ Adams</person>
        </persons>
        <links>
          <link href="http://openui5.org/">OpenUI5 Home</link>
          <link href="https://github.com/SAP/openui5/">OpenUI5 Sources on Github</link>
        </links>
      </event>
      <event id="2710">
        <start>14:20</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>all_about_hack</slug>
        <title>All about Hack in 15 minutes</title>
        <subtitle>Why you should consider Hack over PHP</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;Hack is a new programming language from Facebook. It is the natural evolution of PHP. This talk will cover some of the problems with PHP, the benefits of a compiled and statically typed language and then introduce Hack and HHVM as a solution.
Half way into the talk I will give a crash course in Hack and explain its perks and syntactic sugar. At the end I'll give some advice on how and where to get started testing Hack.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2441">Tobias Nyholm</person>
        </persons>
        <links>
          <link href="http://hacklang.org/">Website</link>
        </links>
      </event>
      <event id="3134">
        <start>14:40</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>cockroachdb</slug>
        <title>CockroachDB</title>
        <subtitle>towards an Open-Source Spanner</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;h2&gt;CockroachDB a distributed database written in Go.&lt;/h2&gt;

&lt;p&gt;Many NoSQL databases come with a focus on performance, availability and scalability, sacrificing strong consistency guarantees along the way. In effect, this shifts the burden of providing consistency to the application, and often results in complex and error-prone application logic.
Just a few years ago, an intense effort by Google resulted in Spanner - a globally distributed, replicated datastore that puts transactions back where they belong: right into the heart of the database.&lt;/p&gt;

&lt;p&gt;CockroachDB is a grass-roots effort to bring to the table the guarantees of Spanner (and more) in an open source scalable database that is easy to deploy and, despite the name, quite attractive to have around.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2766">Tobias Schottdorf</person>
        </persons>
        <links>
          <link href="http://cockroachdb.org/">website</link>
        </links>
      </event>
      <event id="2509">
        <start>15:00</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>gcompris</slug>
        <title>GCompris goes Qt Quick with the help of KDE</title>
        <subtitle>GCompris is educational software for children 2 to 10</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;GCompris is a high quality educational software suite comprising of numerous activities for children aged 2 to 10. It was created in 2000 using the GTK+ graphical toolkit. It is available on different platforms, GNU/Linux, and the proprietary platforms MacOSX and Windows.&lt;/p&gt;

&lt;p&gt;Willing to address the large number of tablet users and to enhance the user experience the choice was made in January 2014 to rewrite GCompris in Qt Quick.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The presentation will address the following topic:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Project goal and history&lt;/li&gt;
&lt;li&gt;Community and commercial. Starting in 2003 a Windows version was created and is distributed under a commercial model while being still Free Software. We will see how and why we decided to do so&lt;/li&gt;
&lt;li&gt;Why we selected Qt Quick. This development toolkit is based on Qt and let the developer create dynamic user interface that can run on desktop and mobile platforms&lt;/li&gt;
&lt;li&gt;Why we became a KDE project. GCompris has always been a community project, leaving the GTK+ toolkit it does not make sense to develop the new version under the Gnome umbrella&lt;/li&gt;
&lt;li&gt;State of the Qt Quick port&lt;/li&gt;
&lt;/ul&gt;
</description>
        <persons>
          <person id="2261">Bruno Coudoin</person>
        </persons>
        <links>
          <link href="http://gcompris.net">GCompris main site</link>
        </links>
      </event>
      <event id="2902">
        <start>15:20</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>requirements_bazaar</slug>
        <title>Requirements Bazaar</title>
        <subtitle>How to encourage users to tell us what they really need!</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;In this Lightning Talk we want to present “Requirements Bazaar 2.0” that aims to be a social platform to bring developers and end-users together. In years of research we have developed and actually operated an Open Innovation Platform for gathering requirements for prototypes in large international academic projects. The last version of the current product is available under http://requirements-bazaar.org . End-users can enter their requirements by providing short descriptions including user stories, screenshots and other images. The requirements can then be shared amongst its users. On the other side of the chain, developers may take up ideas and transfer the accepted requirements to an issue system like JIRA.&lt;/p&gt;

&lt;p&gt;Over the last years it turned out that people want more lightweight and mobile-friendly tools; we found the old monolithic system to be very hard to maintain to add new features. Therefore we are currently redeveloping it from scratch integrating many ideas from our users and incorporating new research findings. We are further driven by a mobile-first approach to support a wide variety of devices. We additionally want to support various social features like sharing on social networks or blogs and allowing discussions and rating amongst end-users and developers.&lt;/p&gt;

&lt;p&gt;At FOSDEM we would like to encourage open source developers in rethinking the way requirements are currently gathered from the crowd. How do we want to collect new software ideas or simply feature requests from our users. Will it really be through feedback forms in our apps’ “About” menu? Do our users really think in terms of issues like we developers do? How can gamification be used to reward actual end-users of software? We hope Requirements Bazaar can answer these questions and fill the gap!&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The main backend part can be found at
https://github.com/rwth-acis/RequirementsBazaar
while the Web frontend is hosted at
https://github.com/rwth-acis/RequirementsBazaar-WebFrontend&lt;/p&gt;

&lt;p&gt;We use a Java backend based on microservices and an AngularJS/Polymer based Web frontend.&lt;/p&gt;</description>
        <persons>
          <person id="2608">István Koren</person>
        </persons>
        <links>
          <link href="https://github.com/rwth-acis/RequirementsBazaar">main backend</link>
          <link href="https://github.com/rwth-acis/RequirementsBazaar-WebFrontend">Web frontend</link>
        </links>
      </event>
      <event id="2786">
        <start>15:40</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>jitsi_videobridge</slug>
        <title>Scalable Video Conferencing with Jitsi Videobridge</title>
        <subtitle>Using Simulcast, DataChannels and adaptive streaming for Free scalable conferencing </subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;The talk will describe the problems of scalability for libre video conferencing and how they are being addressed by the new video routing architectures. It is gong to go over optimization techniques such as Last N and Simulcast. The presentation is going to then go over the Jitsi Videobridge FLOSS video router and talk about how developers can use it in their video conferencing applications.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Until recently high quality, multi-party video conferencing has been an ever elusive dream to many of us. While it has existed for tens of years already, it has always been been prohibitively expensive and a luxury that only rich corporations could afford.&lt;/p&gt;

&lt;p&gt;Readily available broadband, has opened up new horizons in the field however. The traditional video mixing servers (MCUs) are becoming irrelevant today and are being replaced by infinitely more scalable video routers, also known as Selective Forwarding Units (SFUs).&lt;/p&gt;

&lt;p&gt;Google Hangouts and the underlying Vidyo technology they used, have been one of the more popular examples in the past couple of years. Early 2014, jitsi.org also released Jitsi Videobridge, an open source video router (SFU) that is compatible with WebRTC and that allows FLOSS developers around the world to start building scalable video conferencing applications.&lt;/p&gt;

&lt;p&gt;This lecture is going to go over some of the more important concepts of scalable video conferencing, such as selective routing, simulcasting and layered video, RTCP termination and others.&lt;/p&gt;

&lt;p&gt;We are then going to look into the privacy issues related to video conferencing today, discuss the possibilities for truly confidential multi-party calls and the interesting impact, both positive and negative, that WebRTC has on the possible solutions.&lt;/p&gt;</description>
        <persons>
          <person id="1107">Emil Ivov</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2906">
        <start>16:00</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>xmpp_and_android</slug>
        <title>XMPP and Android</title>
        <subtitle>Creating stable, reliable, push-enabled and battery friendly XMPP connections on Android</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;Using XMPP on resource constraint systems, like Android devices that are surrounded by a hostile mobile environment, imposes many challenges. But with the right measures a stable, reliable, push-enabled and battery friendly connection can be achieved. This talk will present the required techniques using Smack, an open source XMPP client library written in Java. One outstanding property of Smack is that it's a multi-runtime library, i.e. it is able to run on Java SE runtimes &lt;em&gt;and&lt;/em&gt; on Android.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;XMPP on Android is challenging. But with Smack there exists an open source XMPP client library written in Java, that is able to run natively on Java SE runtime environments and on Android. Smack is a lightweight, resource friendly and highly modular library. Ideal for the deployment in low-end devices. But the mobile usage scenario of Android devices poses another obstacle towards a stable and reliable (mobile) XMPP connection. Data connectivity changes, caused for example when a GSM ↔ WiFi switch happens, and high latency, are just some effects of such a mobile environment. With XEP-198 Stream Management, XMPP provides the ideal extension to tackle those issues. Using XEP-198 Stream Management enabled connections, data connectivity changes become transparent to the application.&lt;/p&gt;

&lt;p&gt;Another obstacle imposed by Android is caused by the device entering the so called "deep sleep" mode. While incoming radio activity usually causes the device to leave the sleep, it's not guaranteed that it will not re-enter the sleep before the XMPP stanza has been fully processed. There are some forms of possible mitigations conceivable. But which are good? And which are just snake oil?&lt;/p&gt;

&lt;p&gt;I'll start with a short introduction of XMPP and Smack and explain how Smack is able to target Android and Java SE runtimes. The rest of the talk will consist of best practices using Smack on Android and how Smack can be used for stable, reliable XMPP connections and push notifications.&lt;/p&gt;</description>
        <persons>
          <person id="2617">Florian Schmaus</person>
        </persons>
        <links>
          <link href="http://www.igniterealtime.org/projects/smack/">http://www.igniterealtime.org/projects/smack/</link>
          <link href="https://github.com/flowdalic/asmack">https://github.com/flowdalic/asmack</link>
        </links>
      </event>
      <event id="2859">
        <start>16:20</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>matrix</slug>
        <title>Matrix.org - a new open standard for distributed, real-time communication</title>
        <subtitle>Solving the fragmented online communication space with an open standard </subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;Matrix is a new, pragmatic HTTP-based clean-room alternative to XMPP, SIP, IRC and other messaging/VoIP technologies. It consists of an open standard defining RESTful HTTP APIs and open source, Apache-licensed reference implementations for creating and running your own real-time communication infrastructure.&lt;/p&gt;

&lt;p&gt;Our hope is to make VoIP/IM as universal and interoperable as email, and build an open ecosystem that people can use for a multitude of purposes.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;We believe that real-time communication is fundamentally broken and fragmented on today's internet. XMPP and SIP tried to solve this, but haven't taken off as they might have done, leaving the internet dominated by closed proprietary islands of communication like WhatsApp, Facebook, Hangouts, etc.&lt;/p&gt;

&lt;p&gt;Enter Matrix: a set of pragmatic RESTful HTTP JSON APIs as an open standard, intended to be implemented on a wide range of servers, services and clients, letting developers build messaging and VoIP functionality on top of the Matrix ecosystem rather than adding yet another closed/proprietary solution.&lt;/p&gt;

&lt;p&gt;In Matrix, every user runs one or more Matrix clients, which connect through to a Matrix "homeserver" which stores all their personal chat history and user account information - much as a mail client connects through to an IMAP/SMTP server. Just like email, you can either run your own Matrix homeserver, which means you own and control your own communications and history - or you can use one hosted by someone else (e.g. matrix.org) - there is no single point of control or mandatory service provider in Matrix.  In fact, there is no single point of control over conversations in Matrix at all - conversation history is a first class citizen, with room state replicated over all participating servers, avoiding single-points of failure or control as you get in XMPP MUCs.&lt;/p&gt;

&lt;p&gt;In the end, we hope Matrix will crack the problem of a widely successful open federated platform for communication on the internet, and provide a worthy alternative to the PSTN. You should be able to use your favourite app to communicate via Matrix - and your recipients should be able to reply through the app of their choice!&lt;/p&gt;</description>
        <persons>
          <person id="2333">Oddvar Lovaas</person>
          <person id="2951">Matthew Hodgson</person>
        </persons>
        <links>
          <link href="http://matrix.org">Matrix.org</link>
        </links>
      </event>
      <event id="2912">
        <start>16:40</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>yatta</slug>
        <title>Yatta: A Real-Time Framework for Peer-to-peer Group Editing on Arbitrary Data Types</title>
        <subtitle>Enabling real-time collaboration on the Web</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;Yatta is an open source framework that can be used to collaborate in real-time on arbitrary data types. It is based on a new operational transformation-like approach that can be used in peer-to-peer settings on the Web, using standard communication protocols such as WebRTC or XMPP. Part of the shared editing projects family (e.g. ShareJs, OpenCoweb, etc.), Yatta currently implements support for text, XML and JSON and proved to be very fast and reliable.
In this lightning talk we introduce the concepts and features of the Yatta framework and discuss how it can be leveraged to design the next generation of peer-to-peer shared editing tools. We conclude the talk with a short demo that highlights the capabilities of the framework.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Yatta solves many of the current issues for concurrency control and consistency maintenance approaches in collaborative software. In order to achieve this, we created a new approach for optimistic concurrency control, which was formally proven to be reliable and to output the best time complexity (compared to existing dedicated related literature). The approach was designed to support real-time shared editing on linear, tree and graph data structures. A short part of this lightning talk aims to present the core concepts of our approach.&lt;/p&gt;

&lt;p&gt;Designed to work on both peer-to-peer and client-server architectures, Yatta can be easily embedded in Web applications in order to foster collaboration. Developed in Javascript, the framework outputs very good scaling capabilities in the number of users and operations in test environments. Yatta currently supports text, JSON and XML data types and was tested using WebRTC and XMPP as an underlying communication protocol.&lt;/p&gt;

&lt;p&gt;In this lightning talk, the Yatta framework will be presented to the wider OS community for the first time. We consider our framework to be developer friendly, but given the opportunity of a lightning talk, we would like to invite FOSDEM developers to use Yatta and share with us their experience. Ideally we aim to establish connections and potential collaborations, in order to improve our open source project.&lt;/p&gt;</description>
        <persons>
          <person id="2623">Petru Nicolaescu</person>
          <person id="2971">Kevin Jahns</person>
        </persons>
        <links>
          <link href="https://github.com/rwth-acis/Yatta">Yatta Framework</link>
        </links>
      </event>
      <event id="2784">
        <start>17:00</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>open_source_voip_phone</slug>
        <title>Building an Open Source VoIP hardware phone</title>
        <subtitle/>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;Introduction to OP^2 Project, which provides a framework for implementing SIP hardware phones.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Project OP^2 started as a self-learning experience to see if the features present in SIP desktop clients could be brought to a hardware device. Traditional VoIP hardware phones are very closed systems, and Project OP^2 was designed with openness and flexibility in mind. The first prototypes were built using a RaspberryPi as the hardware platform.&lt;/p&gt;</description>
        <persons>
          <person id="186">Saúl Ibarra Corretgé</person>
        </persons>
        <links>
          <link href="http://op2-project.github.io/">Project website</link>
          <link href="https://github.com/op2-project/op2-daemon">Repository</link>
        </links>
      </event>
      <event id="2673">
        <start>17:20</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>codebender</slug>
        <title>codebender: Arduino programing, online</title>
        <subtitle>Learn how to program an Arduino faster and easier, online, using codebender</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;Arduino is the favorite programming platform for embedded hardware, especially for beginners, but also for more advanced users who take advantage of its ease of use. We will show how to program more effectively, easily, and in collaboration with others. By using codebender, you can code, compile, and test Arduino code online, take advantage of the ~500 included libraries, and use code available by the community.&lt;/p&gt;

&lt;p&gt;We will show how someone can use Arduino with the power of codebender.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="552">Vasileios Georgitzikis</person>
        </persons>
        <links>
          <link href="https://codebender.cc">codebender website</link>
        </links>
      </event>
      <event id="2826">
        <start>17:40</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>rizzly</slug>
        <title>Rizzly: Event Driven Microcontroller Programming</title>
        <subtitle>A new programming language for event driven programming of 8 bit microcontroller.</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;I present Rizzly, a programming language and compiler I am working on. It is designed for the event driven programming of the smallest 8 bit micro controllers.&lt;/p&gt;

&lt;p&gt;In this talk I first present the concepts and some interesting details of Rizzly.
Although one can already use Rizzly, there are several open tasks. In the second part I will address those and present ideas how to solve those.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2562">Urs Fässler</person>
        </persons>
        <links>
          <link href="http://www.bitzgi.ch/projects/rizzly/index.html">Description of Rizzly</link>
          <link href="https://gitorious.org/rizzly">Source of Rizzly</link>
          <link href="http://www.linuxday.at/ereignisorientierte-mikrocontroller-programmierung-mit-rizzly">Presentation of Rizzly at LinuxDay (German)</link>
        </links>
      </event>
      <event id="2805">
        <start>18:00</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>crazyfile_nano_quadcopter</slug>
        <title>Crazyflie Nano Quadcopter</title>
        <subtitle>A flying open source PCB</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;In 2009 three Swedish engineers invented a small quadcopter that started with a simple idea: get an electronic board (PCB) to fly.
They created the "Crazyflie Nano Quadcopter" which weighs only 19g and fits in the palm of your hand. It can be controlled from various devices, including PC, Android or iOS devices, Raspberry Pi or a R/C remote.
While the main client has been written in Python, it has also been ported to Java, C, JavaScript.
Since the beginning of 2013 the hardware can be bought from http://www.seeedstudio.com, but the schematics for the PCB and the firmware/host source code are also available on their website/Github account.
Due to the low cost for the hardware and the open source approach, the Crazyflie has been used in different private and academic science and research projects around the world.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2543">Frederic Gurr</person>
        </persons>
        <links>
          <link href="http://www.bitcraze.se/crazyflie/">Crazyflie website</link>
          <link href="https://github.com/bitcraze">Crazyflie Github repository</link>
          <link href="http://wiki.bitcraze.se/index">Crazyflie Wiki</link>
        </links>
      </event>
      <event id="2882">
        <start>18:20</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>llvmlinux</slug>
        <title>LLVMLinux</title>
        <subtitle>The advantages of using clang for the kernel</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;Being able to build the kernel with clang opens up the possibility of using a range of llvm related tools with the kernel code. This talk will introduce a number of the possibilities.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2603">Behan Webster</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2879">
        <start>18:40</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>dtrace</slug>
        <title>Pretty-printing kernel data structures</title>
        <subtitle>Reusing D-Trace technology in unexpected places</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;Compact C Type Format (CTF) is a technology created during development of the
D-Trace software to describe the C data types. With its second version it
evolved into a fully expressive, yet space-wise efficient format that can be
used outside of the D-Trace suite too. Compiling the FreeBSD kernel with the
CDDL/CTF option triggers the creation of such CTF data that corresponds to the
respective kernel objects. This dataset can be parsed and processed to become a
source of information needed to pretty print all kernel data structures inside
the on-line kernel debugger DDB.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;In order to use the CTF technology a new implementation of the format had to be
developed - truly multiplatform, freely licensed and supporting different
endians. The project had to tackle many difficult problems such as transport of
the CTF data to the kernel debugger, which itself is a very limited space.
Pretty-printing recursive data structures can be very tricky, as they are
implemented as nested struct pointers and the interpretation can lead into
unmanageable indentation issues. The solution is to detect certain common types
of data structures - lists, queues and trees - and adapt to such structures on
a higher level of abstraction.&lt;/p&gt;

&lt;p&gt;Apart from the DDB application, CTF data can be used inside user-space
debuggers too. As a result of the slim binary design of the format storage,
each binary in the whole system, even a production one, can contain the CTF
data. To achieve even further minimisation of the space used, a concept of
multilevel parent-child relationships was introduced, in which the parent
contains the types used in both parent and child and its own, whereas the child
has only its unique ones and references the parent set.&lt;/p&gt;

&lt;p&gt;This talk is interesting outside of the BSD community too: since the libctf
implementation is multiplatform and supports the Debian and OpenIndiana
distributions, such pretty-printing functionality could be ported. The CTF
toolset - ctfconvert, ctfmerge and ctfdump - is multiplatform as well.  Thanks
to the free BSD license, the inclusion of such library should not pose a legal
problem. Some parts of the project are still work in progress and therefore the
community support is much appreciated.&lt;/p&gt;</description>
        <persons>
          <person id="2599">Daniel Lovasko</person>
        </persons>
        <links>
          <link href="https://github.com/lovasko/libctf">Main project repository</link>
        </links>
      </event>
    </room>
    <room name="UD2.120 (Chavanne)">
      <event id="2855">
        <start>10:40</start>
        <duration>00:20</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>v2v</slug>
        <title>Moving your Virtual Machines to oVirt with ease</title>
        <subtitle>Overview of the process of import VMs from different environments into oVirt in light of the upcoming integration with virt-v2v</subtitle>
        <track>Infrastructure as a service</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Suppose you want to import virtual machines you already have into oVirt to enjoy a features-rich open sourced management system. You will soon figure out that the conversion of virtual machines running on different hypervisors or managed by different management systems into oVirt is not an easy task. The next major version of oVirt is going to introduce an integrated process that will simplify import of virtual machines not being managed by oVirt into oVirt. This session gives a heads up for the feature: we will go over the design and see how it solves issues that we had before to provide better way for import virtual machines to oVirt.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Until now from oVirt one could only import virtual machines (VMs) that were managed once by oVirt, either VMs that were exported from oVirt or VMs that reside on storage that was attached once to oVirt. In order to import VMs that run on different hypervisors or managed by different tools/management solutions, one had to use external tool, such as virt-v2v, separately to convert the VMs so they will fit to oVirt and then import the VMs from oVirt. This results in a slow, tedious and error-prone process.
An important feature in oVirt 3.6 is going to be the extension of import VMs capabilities to provide users with a process that is integrated within oVirt web-admin ui for import VMs from external environments, i.e VMs that run on different hypervisors and managed by different management solutions. We produce a process based on integration with virt-v2v, for import such VMs to oVirt which is better in terms of usability, performance and monitoring. The new process will ease migration of existing VMs into oVirt, encouraging people to have their existing virtual environments replaced with oVirt.
In this session we will analyse the problems with the previous process, go over the design of the new one and see how it address the problems we used to have, producing a better way for migrate existing virtual environments to open source virtualization platform.&lt;/p&gt;</description>
        <persons>
          <person id="2587">Arik Hadas</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3081">
        <start>11:00</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>faulttolerantmesos</slug>
        <title>Build Distributed, Fault-Tolerant Infrastructure with Apache Mesos</title>
        <subtitle/>
        <track>Infrastructure as a service</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Apache Mesos is a resource manager for datacenter infrastructure that uses a two-level scheduling model to provide hardware resources to various application frameworks. Organized in two parts, this talk will provide an overview of the Mesos compute model (comparing and contrasting how it relates to IaaS), and then walk through writing an application for Mesos using the framework API.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Apache Mesos is a resource manager for datacenter infrastructure that uses a two-level scheduling model [1] to provide hardware resources to various application frameworks. Similar to Infrastructure as a Service (IaaS), Mesos manages hardware and the execution of applications, while delegating the responsibility of deployment to other platforms. In the Mesos model, application frameworks are responsible for scheduling and deployment logic. Multiple frameworks can be run on bare-metal at the same time using a single pool of resources, including use-cases for long-running services (including Marathon, Aurora, Singularity), and batch/streaming (Hadoop, Storm, Jenkins).&lt;/p&gt;

&lt;p&gt;The abstraction Mesos provides for running and writing distributed applications has proven interesting to several IaaS projects, including OpenStack [3] and CloudStack. [4] While IaaS typically addresses a larger set of concerns (including virtual machines, servers, storage, load balancers, and network), the narrow focus of Mesos on resource management has provided opportunities for integration between traditional IaaS and Mesos in the future.&lt;/p&gt;

&lt;p&gt;Organized in two parts, this talk will provide both an overview of the Mesos compute model (comparing and contrasting how it relates to IaaS), and walk through writing an application for Mesos using the framework API.&lt;/p&gt;

&lt;p&gt;Part one will cover their essential architectures and how they enable fault-tolerance with replicated master nodes, scalability to 10,000's of machines, and resource isolation between tasks. Part two will demonstrate how users can write custom application schedulers for Mesos by leading through an example (likely in Python or Go). Attendees will come away with an understanding of how the software abstractions Mesos provides (resource manager and scheduler) work together, and with essential knowledge to write a custom scheduler.&lt;/p&gt;

&lt;p&gt;Citations:
[1] http://people.csail.mit.edu/matei/papers/2011/nsdi_mesos.pdf
[2] http://mesos.apache.org/documentation/latest/mesos-frameworks
[3] https://issues.apache.org/jira/browse/MESOS-876
[4] https://twitter.com/ke4qqq/status/535421157202460674&lt;/p&gt;</description>
        <persons>
          <person id="1925">Dave Lester</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2842">
        <start>11:40</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>glusterfsoverview</slug>
        <title>GlusterFS - Overview &amp; Future Directions</title>
        <subtitle/>
        <track>Infrastructure as a service</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;GlusterFS is a distributed scale-out filesystem that runs on commodity hardware. In this session, Niels de Vos will
provide an architectural overview of GlusterFS and discuss how its file, object &amp;amp; block interfaces can be used to build a scale-out storage solution for
IaaS needs. Details on new features , use cases and interesting challenges with GlusterFS will be provided. As part of this
session, Niels will also discuss integration of GlusterFS with other open source ecosystems like OpenStack, oVirt and provide
future directions of the GlusterFS project.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2925">Niels de Vos</person>
        </persons>
        <links>
          <link href="http://gluster.org">Homepage of the Gluster Community</link>
        </links>
      </event>
      <event id="3056">
        <start>12:20</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>hyperconvergence</slug>
        <title>oVirt and Gluster Hyperconvergence</title>
        <subtitle/>
        <track>Infrastructure as a service</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This session will cover in detail the ongoing effort of integrating the oVirt virtualization and Gluster storage resources in single commodity boxes that can scale horizontally. The presentation will include the description of the technical challenges encountered, the status of the ongoing effort and the roadmap for the possible future improvements.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;oVirt virtualization and Gluster storage overview&lt;/li&gt;
&lt;li&gt;Architecture, hardware and software setups&lt;/li&gt;
&lt;li&gt;Scaling horizontally&lt;/li&gt;
&lt;li&gt;Challenges of the oVirt and Gluster Hyperconvergence&lt;/li&gt;
&lt;li&gt;Current status and other possible improvements&lt;/li&gt;
&lt;li&gt;Roadmap and future additions&lt;/li&gt;
&lt;/ul&gt;
</abstract>
        <description></description>
        <persons>
          <person id="620">Federico Simoncelli</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3163">
        <start>13:00</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>leveragingceph</slug>
        <title>Leveraging Ceph</title>
        <subtitle>Ceph integration in OpenStack, Cloudstack, ganeti ..</subtitle>
        <track>Infrastructure as a service</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The Ceph storage system is used by many IaaS software. It provides self-healing distributed storage in many forms (block device, file system and object store).&lt;/p&gt;</abstract>
        <description>&lt;p&gt;An overview of the most recent Ceph features will be followed by use cases about how current IaaS stacks could leverage them.&lt;/p&gt;</description>
        <persons>
          <person id="984">Loic Dachary</person>
        </persons>
        <links>
          <link href="http://ceph.com/">Ceph</link>
        </links>
      </event>
      <event id="3243">
        <start>13:40</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>opennebula</slug>
        <title>OpenNebla Deployments, from small to massive</title>
        <subtitle>Leveraging other open source projects to build clouds</subtitle>
        <track>Infrastructure as a service</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Learn how other people are using OpenNebula today to deploy clouds in a snap, all the way from micro clouds to massively big, federated clouds. Learn performance and tuning tips shared by other OpenNebula fellow users to leverage other open-source projects like Ceph, LizardsFS, Open vSwitch and Puppet into making your cloud resilient, fast, flexible and massive.&lt;/p&gt;

&lt;p&gt;We will also shed some light on other OpenNebula compoments that have grown indispensable to their users, like hooks, AppMarket to share images accross OpenNebula deployments, OneFlow to manage services and OneGate to report metrics directly to OpenNebula.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2814">Jaime Melis</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2706">
        <start>14:20</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>cinderstateopenstack</slug>
        <title>Cinder - the state of block storage in Openstack</title>
        <subtitle>Where we've been, where we are, where we're going and where you can help</subtitle>
        <track>Infrastructure as a service</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Cinder is the block storage solution for Openstack. It has been around for 2 years, and has become a stable and useful part of the Openstack infra-structure. This talk gives the history of Cinder, the current challenges being worked on and some blue sky ideas for where it could go.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2434">Duncan Thomas</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3156">
        <start>15:00</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>deployopenstackxen</slug>
        <title>OpenStack and Xen</title>
        <subtitle>Deploy your OpenStack cloud on the Xen hypervisor</subtitle>
        <track>Infrastructure as a service</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk will explain how to deploy OpenStack using the Xen hypervisor to run your virtual machines.&lt;/p&gt;

&lt;p&gt;It will start by describing the OpenStack architecture and its most important components.
It will go into details on how to use DevStack to setup an OpenStack development environment based on Xen and Libvirt. It will also cover the most popular and robust deployment schemes for OpenStack with Xen and Libvirt aimed for production servers, including Ubuntu packages from the latest LTS, Chef and Puppet.&lt;/p&gt;

&lt;p&gt;The audience will learn the most important OpenStack and Xen config options, the pitfalls to avoid in their deployment and how to tweak both of them to get the best performance and stability out of your OpenStack cloud.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1892">Stefano Stabellini</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2847">
        <start>15:40</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>smartvmsched</slug>
        <title>Smart VM scheduling in oVirt cluster</title>
        <subtitle>Deep dive to scheduling service based on probabilistic methods</subtitle>
        <track>Infrastructure as a service</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The oVirt project allows efficient management of virtualized datacenters. Deciding what machine should host a certain VM is one of the important functions of the management platform. Unfortunately it is also one of the complex ones, because there can be many rules governing the placement policy and there is a time limit in which a VM has to be started or migration initiated. Till now each VM was considered separately and that caused fragmentation of free resources.&lt;/p&gt;

&lt;p&gt;We are about to present a new solution to this issue in this presentation. We have started a cooperation with the OptaPlanner team that develops an optimization engine based on probabilistic (soft computing) algorithms. This means that oVirt will feed situation updates to an optimization service and continuously receive improved solutions back. It will then use the precomputed results for rebalancing the clusters.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1878">Roy Golan</person>
        </persons>
        <links>
          <link href="http://community.redhat.com/blog/2014/11/smart-vm-scheduling-in-ovirt-clusters/">Blog post explaining the project goals and internals</link>
        </links>
      </event>
      <event id="3140">
        <start>16:20</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>whatmanageiq</slug>
        <title>What you can do with open source cloud management (and ManageIQ)</title>
        <subtitle>Control all of the things</subtitle>
        <track>Infrastructure as a service</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;What is cloud management and why do you need it? This talk explains the security and productivity ramifications of a hybrid cloud infrastructure, and how you can wrangle its various components. You need: comprehensive security, finance/chargeback, automation and orchestration. Here's how to control all of the things.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;What is "Cloud Management"? In a datacenter, you might have 2 or more virtualization management platforms, with a private cloud running alongside, and some workloads running in a public cloud. ManageIQ gives admins and developers a way to seamlessly deliver services from multiple cloud and virtualization platforms.&lt;/p&gt;

&lt;p&gt;Across your cloud and virtualization platforms, you'll need to enforce some kind of consistency in who can consume your resources, integrate with approval workflows, and be aware of waste when it is happening. Maybe you also want to automate the provisioning of instances, integrate with a service catalog or configuration management system. Perhaps you want to know when VMs are vulnerable to security issues, prevent new VMs to be created from known-bad templates, and perform some clean-up of services when they are retired.&lt;/p&gt;

&lt;p&gt;These are all cloud management problems. Whether it's containing VM sprawl or finding and fixing hot spots in the data center, this presentation will give you tools and techniques you can use to manage it all.&lt;/p&gt;

&lt;p&gt;ManageIQ is a recently open sourced cloud management platform and toolkit with a RESTful API and comprehensive gateway to most popular virtualization and cloud services platforms, including vSphere, Hyper-V, oVirt, RHEV, AWS, and OpenStack (with more on the way). It is a powerful orchestration and automation engine that admins use to integrate their build, test and deploy services with virtualization and cloud platforms. ManageIQ allows developers and admins to manage their services in one place, side-by-side.&lt;/p&gt;

&lt;p&gt;In this technical deep dive, we will explore the orchestration and automation components of ManageIQ and demonstrate how it can be used to operationalize any hybrid cloud deployment . You'll learn about:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Code to create an application service catalog.
Automation of compute host evacuation in response to monitoring and security events
Preparation of physical compute hosts in advance of planned maintenance work.
This talk will include an overview of the ManageIQ community as well as a live demonstration.
&lt;/code&gt;&lt;/pre&gt;</description>
        <persons>
          <person id="1072">John Mark Walker</person>
        </persons>
        <links>
          <link href="http://manageiq.org/">ManageIQ home</link>
        </links>
      </event>
      <event id="2944">
        <start>17:00</start>
        <duration>00:20</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>ignoredfamousiaas</slug>
        <title>Why we tried (and ignored) famous IaaS to deliver SecurePass</title>
        <subtitle>A walk through our journey through IaaS such as VMware, OpenStack and Ganeti and why we chose our own solution</subtitle>
        <track>Infrastructure as a service</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Our question was: "what is the best infrastructure to run our SaaS on?".
We tried most of the infrastructure software, starting from vmware, moving to Proxmox, OpenNebula, OpenStack, and Google's Ganeti. We also considered software storage and software defined networks. We mastered some of these technologies and we even contributed to the projects. But we felt we needed something different and lighter and we "blended" our own solution, mixing and matching the best of the above and keeping in consideration our needs in terms of computing, network and storage. This talk will go through our (long) journey, understanding pros and cons of each technology and describing what we used to deliver SecurePass and other services.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2647">Giuseppe Paternò</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3165">
        <start>17:40</start>
        <duration>00:20</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>designatedns</slug>
        <title>Designate - DNS as a Service for Openstack</title>
        <subtitle>Multitenant DNS Service for your cloud</subtitle>
        <track>Infrastructure as a service</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Designate is a newly incubated project in OpenStack, for providing an easy to use, integrated DNS service to users of your cloud.
We integrate with Nova and Neutron, and allow control of Reverse DNS for floating IPs.
Using sink features, we can pull events from the neutron / nova event queue and auto generate DNS entries.&lt;/p&gt;

&lt;p&gt;We will show all of this functionality, and talk about the upcoming features, while taking feedback from the community about what else they would like to see provided by Designate.&lt;/p&gt;

&lt;p&gt;We will also update the community on the developments of the Mid-Cycle summit (happening the week previously)&lt;/p&gt;

&lt;p&gt;Graham Hayes is a member of designate-core, and one of the main architects of our current feature push called server pools, which will allow per user DNS servers, and the ability to run DNS servers at massive scale.&lt;/p&gt;

&lt;p&gt;Kiall Mac Innes is the PTL and the original author for Designate&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2777">Graham Hayes</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="UB2.252A (Lameere)">
      <event id="2756">
        <start>10:30</start>
        <duration>00:25</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>allwinner_upstream</slug>
        <title>Upstream Allwinner ARM SoC (A10 / sunxi) support status</title>
        <subtitle/>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;What is the current status of Allwinner support in upstream u-boot and the kernel, which SoCs are supported, and which features (sound, video, etc.) are supported ?&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The linux-sunxi community has been slowly but steadily working on getting Allwinner SoCs like the A10 supported in upstream u-boot and the kernel.&lt;/p&gt;

&lt;p&gt;This talk will present the current status of Allwinner support upstream. Which SoCs are supported and which ones are not (yet) supported ? Which blocks if the supported SoCs are supported, and which are not ? Why are some SoCs / blocks not supported, and what are the plans to get them supported ? This are some of the questions this talk tries to answer.&lt;/p&gt;</description>
        <persons>
          <person id="80">Hans de Goede</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2975">
        <start>11:00</start>
        <duration>00:25</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>freertos</slug>
        <title>FreeRTOS introduction</title>
        <subtitle/>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Not all free operating systems are feature-full POSIX systems. FreeRTOS is a minimal operating system which is designed to run on microcontrollers, and provide real-time scheduling. It is used in industrial automation and automotive.&lt;/p&gt;

&lt;p&gt;A brief introduction to FreeRTOS, depending on audience preference, will be followed by either a hands-on workshop using PCs, or a demonstration on a board. The workshop includes how to get started, what can be done with it, and what type of features and pitfalls to expect from FreeRTOS.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2023">Atilla Filiz</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3004">
        <start>11:30</start>
        <duration>00:25</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>car_hypervisor</slug>
        <title>Xvisor: An open-source, lightweight, embedded hypervisor for your car</title>
        <subtitle/>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;As ADAS and infotainment require more electronics, using an hypervisor is
a solution to gather multiple boards into one. Xvisor is an open source
lightweight hypervisor for embedded systems that perfectly fits the needs of
the automative industry. It is a complete monolithic type-1 hypervisor with
full virtualization and paravirtualisation support, showing better performances
than KVM.&lt;/p&gt;

&lt;p&gt;We, OpenWide and the Institute for Technological Research SystemX, are working
on its port on i.MX6 boards.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Nowadays, as the Advance Driver Assistance Systems (ADAS) needs drastically
increases, the number of electronic boards, cables, communication channels,
and devices explodes.
In the meantime, infotainment is one of the selling points for automotive
industries to sell new cars, which also mean more electronics.
Thanks to the Genivi initiative, those systems will run under Linux, whilst
car control electronics run under Autosar (AUTomotive Open System
ARchitecture) OSes, which are closed source binaries.&lt;/p&gt;

&lt;p&gt;Gathering multiple boards into one with hypervisors is a solution to reduce
costs and increase functionalities. Xvisor is an open source lightweight
hypervisor for embedded systems that fits perfectly the needs of the automative
industry.&lt;/p&gt;

&lt;p&gt;It is a complete monolithic type-1 hypervisor with full virtualization,
allowing unmodified guest support (useful for AUTOSAR components) and
paravirtualization, which can help improve Linux guest performance.
Moreover, on ARM, Xvisor shows better performances than KVM.
It has been mainly developed by Anup Patel, and joined by
Jean-Christophe Dubois, Himanshu Chauhan, Sukanto Ghosh and
Pranav Sawargaonkar.
This presentation will focus on ARM usage while introducing the concepts of
virtualisation, paravirtualisation.&lt;/p&gt;

&lt;p&gt;Even if Xvisor is a young project, publicly visible from June 2011, as its
sources are very close to Linux, ports remain quite fast and easy. It uses
device tree files, both for board definition and configuration parts.
It is in this way that we, OpenWide and the Institute for Technological
Research SystemX, continue the work of Jean-Christophe on the i.MX6 port of
Xvisor, for the Boundary Devices Nitrogen6x (and the Freescale SabreLite).&lt;/p&gt;

&lt;p&gt;Then will show:
- the binary rewriting tool usage on guest binaries,
- Xvisor running on Qemu,
- configurable and dynamic guest creation
- and Xvisor running on the i.MX6.&lt;/p&gt;</description>
        <persons>
          <person id="2693">Jimmy Durand Wesolowski</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2641">
        <start>12:00</start>
        <duration>00:45</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>fish_fly</slug>
        <title>Teaching Fish to Fly</title>
        <subtitle>Embedded platforms take to the air.</subtitle>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In 2013, at the Embedded Linux Conference in Europe in Edinburgh, there was a race between a dog and a blimp. It was said that despite the dogs win, that the blimp had participated in the miracle of flight. In 2014 we intend to show that the brains of that dog can be transplanted and that it too, can participate in the miracle of flight. The talk is mainly targeting taking an off the shelf embedded platform, MinnowBoard Max, and it's use in UAVs, specifically quad-copters. With the ability to do real time computer vision, as well as various GPIO capabilities we'll explore the directions that significantly more autonomous UAVs can take with Linux and embedded platforms using, mostly, off the shelf components.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;In 2013, at the Embedded Linux Conference in Europe in Edinburgh, there was a race between a dog and a blimp. It was said that despite the dogs win, that the blimp had participated in the miracle of flight. In 2014 we intend to show that the brains of that dog can be transplanted and that it too, can participate in the miracle of flight. The talk is mainly targeting taking an off the shelf embedded platform, MinnowBoard Max, and it's use in UAVs, specifically quad-copters. With the ability to do real time computer vision, as well as various GPIO capabilities we'll explore the directions that significantly more autonomous UAVs can take with Linux and embedded platforms using, mostly, off the shelf components.&lt;/p&gt;

&lt;p&gt;There are a multitude of applications where this kind of technology is useful, from basic hobbyists, forestry services to search and rescue.&lt;/p&gt;</description>
        <persons>
          <person id="2310">John 'Warthog9' Hawley</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3035">
        <start>13:00</start>
        <duration>00:45</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>sailfishos</slug>
        <title>Recycle your Android devices for anything : run real Linux on them</title>
        <subtitle>Routing around the breakage of closed binary blobs</subtitle>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Our world is full of small powerful devices; but most of them run Android.&lt;/p&gt;

&lt;p&gt;I'll show how Mer, SailfishOS and HADK lets us reuse them as full blown linux systems - with touchscreens, 3D graphics, modem, wifi, usb...&lt;/p&gt;

&lt;p&gt;At the heart is libhybris - talked about at FOSDEM; found inside the Ubuntu Touch distro, invented and developed at Mer &amp;amp; Jolla where it's used in the Jolla phone (ARM) and soon the Jolla tablet (x86).&lt;/p&gt;

&lt;p&gt;Together we can route around the breakage of closed binary blobs and work on FOSS on these devices.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2373">David Greaves</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2646">
        <start>14:00</start>
        <duration>00:45</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>hack_your_camera</slug>
        <title>How to program your camera!</title>
        <subtitle>An introduction to CHDK</subtitle>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Digital cameras provide almost every feature you could want. But if they don't, you are forced to upgrade or go without. CHDK is a project which allows you to program new functionality to the majority of Canon cameras, in either C, Lua, or Basic. The talk features background on the project, code, tools, and the methods of compiling and introducing a new firmware into the camera.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Over the course of 1 hour, Steven Goodwin will guide the audience through the entire process of taking a normal (proprietary) camera and converting it into an open source version by installing custom firmware on it. He will then cover some of the features available (such as the on-device scripting language) and continue by explaining how to build and debug your own functionality. Starting with simple grids, continuing with games, and time-lapse code. And ending with a fully recompiled firmware running on the device.&lt;/p&gt;</description>
        <persons>
          <person id="392">Steven Goodwin</person>
        </persons>
        <links>
          <link href="http://chdk.wikia.com">Main site</link>
          <link href="http://marquisdegeek.com/rnd_chdk.php">Speakers CHDK tools</link>
        </links>
      </event>
      <event id="3186">
        <start>15:00</start>
        <duration>00:45</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>embedded_freedom</slug>
        <title>Freedom Embedded: Devices that Respect their Users</title>
        <subtitle/>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;GNU and Linux are now embedded on more kinds of hardware than ever,
but often only by requiring proprietary bits. Plus, we now have
tablets and phones loaded with nonfree software on top of a free core
-- how do we get the freedom we all want, and how do we create the
market for that? The Free Software Foundation has a certification
program called "Respects Your Freedom" that awards a certification
mark to hardware meeting a set of standards (fsf.org/ryf). Embedded
devices are a major target for the future of this program.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;It has already made significant gains, especially over the last two
years, certifying USB wifi adapters, 3D printers, home wifi routers,
and a laptop. Even bigger things are planned, and most involve the
embedded world. Hear about what's in store, learn what it takes to get
your embedded product certified, hear about the impact of
certification so far, and discuss possible improvements to the
program.&lt;/p&gt;</description>
        <persons>
          <person id="1577">John Sullivan</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2738">
        <start>16:00</start>
        <duration>00:25</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>arm_perf</slug>
        <title>perf status on ARM and ARM64</title>
        <subtitle/>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Kernel profiling tools status on ARM and ARM64:
- perf status,
- ARM and ARM64 support,
- callchain unwinding mechanisms and support,
- patches status: merged, pending, in development,
- links to discussions (LKML) and patches.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The profiling tools in the kernel are changing at a fast pace.
This talk is about the support for ARM and ARM64 architecture and the development of features for these architectures, namely the callchain unwinding.
The presentation goes over:
- the detailed description of the feature,
- the methods used to do the callchain unwinding (fp, exidx, dwarf etc.),
- the status of the on-going patches,
- the remaining work to be done,
- the links to patches, discussions on the mailing lists,
- -if needed and if time allows- a demo of the feature.&lt;/p&gt;</description>
        <persons>
          <person id="2472">Jean Pihet</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3098">
        <start>16:30</start>
        <duration>00:25</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>medical_monitoring</slug>
        <title>Building a medical monitoring connected device with Yocto</title>
        <subtitle>Professional OS with yocto</subtitle>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Building a medical device requires to follow certain rules specially when health care depend on it.
The presentation will explain how Yocto help us in Kaptalia to solve this issue.
In particular we will focus on fast boot, update with unskilled user base, Bluetooth Low Energy, security and data privacy.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;During this event we will show how our team succeeded to build our first OS, start from a company with medical expert only and no prior expertise on embedded systems.&lt;/p&gt;

&lt;p&gt;In addition, an explanation to the Yocto (errors you do not want to repeat) path will be presented.&lt;/p&gt;

&lt;p&gt;During a medical procedure, especially when the patient is asleep, the anesthetist need a device to check the vital signs of his patient.
As our device is aimed to be used as medical user base, it meets the requirements of being reliable, easy to use, easy to update, and satisfies regulatory environments.
Our monitor communicates with some wireless devices using Bluetooth Low Energy.
The device contains medical data so we had deal with data privacy and security.
During industrialization, the entire OS is deployed in one shot. This operation has to be performed by a technician in a very secure manner.
Also, the steps of building our devices will be presented. This includes the device architecture, the fast boot on ARM, the time duration of boot on ARM and its optimization, the bullet proof update, and the custom Bluetooth Low Energie program.&lt;/p&gt;

&lt;p&gt;At the end, a live demonstration for using the the monitor and sensor will be held.&lt;/p&gt;

&lt;p&gt;Questions &amp;amp; answers&lt;/p&gt;</description>
        <persons>
          <person id="2747">Adrien Renault</person>
        </persons>
        <links>
          <link href="http://www.kaptalia.com">website</link>
        </links>
      </event>
      <event id="3028">
        <start>17:00</start>
        <duration>00:45</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>lava_bugs</slug>
        <title>Using LAVA for bisecting bugs</title>
        <subtitle>The Linaro Automated Validation Architecture</subtitle>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;LAVA is a python service created by Linaro for testing software on hardware which accepts test jobs to perform on selected hardware to provide a black box to continuous integration tests. Bisecting is a technique for finding commit in version control system that broke the software. Git provides the powerful "git bisect" subcommand for this purposes. In this talk we give and introduction to LAVA and explain howto combine LAVA and git bisect to automatically find offending commits in the Linux kernel.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;LAVA stands for "The Linaro Automated Validation Architecture", A tool created to help automatic testing of ARM Linux systems. It is completely open source and developed out in open. LAVA is the testing side of the Linaro's continous integration loop, providing users ability to do smoke, regression and performance test easily on wide variety of ARM boards. It provides a web dashboard for submitting test jobs, viewing results, trends and states of users jobs. Pretty much any embedded Linux project involves updating the kernel and booting the target board numerous times. LAVA helps take away the manuals steps from the process.&lt;/p&gt;

&lt;p&gt;"Git bisect" is a powerful command in git. It lets users do a binary search from git version history between a "known good" and "known bad" commit to find which exact commit is at the fault on regressions. Most  developers who actively use git are familiar with bisect, those who are not, should definitely consider learning it.&lt;/p&gt;

&lt;p&gt;Wiring up LAVA to manual bisect testing is easy, but why settle there, when you can automate it all the way? During the presentation we let the computer do a bisecting demo in background.&lt;/p&gt;</description>
        <persons>
          <person id="2712">Riku Voipio</person>
        </persons>
        <links>
          <link href="http://validation.linaro.org/">Linaro LAVA Server</link>
          <link href="https://wiki.linaro.org/LAVA">LAVA wiki</link>
          <link href="https://validation.linaro.org/static/docs/">LAVA documentation</link>
          <link href="http://git-scm.com/docs/git-bisect">git bisect manual</link>
        </links>
      </event>
      <event id="3023">
        <start>18:00</start>
        <duration>00:45</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>diy_dvr</slug>
        <title>How to record all TV</title>
        <subtitle>Creating a 30 channel DVR</subtitle>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Prospero Technologies has made a Linux based Digital Video Recorder which constantly records all UK broadcast TV so that the consumer no longer needs to schedule recordings. This will be a talk on the technologies used to achieve this, the open source software on the consumer device and how you can build your own 30 channel DVR.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The 30 channel DVR is a consumer version of a product we have been refining, a multi-tuner PCI card called Vortex. I shall be detailing the process and the pitfalls of developing a Linux PCI driver and explaining how Vortex itself works.&lt;/p&gt;

&lt;p&gt;Lots of consumer embedded devices run Linux these days, but it's hard to pick out a distribution. I'll be explaining the process we went through, how we ended up with using Yocto for our device and a brief overview of how to roll your own distribution using Yocto.&lt;/p&gt;

&lt;p&gt;The final version of the DVR uses a freescale i.mx6 cpu with a video processing unit, the talk will cover how well this is supported by gstreamer and how we built a QT application to display our HTML5 interface.&lt;/p&gt;</description>
        <persons>
          <person id="2709">Philip Downer</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="H.1301 (Cornil)">
      <event id="3086">
        <start>10:30</start>
        <duration>00:25</duration>
        <room>H.1301 (Cornil)</room>
        <slug>taskflow:_state_management_framework</slug>
        <title>TaskFlow: State Management Framework</title>
        <subtitle/>
        <track>Python</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;TaskFlow is a lightweight and efficient state management library. It was originally developed for OpenStack projects and has recently become popular and widely used across python community and projects for efficient state management.&lt;/p&gt;

&lt;p&gt;The agenda for this discussion will be following
1) Motivation &amp;amp; Expectation for State Management
2) Usage Scenario
3) Basic Concepts and Architecture
4) Demonstration and usage of the taskflow library&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2695">Vishal Yadav</person>
        </persons>
        <links>
          <link href="http://in.pycon.org/funnel/2014/191-taskflow-python-state-management-framework">PyCon India - 2014</link>
          <link href="https://speakerdeck.com/navigator/python-taskflow">Speaker Deck</link>
        </links>
      </event>
      <event id="2751">
        <start>11:00</start>
        <duration>00:25</duration>
        <room>H.1301 (Cornil)</room>
        <slug>lea,_a_probability_engine_in_python</slug>
        <title>Lea, a probability engine in Python</title>
        <subtitle>the discreet charm of probabilities</subtitle>
        <track>Python</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Lea is a Python open-source module dedicated to discrete probability distributions. It allows modelling uncertain information and derive  probabilities in an intuitive way. It provides means to build random variables with given probability distributions, probability calculus with integers, standard indicators, conditional probabilities and generation of random samples. The forthcoming Lea 2 (should be ready for FOSDEM 2015!) shall include Bayesian reasoning, Markov chains and a high-level PPL (Probability Programming Language).&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Lea is a Python package aiming at working with discrete probability distributions in an intuitive way. It allows modelling a broad range of random phenomenons, like dice throwing, coin tossing, cards hands, gambling, lottery, … with fair or unfair characteristics! More generally, Lea may be used for any finite set of discrete values having known probability: numbers, boolean variables, date/times, symbols, ...&lt;/p&gt;

&lt;p&gt;Each probability distribution is modelled as a plain object, which can be named, displayed, queried or processed to produce new distribution objects. Lea provides standard indicators, conditional probabilities and generation of random samples. The forthcoming Lea 2 (should be ready for FOSDEM 2015!) shall include Bayesian reasoning, Markov chains and "Leash", a high-level PPL (Probability Programming Language).&lt;/p&gt;

&lt;p&gt;On an implementation point of view, probabilities are stored using integers (e.g. not float), allowing to avoid any risk of rounding errors. Lea implementation heavily relies on Python's operator overloading, generators and duck-typing.&lt;/p&gt;</description>
        <persons>
          <person id="2480">Pierre Denis</person>
        </persons>
        <links>
          <link href="http://code.google.com/p/lea/">Lea project page</link>
          <link href="http://pypi.python.org/pypi/lea/1.3.1">Lea on PyPI</link>
        </links>
      </event>
      <event id="3054">
        <start>11:30</start>
        <duration>00:25</duration>
        <room>H.1301 (Cornil)</room>
        <slug>dive_into_scrapy</slug>
        <title>Dive into Scrapy</title>
        <subtitle>In this talk some advanced techniques will be shown based on how Scrapy is used at Scrapinghub.</subtitle>
        <track>Python</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Scrapy is a fast high-level screen scraping and web crawling framework, used to crawl websites and extract structured data from their pages. It can be used for a wide range of purposes, from data mining to monitoring and automated testing.
In this talk some advanced techniques will be shown based on how Scrapy is used at Scrapinghub.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2727">Juan Riaza</person>
        </persons>
        <links>
          <link href="http://scrapy.org">Scrapy framework</link>
          <link href="http://scrapinghub.com">http://scrapinghub.com</link>
        </links>
      </event>
      <event id="3142">
        <start>12:00</start>
        <duration>00:25</duration>
        <room>H.1301 (Cornil)</room>
        <slug>mercurial,_with_real_python_bites</slug>
        <title>Mercurial, with real python bites</title>
        <subtitle>Up and Down of the python language in large scale command line tool.</subtitle>
        <track>Python</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In 2005, Matt Mackall picked Python to implement a new version control system: Mercurial. Ten years later, the project is a success! Thanks to python? Lets see what shinning advantages met us and what issues we, developers, had to work around. We'll also take a detour to the place were python outcrop to the users, the extensions system.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;In 2005, Matt Mackall picked Python to implement a new version control system: Mercurial. Ten years later, the project is a success! Thanks to python?&lt;/p&gt;

&lt;p&gt;In this Talk, we'll go over on the advantages of Python that helped the project both in its early life when so much feature needs to be implemented, but also nowaday when major companies like Facebook bet on Mercurial for scaling. We'll also point at the drawback of choosing python and how some work-arounds had to be found. Finally, we'll look at how the choice of python have an impact on the user too with a demonstration of the extensions system.&lt;/p&gt;</description>
        <persons>
          <person id="1232">Pierre-Yves David</person>
        </persons>
        <links>
          <link href="http://www.pycon.fr/2013/schedule/presentation/34/">First version of the talk (french)</link>
        </links>
      </event>
      <event id="2702">
        <start>12:30</start>
        <duration>00:25</duration>
        <room>H.1301 (Cornil)</room>
        <slug>python_prompt_toolkit_/_ptpython</slug>
        <title>python-prompt-toolkit / ptpython</title>
        <subtitle/>
        <track>Python</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Ptpython is a better Python REPL built on top of prompt-toolkit. In this talk we'll have a look at what pt(i)python is and how to use it.
Further we'll have a look at the underlying library prompt-toolkit. We'll see how it works and how easy it is to create a custom REPL with syntax highlighting, code completion and input validation. (for instance to create an SQLite client.)&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Prompt-toolkit is a library for designing command line interfaces. Basically, it can be a pure Python replacement for GNU readline: it implements most of the Emacs and Vi keybindings as well as reverse search and code completion and it supports double width characters. However, it can be even much more powerful. There is syntax highlighting of the input, multiline editing, support for toolbars, custom layouts, multiple input fields and integration with other event loops (e.g. asyncio).&lt;/p&gt;

&lt;p&gt;In this talk we will see how easy it is to create a custom command line interface: it doesn't take more than a few lines of code. Further we'll see how to add input validation, code completion and other extensions, each without much effort.&lt;/p&gt;

&lt;p&gt;We will also have a look at ptpython. This is a Python REPL build on top of this library. We have a look at several interesting features of ptpython which can make your REPL experience even better. And finally, there is ptipython, the front-end for IPython.&lt;/p&gt;</description>
        <persons>
          <person id="2431">Jonathan Slenders</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3190">
        <start>13:00</start>
        <duration>00:25</duration>
        <room>H.1301 (Cornil)</room>
        <slug>federation_and_python_webapps</slug>
        <title>Federation and Python webapps</title>
        <subtitle/>
        <track>Python</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Decentralize the web!  Everyone wants to, but actually getting a decentralized network of websites is notoriously hard.  Luckily, much of the hard work is already done.  Learn about federation standards (including recent activities at the W3C Social Working Group) and how to use PyPump, a library to make federating with Python easier, and how we're tackling site-to-site federation in GNU MediaGoblin.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Decentralize the web!  Everyone wants to, but actually getting a decentralized network of websites is notoriously hard.&lt;/p&gt;

&lt;p&gt;Luckily, much of the hard work is already done.  Learn about federation standards and how to use &lt;a href="http://pypump.org/"&gt;PyPump&lt;/a&gt;, a python library to make federating with Python easier following the &lt;a href="https://github.com/e14n/pump.io/blob/master/API.md"&gt;Pump API&lt;/a&gt;, and how we're tackling site-to-site federation in &lt;a href="http://mediagoblin.org/"&gt;GNU MediaGoblin&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In addition to examples on how to federate, learn what the current state of standardizing federation protocols are, lessons learned through the standards process, and the latest to come out of the &lt;a href="https://www.w3.org/wiki/Socialwg"&gt;W3C Social Working Group&lt;/a&gt;.&lt;/p&gt;</description>
        <persons>
          <person id="1062">Christopher Webber</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3417">
        <start>13:30</start>
        <duration>00:25</duration>
        <room>H.1301 (Cornil)</room>
        <slug>lets_build_a_spreadsheet_app_in_python</slug>
        <title>Let's build a spreadsheet app in Python</title>
        <subtitle>A tour of the (remarkably simple) code you need to build a fully-functional Pythonic spreadsheet</subtitle>
        <track>Python</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Building a spreadsheet app with Python is simpler than you think!  I'll show you how we can build one with Python, from the ground up, in 15 minutes or less.  Fun times with recursion guaranteed.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Have you ever wondered how a spreadsheet works? I was fairly #mindblown when someone first explained it to me on the back of a beermat -- it's simpler than I thought! Let me take you on a tour of the source code for Project Dirigible, an experimental web port of Resolver One, the (sadly defunct) Pythonic spreadsheet. We'll cover formula parsing, identifying dependencies, building the recalculation graph, loop detection, and even some of the mind-bending fun that Dirigible lets you do with user-defined functions.&lt;/p&gt;</description>
        <persons>
          <person id="2907">Harry Percival</person>
        </persons>
        <links>
          <link href="https://github.com/pythonanywhere/dirigible-spreadsheet">the source code for dirigible, the pythonic spreadsheet</link>
          <link href="http://">http://</link>
        </links>
      </event>
      <event id="3063">
        <start>14:00</start>
        <duration>00:25</duration>
        <room>H.1301 (Cornil)</room>
        <slug>understanding_cpython_34_objects</slug>
        <title>Understanding CPython (3.4) Objects</title>
        <subtitle/>
        <track>Python</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;I will explain how CPython objects are built, from simple objects
like int or None to complex ones like dict. To make it funnier, I
will play to change instance data directly using ctypes and do
"really bad things" like truncating tuples.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2500">Jesús Espino</person>
        </persons>
        <links>
          <link href="https://speakerdeck.com/jespino/objetos-basicos-de-cpython">Slides in PyConEs 2013</link>
          <link href="https://www.youtube.com/watch?v=qxWKnFo2xAw">Video on PyConEs 2013</link>
        </links>
      </event>
      <event id="3405">
        <start>14:30</start>
        <duration>00:25</duration>
        <room>H.1301 (Cornil)</room>
        <slug>customize_gunicorn_for_your_own_business</slug>
        <title>Customize Gunicorn for your own business.</title>
        <subtitle/>
        <track>Python</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Most people know Gunicorn as a Python WSGI HTTP Server engine, but a lot
ignore it can be used for more usages. With this talk you will discover how
you can use it to fit your own needs/business or simply distribute extensions for it.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Most people know Gunicorn as a Python WSGI HTTP Server engine, but a lot
ignore it can be used for more usages.&lt;/p&gt;

&lt;p&gt;This talk will show you how you can use the current Gunicorn version for different usages, from
embedding it in your application to extend it with your own TCP workers or
logging modules. This talk will also provide a quick glance (with demo) of the new
gunicorn engine, a fully featured process and sockets supervisor engine
allowing more customisations.&lt;/p&gt;</description>
        <persons>
          <person id="1385">Benoit Chesneau</person>
        </persons>
        <links>
          <link href="http://gunicorn.org">Gunicorn main website</link>
          <link href="http://">http://</link>
        </links>
      </event>
      <event id="2783">
        <start>15:00</start>
        <duration>00:25</duration>
        <room>H.1301 (Cornil)</room>
        <slug>python,_webrtc_and_you</slug>
        <title>Python, WebRTC and you</title>
        <subtitle/>
        <track>Python</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Introduction to WebRTC and application development using Python on the server side. Let's build a "Call Roulette"!&lt;/p&gt;</abstract>
        <description>&lt;p&gt;WebRTC is a recent technology present in modern web browsers allowing developers to create rich multimedia applications using realtime audio, video and data. This talk will give an introduction to WebRTC and walk through the implementation of a simple Call Roulette application, designing the necessary signaling protocol and implementing it on the server side using Python3 and asyncio.&lt;/p&gt;</description>
        <persons>
          <person id="186">Saúl Ibarra Corretgé</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2763">
        <start>15:30</start>
        <duration>00:25</duration>
        <room>H.1301 (Cornil)</room>
        <slug>when_performance_matters_</slug>
        <title>When performance matters ...</title>
        <subtitle/>
        <track>Python</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Python applications sometimes need all the performance they can get. Think of e.g. web, REST or RPC servers. There are several ways to address this: scale up by using more processes, use Cython, use PyPy, rewrite parts in C, etc.&lt;/p&gt;

&lt;p&gt;However, there are also quite a few things that can be done directly in Python. This talk goes through a number of examples and show cases how sticking to a few idioms can easily enhance the performance of your existing application without having to revert to more complex optimization strategies.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2150">Marc-André Lemburg</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2942">
        <start>16:00</start>
        <duration>00:25</duration>
        <room>H.1301 (Cornil)</room>
        <slug>gradual_typing_in_python</slug>
        <title>Gradual Typing in Python</title>
        <subtitle/>
        <track>Python</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Gradual typing in dynamic languages is becoming popular. The implementations for Python, Lua, Clojure and Racket show how a dynamic language can be retrofitted with static type checking. This makes possible to combine the flexibility of these languages with the guarantees of a type checker and can be done in a gradual, non-invasive manner.&lt;/p&gt;

&lt;p&gt;In this talk we'll understand what gradual typing is and the benefits it yields, explore the existing implementations for Python and talk about Guido's plans for the usage of function annotations introduced in Python 3.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2646">Alejandro Gómez</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3096">
        <start>16:30</start>
        <duration>00:25</duration>
        <room>H.1301 (Cornil)</room>
        <slug>knowing_your_garbage_collector</slug>
        <title>Knowing your garbage collector</title>
        <subtitle/>
        <track>Python</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;As Python programmers we're used to program without taking care about allocating
memory for our objects and later on freeing them, Python garbage collector
takes care of this task automatically for us.&lt;/p&gt;

&lt;p&gt;Garbage collection is one of the most challenging topics in computer science,
there are a lot of research around the topic and different ways to tackle
the problem.&lt;/p&gt;

&lt;p&gt;Knowing how our language does this process give us a better understanding
of underlying interpreter and allow us to know why problems like cycles
can happen in CPython interpreters.&lt;/p&gt;

&lt;p&gt;So, this talk aims to be and introduction to the topic and a walkaround
through different approaches followed in CPython and PyPy:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Generational Reference counting with cycles detector on CPython.&lt;/li&gt;
&lt;li&gt;Incremental version of the MiniMark GC on PyPy.&lt;/li&gt;
&lt;/ul&gt;
</abstract>
        <description>&lt;p&gt;As Python programmers we're used to program without taking care about allocating
memory for our objects and later on freeing them, Python garbage collector
takes care of this task automatically for us.&lt;/p&gt;

&lt;p&gt;Garbage collection is one of the most challenging topics in computer science,
there are a lot of research around the topic and different ways to tackle
the problem.&lt;/p&gt;

&lt;p&gt;Knowing how our language does this process give us a better understanding
of underlying interpreter and allow us to know why problems like cycles
can happen in CPython interpreters.&lt;/p&gt;

&lt;p&gt;So, this talk aims to be and introduction to the topic and a walkaround
through different approaches followed in CPython and PyPy:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Generational Reference counting with cycles detector on CPython.&lt;/li&gt;
&lt;li&gt;Incremental version of the MiniMark GC on PyPy.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <persons>
          <person id="2749">Francisco Fernández Castaño</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3112">
        <start>17:00</start>
        <duration>00:25</duration>
        <room>H.1301 (Cornil)</room>
        <slug>redbaron</slug>
        <title>RedBaron</title>
        <subtitle>a bottom up approach to refactoring in python</subtitle>
        <track>Python</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Writing code that modifies source code is a task reserved to a small number of audacious developers. RedBaron was built on the foundations of a Lossless Abstract Syntaxe Tree (AST) and serves to make customized refactoring accessible to as many developers as possible. It does so by offering an abstraction that allows to focus on specific objectives regardless of the low-level details.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;RedBaron's aim is to make the process of writing of code that modifies source code easy (and fun) enough to change it into a manageable, or even desirable, task. To do so, RedBaron acts like BeautifulSoup/JQuery onto your Python source code. The idea is to make it powerful and expressive enough so that it can be directly used into a Python shell like IPython.&lt;/p&gt;

&lt;p&gt;Baron, the basis for RedBaron , is a Syntax Tree for Python meant to preserve every information. In this way, [source code -&gt; tree -&gt; source code] will yield the exact same source code even at the formatting level. Baron is relatively stable; it comprises over 1000 unit tests; it was applied to the top 100 pypi packages; and it is documented. Though still in development, RedBaron is stable and functional. The next step consists in making it enjoyable to use. Around November it comprised more than 1200 unit tests, and was fully documented with numerous examples.&lt;/p&gt;

&lt;p&gt;Source code and documentation:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;RedBaron: https://github.com/psycojoker/redbaron http://redbaron.rtfd.org&lt;/li&gt;
&lt;li&gt;Baron: https://github.com/psycojoker/baron http://baron.rtfd.org&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The ambitious aim of RedBaron is to facilitate the writing of code-writing source code and make this task both realistic and enjoyable.&lt;/p&gt;</description>
        <persons>
          <person id="2490">Laurent Peuch</person>
        </persons>
        <links>
          <link href="http://redbaron.rtfd.org">RedBaron documentation</link>
          <link href="https://github.com/psycojoker/redbaron">RedBaron Github</link>
          <link href="http://baron.rtfd.org">Baron documentation</link>
          <link href="https://github.com/psycojoker/baron">Baron Github</link>
        </links>
      </event>
      <event id="3097">
        <start>17:30</start>
        <duration>00:25</duration>
        <room>H.1301 (Cornil)</room>
        <slug>extending_python,_what_is_the_best_option_for_me</slug>
        <title>Extending Python, what is the best option for me</title>
        <subtitle/>
        <track>Python</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Python is a great language, but there are occasions where we need access to low
level operations or connect with some database driver written in C or we need to
overcome to some speed boottleneck in Python due to some limitation in the
language, like NumPy or Scikit-learn do, using extensions.&lt;/p&gt;

&lt;p&gt;With the FFI(Foreign function interface) we can connect Python with other
languages like C, C++ and even Rust or Fortran.
There are some alternatives to achieve this goal, Native Extensions, Ctypes and CFFI.
We'll compare this three ways of extending Python and we'll study pros and cons
of each approach.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Python is a great language, but there are occasions where we need access to low
level operations or connect with some database driver written in C or we need to
overcome to some speed boottleneck in Python due to some limitation in the
language, like NumPy or Scikit-learn do, using extensions.&lt;/p&gt;

&lt;p&gt;With the FFI(Foreign function interface) we can connect Python with other
languages like C, C++ and even Rust or Fortran.
There are some alternatives to achieve this goal, Native Extensions, Ctypes and CFFI.
We'll compare this three ways of extending Python and we'll study pros and cons
of each approach.&lt;/p&gt;</description>
        <persons>
          <person id="2749">Francisco Fernández Castaño</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3010">
        <start>18:00</start>
        <duration>00:25</duration>
        <room>H.1301 (Cornil)</room>
        <slug>pypy_and_the_future_of_the_python_ecosystem</slug>
        <title>PyPy and the future of the Python ecosystem</title>
        <subtitle/>
        <track>Python</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Python has a great versatile ecosystem but the competition is getting better, this talk is about how can Python keep up with these new languages and where PyPy fits into this.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Recently we've seen the rise of new technologies like Go, Node.js and Julia, those have the ability to build an ecosystem on a clean slate and thus be better than Python in some aspects. What would it take to be as good as those technologies on those aspects without loosing all the things we love about Python ? This talk will describe my perfect future where Python keeps getting better, gets to keep it's great set of libraries and where PyPy fits in that future.&lt;/p&gt;</description>
        <persons>
          <person id="2146">Romain Guillebert</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3470">
        <start>18:30</start>
        <duration>00:30</duration>
        <room>H.1301 (Cornil)</room>
        <slug>lightning_talks</slug>
        <title>Lightning Talks</title>
        <subtitle/>
        <track>Python</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Lightning Talks Session&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Lightning Talks Session&lt;/p&gt;</description>
        <persons>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="H.1302 (Depage)">
      <event id="3516">
        <start>10:30</start>
        <duration>00:05</duration>
        <room>H.1302 (Depage)</room>
        <slug>welcome_to_the_distributions_devroom</slug>
        <title>Welcome to the Distributions Devroom</title>
        <subtitle>A short introduction to the room, the schedule and the team</subtitle>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract></abstract>
        <description></description>
        <persons>
          <person id="2357">Andreas Thienemann</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2969">
        <start>10:35</start>
        <duration>00:20</duration>
        <room>H.1302 (Depage)</room>
        <slug>from_debian_gis_to_osgeo_live_and_back</slug>
        <title>From Debian-GIS to OSGeo live and back</title>
        <subtitle/>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Debian GIS is a project with the goal of making Debian the best distribution for Geographical Information System applications.&lt;/p&gt;

&lt;p&gt;OSGeo live (live.osgeo.org) is a self-contained bootable dvd, usb thumb drive or virtual machine based on Lubuntu, that allows you to try a wide variety of open source geospatial software without installing anything. It also contains a set of uniform documentation (description and quickstarts) to guide people around the different projects.&lt;/p&gt;

&lt;p&gt;Even though OSGeo live is based on the packages in Debian, both projects diverted and where OSGeo live managed to get a large (100+) community of contributors, progress in Debian GIS was stalling. Recently however, a new wind is blowing in Debian GIS (among others with the Debian pure blends initiative) and many changes from OSGeo live are being incorporated back into Debian.&lt;/p&gt;

&lt;p&gt;Apart from presenting both projects I will highlight some problems people encounter when they would like to add their package to Debian GIS, and how Debian pure blends try to solve this.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2381">Johan Van de Wauw</person>
        </persons>
        <links>
          <link href="https://wiki.debian.org/DebianGis">https://wiki.debian.org/DebianGis</link>
          <link href="http://live.osgeo.org/en/index.html">http://live.osgeo.org/en/index.html</link>
        </links>
      </event>
      <event id="2569">
        <start>11:00</start>
        <duration>00:50</duration>
        <room>H.1302 (Depage)</room>
        <slug>nix,_nixos,_nixops</slug>
        <title>Nix, NixOS, NixOps</title>
        <subtitle>From Developing to Provisioning software</subtitle>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Nix is a package manager that provides side-by-side installation of multiple versions of a package, multi-user package management and easy setup of build environments.  This talk highlights how simple features of a package manager can change the way components are developed and deployed.  We will investigate how Nix works and demonstrate how to use it throughout the development life-cycle.  We will create a development environment, configure a system service, deploy to a container for testing and finally deploy a remote system.&lt;/p&gt;</abstract>
        <description>&lt;ul&gt;
&lt;li&gt;Package management:&lt;/li&gt;
&lt;li&gt;Issues: Correctness, Completeness, Interference.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Deployment: Source vs. Binary.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Nix&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Isolation: Hashing build inputs.&lt;/li&gt;
&lt;li&gt;Making build environment.&lt;/li&gt;
&lt;li&gt;Demo: Building a package.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Source &amp;amp; Binary deployment.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;NixOS&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Configuration implies Installation.&lt;/li&gt;
&lt;li&gt;Configuration management &amp;amp; Abstraction.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Demo: Generate configuration files around a service.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;NixOps&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Provisioning a configuration.&lt;/li&gt;
&lt;li&gt;Demo: Testing deployment.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <persons>
          <person id="2318">Nicolas B. Pierron</person>
        </persons>
        <links>
          <link href="http://nixos.org/nix/">Nix - Package Manager</link>
          <link href="http://nixos.org/">NixOS - Linux Distribution</link>
          <link href="http://nixos.org/nixops/">NixOps - Cloud Deployment Tool</link>
        </links>
      </event>
      <event id="3245">
        <start>12:00</start>
        <duration>00:55</duration>
        <room>H.1302 (Depage)</room>
        <slug>upstream_downstream</slug>
        <title>Upstream Downstream</title>
        <subtitle>The relationship between developer and package maintainer</subtitle>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;How is it to be a fairly large project upstream of several Linux
distributions? How is it do be downstream of such a project? Among the
challenges are coordinating between distributions, handling different
expectations from distributions and users, and technical issues such
as making the software easy to package. Using MySQL as the example,
we'll go through several real-life cases and try to see them from both
sides of the developer-maintainer relationship.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;MySQL is the world's most popular open source DBMS, with a large user
base on Linux, Windows, OS X, FreeBSD, Solaris, and others. Besides
direct download from the upstream web site and package repositories,
Linux distributions are the major delivery channels for MySQL. This
talk is based on real-life experiences in the upstream-downstream
relationship between MySQL and the major Linux distributions over the
last few years.&lt;/p&gt;

&lt;p&gt;Among the topics covered are upstream's role in coordinating between
the different distributions, how to handle distributions that deliver
on platforms that are unsupported by upstream, handling bugfixes and
requests for new features in stable releases, and how having an
upstream package repository can improve the quality of packages in the
distributions.&lt;/p&gt;

&lt;p&gt;The target audience is software developers that have or want to have
their software packaged for one or more Linux distribution, package
maintainers in distributions, and end users wanting to understand more
about how Linux distributions are made.&lt;/p&gt;</description>
        <persons>
          <person id="2520">Norvald H. Ryeng</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3514">
        <start>13:00</start>
        <duration>00:55</duration>
        <room>H.1302 (Depage)</room>
        <slug>how_coreos_is_built,_modified,_and_updated</slug>
        <title>How CoreOS is built, modified, and updated</title>
        <subtitle>From repo sync to Omaha. </subtitle>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Traditional Linux distributions are updated via one of two methods: utilizing package managers like RPM, apt, or pacman or good old "config, make, make install."  We will analyze how atomic CoreOS updates are developed, packaged, and distributed in order to sign an image and distribute it to the masses.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2788">Brian 'redbeard' Harrington</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3258">
        <start>14:00</start>
        <duration>00:55</duration>
        <room>H.1302 (Depage)</room>
        <slug>distributions_boring_solved_problem</slug>
        <title>Are distributions really boring and a solved problem?</title>
        <subtitle/>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Recently distributions are often perceived as boring, and working mostly on
solved problems, as the focus is moving away to hype stuff such as
configuration management or the Cloud. However, distributions are in the best
spot to address a number of important challenges -- both old ones that never
had a satisfying solution so far, and arising ones. I will describe ongoing
work on some of those challenges (mainly in Debian), as well as some thoughts
on how we could address other challenges.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The goal of this talk is to review a number of ongoing work in Debian and other distributions, and try to motivate people to work on some important issues. Though centered on Debian due to my experience, I believe that it will be equally valuable for people from other distributions.&lt;/p&gt;</description>
        <persons>
          <person id="2073">Lucas Nussbaum</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3220">
        <start>15:00</start>
        <duration>00:45</duration>
        <room>H.1302 (Depage)</room>
        <slug>the_emacs_of_distros</slug>
        <title>The Emacs of Distros</title>
        <subtitle>How GNU Guix Seeks to Empower Users</subtitle>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;What's with Emacs?  Its design makes user freedom more practical by putting all the mechanics at the user's fingertips.  This talk will explore how GNU Guix and its distribution seek to empower users in a similar way.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Emacs is that extensible, self-documenting "editor" whose very design
empowers users: the whole documentation and source is at their
fingertips, ready to be debugged or changed for immediate effect.  Free
software made practical!&lt;/p&gt;

&lt;p&gt;What about following that Emacs meme for a complete distro?  That's what
the GNU Guix project has been trying to answer.  The project has been
developing a package manager and associated GNU/Linux distribution over
the last two years.  By using a general-purpose implementation language,
Scheme, and by specializing it to offer high-level abstractions, Guix
empowers users by blurring the distinction between packagers and users,
and by offering a uniform, hackable framework.&lt;/p&gt;

&lt;p&gt;The distribution provided by the Guix project pursues similar goals.
Users specify the whole system configuration in a declaration, which is
then instantiated, and may be reproduced on other machines.  The
configuration specifies system-wide settings such as locales and
timezone, host name, file systems, mapped devices, user accounts,
available services, and so on.  It uses GNU dmd, a simple
dependency-based init system written in Scheme.&lt;/p&gt;

&lt;p&gt;This talk is directed at hackers and free software supporters who want
to know more about the implementation and the use of Guix, and how we
hope they can improve the user experience and enhance software freedom.&lt;/p&gt;

&lt;p&gt;We will see how users can fiddle with these foundations without having
to cross barriers imposed by complex C systems and the historical
baggage of a flurry of loosely integrated scripts and tools of varying
languages.  The talk will also demo features that set Guix apart from
many other tools: supports transactional upgrades, rollback, per-user
installations, and more.  Last but not least: Emacs is not the only
editor found in the distro!&lt;/p&gt;</description>
        <persons>
          <person id="2003">Ludovic Courtès</person>
        </persons>
        <links>
          <link href="http://www.gnu.org/software/guix">GNU Guix</link>
          <link href="http://www.gnu.org">GNU operating system</link>
        </links>
      </event>
      <event id="3288">
        <start>15:50</start>
        <duration>00:40</duration>
        <room>H.1302 (Depage)</room>
        <slug>_centos:_community_build_service_and_infrastructure</slug>
        <title> CentOS: Community build service and infrastructure.</title>
        <subtitle>Leveraging existing tools and build workflows for RPM distribution.</subtitle>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;CBS is the community build system for CentOS Special Interest Group members.&lt;/p&gt;

&lt;p&gt;The service allows to build package with Koji, the open source Fedora project, against CentOS 5, CentOS 6 and CentOS 7.
Details for leveraging and adapting existing tools to build RPMs from git repositories will be given.&lt;/p&gt;

&lt;p&gt;The process uncovered challenges about both RPMs building and their final distribution, we will review them, along with solutions and what remains to be done.&lt;/p&gt;

&lt;p&gt;Finally, the supporting infrastructure will be described and key choices highlighted.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;In an agile world, building RPMs and distributing them in a clean and fast way is more and more important for all system administrators.
Providing users with a simple interface and an easy way to deploy test packages, validate their software functionality and finally distribute them is very important.&lt;/p&gt;

&lt;p&gt;Koji is the software that builds RPM packages for the Fedora project. It uses Mock to create chroot environments to perform builds.
"Koji" installation and management will be detailed with a review of needed patches.&lt;/p&gt;

&lt;p&gt;"fedpkg" is the command line software for Fedora developers. It interacts with dist-git, koji, rpmbuild, git.
"centpkg" provides CentOS specific configuration to interact with CBS Koji instance and git.centos.org.
Both tools are based on rpkg ; a python library (pyrpkg) and example runtime script to interact with git repos housing rpm spec files building through koji like build systems.&lt;/p&gt;

&lt;p&gt;An additional challenge is to distribute in well organised repositories the resulting signed RPMs. The adopted process will be detailed,&lt;/p&gt;

&lt;p&gt;An insight in the infrastructure needed for building, distributing and signing will be given.&lt;/p&gt;</description>
        <persons>
          <person id="2831">Thomas Oulevey</person>
        </persons>
        <links>
          <link href="http://wiki.centos.org/HowTos/CommunityBuildSystem">Some documentation about the project</link>
          <link href="http://cbs.centos.org">CBS link</link>
        </links>
      </event>
      <event id="2753">
        <start>16:35</start>
        <duration>00:30</duration>
        <room>H.1302 (Depage)</room>
        <slug>homebrew_the_good,_bad_and_ugly_of_osx_packaging</slug>
        <title>Homebrew - The Good, Bad and Ugly of OSX Packaging</title>
        <subtitle>Some of the things that Homebrew does well, badly and the special challenges that OSX packagers need to deal with.</subtitle>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Homebrew is a popular package manager for OSX. We have a relatively unusual contribution and maintenance model and some practices that differentiate us from other package management systems on both OSX and on Linux. This talk will discuss some of the lessons learnt from maintaining Homebrew to facilitate discussion of how we and other package managers can do better.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The audience for this talk is primarily developers of other package managers and maintainers of Unix distributions. We all do things in slightly different ways so this talk aims to facilitate discussion of what we can do better and how we can work together to minimise repeated work. Audience members will learn about Homebrew, how to encourage more contributions to package managers and how to handle a large number of packages will very few maintainers and time spent.&lt;/p&gt;

&lt;p&gt;The plan would be a 15m somewhat interactive talk with 15m discussion afterwards.&lt;/p&gt;</description>
        <persons>
          <person id="2487">Mike McQuaid</person>
        </persons>
        <links>
          <link href="http://brew.sh">Homebrew homepage</link>
          <link href="https://github.com/Homebrew/homebrew">Homebrew on GitHub</link>
        </links>
      </event>
      <event id="3294">
        <start>17:10</start>
        <duration>00:50</duration>
        <room>H.1302 (Depage)</room>
        <slug>get_more_people_intrested_in_your_distros_users_group</slug>
        <title>Get more people intrested in your distros users group.</title>
        <subtitle>Advice from someone who has tried, failed and tried again.</subtitle>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk will discuss the practical ways that someone who is wanting to grop either a community or a meetup around their project or distro they use. Aimed for developers who might be more into the back end side of things, this talk will attempt to show people ways that are both often overlooked and easy to implement for the both the average user and the experienced developer.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Have you ever wanted to grow your projects community, both at home or on a global scale? This talk will go in depth about the problems most people face when they attempt to grow a users group and discuss the areas that people can easily work on to make their users group, or even community as a whole, be a thriving member of the free software world. If you have thought that running meetups is too much work, and afraid to try, this talk will show how meetings and gatherings can plan themselves, and ultimately become the best way to grow your projects community. I will mainly focus on the Ubuntu users groups I have run in the past and still run today. This will be the place where most of my examples come from and where my information will be from.&lt;/p&gt;</description>
        <persons>
          <person id="1976">Philip Ballew</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3162">
        <start>18:05</start>
        <duration>00:50</duration>
        <room>H.1302 (Depage)</room>
        <slug>making_an_lts_distro_with_gentoo_prefix</slug>
        <title>Making an LTS distro with Gentoo Prefix</title>
        <subtitle>at Salomon Automation - a case study.</subtitle>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Why Salomon Automation GmbH has need for Gentoo Prefix.
How to provide an LTS distro based on Gentoo Prefix.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;In this lecture, after telling about why Salomon Automation GmbH needs something like Gentoo Prefix,
and a short overview of the differences between Gentoo Linux and Gentoo Prefix,
I'll show how we manage to combine the rolling distribution concept of Gentoo with the Long-Term Support concept.&lt;/p&gt;</description>
        <persons>
          <person id="1664">Michael Haubenwallner</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3517">
        <start>18:55</start>
        <duration>00:05</duration>
        <room>H.1302 (Depage)</room>
        <slug>see_you_tomorrow</slug>
        <title>See you tomorrow</title>
        <subtitle>Closing remarks for the first day of the Distributions Devroom</subtitle>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Please do share your impressions of the first day at the distributions devroom.
What was great, what can be improved?
What would you like to see in the future?&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2357">Andreas Thienemann</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="H.1308 (Rolin)">
      <event id="3392">
        <start>11:00</start>
        <duration>00:05</duration>
        <room>H.1308 (Rolin)</room>
        <slug>welcome</slug>
        <title>Welcome to the Legal and Policy Issues Devroom</title>
        <subtitle/>
        <track>Legal and policy issues</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Now in its fourth year, the FOSDEM Legal and Policy Issues DevRoom covers topics of licensing, legal, governance issues, and more as it relates to Open Source and Free Software projects.&lt;/p&gt;

&lt;p&gt;Attendees are welcome to come and engage in lively debate with our excellent speakers. Please come with your questions, comments or concerns. The DevRoom talks are carefully chosen to avoid merely being introductory: we believe that FOSDEM attendees are well informed on these issues, and we welcome participation for all. Our goal in organizing this DevRoom is to bring the previously secretive and non-public discussion on these sorts of issues to a public forum.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="418">Tom Marble</person>
          <person id="441">Bradley M. Kuhn</person>
          <person id="448">Karen Sandler</person>
          <person id="583">Richard Fontana</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2804">
        <start>11:05</start>
        <duration>00:40</duration>
        <room>H.1308 (Rolin)</room>
        <slug>opensourcebydesign</slug>
        <title> Open Source by Design</title>
        <subtitle/>
        <track>Legal and policy issues</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;It’s time for GitHub to focus on helping oss thrive. Our "Open Source by Design" project includes three steps. The first step is set to wisely alter the “no license” default, and is based on data we’ve purposefully accumulated. The second step aims to create governance templates that prevent problems that hamper projects. The third step is a new service to help projects comply with license requirements of third party code. The final part of the plan is the project's evaluation metrics.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;GitHub recognizes that it has a role in the development of open source code. For starters, and as a platform, GitHub obviously hosts a great deal of it. As a product, GitHub's primary and presumed workflow is like that of an open source project, with loose or disaggregated networks of project maintainers, contributors, and users. And even as a corporation, GitHub has at times attempted to organize itself according to open source models, experimenting with non-coercive, collaborative, and geographically disparate structures of corporate organization.&lt;/p&gt;

&lt;p&gt;GitHub's internal legal counsel wishes to discuss what GitHub can do to help existing open source projects thrive, to support new projects and new contributors, and to promote the development of the open source community. More specifically, and given GitHub's unique vantage point, GitHub Legal is working on projects utilizing tools of governance and process to contribute to open source in new ways. We wish to present the details of an "Open Source by Design" project in four parts.&lt;/p&gt;

&lt;p&gt;The first part relates to altering the default understanding as to what it means for a project to be hosted without an explicit license on GitHub. We show why we need to tread with care when we alter this default, which data we are collecting that is intended to help us choose the new default wisely, and where that data seems to lead.&lt;/p&gt;

&lt;p&gt;Our second part aims to help introduce governance infrastructure to open source projects in order to solve problems that such projects may some day face. We place particular focus on problems that, in GitHub's experience, often hamper open source projects as they transition along some relevant axis, be it user makeup, maintainer makeup, rate of adoption, commercial developments, design disputes, ownership disputes or the like. We believe that by developing and offering some measure of template governance structures, much confusion and many challenges that bedevil open source projects may be avoided.&lt;/p&gt;

&lt;p&gt;We are sensitive to the potential side-effects of such a project, such as the stifling of alternate project organization and governance models. Another interesting aspect of study would be to what extent, if any, such bottom-up models of project self-governance would influence, supplement, or even act take on the role of law as they themselves became subject to things like increased adoption and standardization. This question seems particularly relevant in areas where formal legislative intervention is light.&lt;/p&gt;

&lt;p&gt;The third part of an "Open Source by Design" project would be a new compliance service that aims to help projects comply with license requirements of third party code that they use, to avoid license inconsistencies where they actually occur and flags preventing the neglect of licensing.&lt;/p&gt;

&lt;p&gt;Finally, we've given much thought to the metrics by which we would gauge the success of the different steps of this project once implemented and that could help us plan the second stage of the project.&lt;/p&gt;</description>
        <persons>
          <person id="2905">Julio Avalos</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2798">
        <start>11:45</start>
        <duration>00:25</duration>
        <room>H.1308 (Rolin)</room>
        <slug>appstores</slug>
        <title>Copyleft licenses and the appstores</title>
        <subtitle/>
        <track>Legal and policy issues</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk is an overview of the current compatibility of the various app stores with the major copyleft licenses.&lt;/p&gt;

&lt;p&gt;I will then speak about the technical limitations of what those platforms impose on application licenses.
I will also cover license strategies to have cross-platform FLOSS applications distributed on those app stores.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;This talk is an overview of the current compatibility of the various app stores (Apple App Store, Google Play Store, Windows Store, BB, etc...) with the major copyleft licenses.&lt;/p&gt;

&lt;p&gt;I will then speak about the technical limitations of what those platforms impose on application licenses, notably on Android, where a large part of the userland is licensed under Apache 2.&lt;/p&gt;

&lt;p&gt;I will also cover license strategies to have cross-platform FLOSS applications distributed on those app stores, if one would like to do it.&lt;/p&gt;

&lt;p&gt;Most of the information gathered here are based on the work we did on VLC to get it running on numerous mobile platforms.&lt;/p&gt;</description>
        <persons>
          <person id="2538">Jean-Baptiste Kempf</person>
        </persons>
        <links>
          <link href="http://www.jbkempf.com/blog/">JBKempf Blog</link>
        </links>
      </event>
      <event id="2999">
        <start>12:15</start>
        <duration>00:25</duration>
        <room>H.1308 (Rolin)</room>
        <slug>spdx</slug>
        <title>SPDX: Debunking the myths and misunderstandings</title>
        <subtitle/>
        <track>Legal and policy issues</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The SPDX specification is a standard format for communicating the components, licenses, and copyrights associated with a software package. Despite that relatively simple explanation, myths and misunderstandings seem to abound as to what SPDX does and does not do; whom benefits from SPDX and how; and more. This talk will address some of the commonly heard myths and misunderstandings.&lt;/p&gt;

&lt;p&gt;This talk will also describe the key changes accompanying the upcoming official release of SPDX 2.0.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2690">Jilayne Lovejoy</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2677">
        <start>12:45</start>
        <duration>00:40</duration>
        <room>H.1308 (Rolin)</room>
        <slug>crypto</slug>
        <title>Crypto Wars 2.0 and the Free Software Response</title>
        <subtitle/>
        <track>Legal and policy issues</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Recent revelations about the scope of government surveillance have touched off renewed interest in encryption and personal data privacy, and prompted technology companies to offer more protections for users' data. In response, the U.S. government has made moves toward increased regulation of encryption software. This talk will discuss the laws regulating surveillance and cryptography, how those laws apply to free software, and opportunities for community response to the new crypto wars.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2402">Aaron Williamson</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2815">
        <start>13:30</start>
        <duration>00:25</duration>
        <room>H.1308 (Rolin)</room>
        <slug>mozillaid</slug>
        <title>Mozilla ID - Developing and protecting a living brand</title>
        <subtitle/>
        <track>Legal and policy issues</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;I propose to introduce the audience to Mozilla's new brand project Mozilla ID. Mozilla ID is a very new project, launched in August 2014 and headed by Mozilla's art director Sean Martell. Mozilla ID aims at developing the core pillars for a new, living Mozilla brand, consisting of a word mark and logo. Mozilla's aim with the project is to allow unlimited variants of the Mozilla logo which will be based on live community data. There will be a logo generator that Mozilla is currently working on where contributors can select the data feeds and colors and it will output SVG versions of the logo for use. People will be able to customize the look based on the options they choose. Effectively, the openness and community contribution that is at the core of Mozilla's software projects will be transferred also to its branding, enhancing community identification on that additional level.&lt;/p&gt;

&lt;p&gt;I will first of all introduce the project and will show images to illustrate the ongoing creative development process led by Sean Martell.&lt;/p&gt;

&lt;p&gt;Moving on to the protection angle: I will speak about traditional patterns of trademark protection and enforcement and how these are being challenged by the market and marketing realities of our modern times. I will speak about the advantages and appeal of living, or fluid, brands, giving examples (such as Google doodle, MTV, Absolut Vodka, to name but a few).  I will point out risks and provide guidance on how a living brand can bridge the divide between valuable community contribution and identification and the restrictions of trademark protection. Essentially, a living brand can have a steady distinctive core which suffices to maintain trademark protection, while certain of its characteristics may be subject to change, community contribution and innovation. The key challenge is to define the core that is to be the subject of trademark protection, without unduly restricting the process of innovation that makes the brand a living brand.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2552">Anthonia Ghalamkarizadeh</person>
        </persons>
        <links>
          <link href="http://www.marques.org/Class46/Default.asp">Active member of the Marques team of trademark bloggers</link>
          <link href="http://lwn.net/Articles/546678/">Talk at fsfe 2013 on Mozilla's trademark enforcement</link>
          <link href="http://www.hoganlovells.de/de/tmt-news-september-2013-10-10-2013/">Discussion of a decision of the District Court of Hamburg on the license conditions of the open source software "netfilter/iptables"</link>
          <link href="http://www.hoganlovells.com/intellectual-property-newsletter---december-2013-12-24-2013/">Regular publications in Hogan Lovells' IP Newsletter</link>
        </links>
      </event>
      <event id="2821">
        <start>14:00</start>
        <duration>00:50</duration>
        <room>H.1308 (Rolin)</room>
        <slug>gnome</slug>
        <title>Fog of War - The GNOME Trademark Battle</title>
        <subtitle/>
        <track>Legal and policy issues</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The backstory of one of the most remarkable trademark battles in Free Software in recent times.  Sri Ramkrishna, Director of the GNOME Foundation and Pamela Chestek, GNOME's trademark counsel will talk about the remarkable 24 hours in a public fundraiser that and the events leading up it.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;GNOME's public fundraiser to fight for its trademark will go down as one of the most successful operations by a Free Software project and expression of the political power of the Free Software community.  Join Pamela Chestek, GNOME's trademark legal counsel and Sri Ramkrishna, Director of GNOME Foundation and learn how events unfold and how a single tweet started a campaign that ended so remarkably.&lt;/p&gt;</description>
        <persons>
          <person id="1245">Pamela Chestek</person>
          <person id="2560">Sri Ramkrishna</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2747">
        <start>15:00</start>
        <duration>00:40</duration>
        <room>H.1308 (Rolin)</room>
        <slug>samba</slug>
        <title>Why Samba moved to GPLv3</title>
        <subtitle>Why we moved, what we gained, what we lost.</subtitle>
        <track>Legal and policy issues</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk will cover the reasons Samba moved license from GPLv2+ to GPLv3+, what we gained as a community out of it, and also the downsides we have experienced from the decision. This talk should interest any project thinking of moving to GPLv3 from an existing license, and also projects considering a new license.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;This talk will cover the reasons Samba moved license from GPLv2+ to GPLv3+, what we gained as a community out of it, and also the downsides we have experienced from the decision. This talk should interest any project thinking of moving to GPLv3 from an existing license, and also projects considering a new license.&lt;/p&gt;</description>
        <persons>
          <person id="1103">Jeremy Allison</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2810">
        <start>15:45</start>
        <duration>00:25</duration>
        <room>H.1308 (Rolin)</room>
        <slug>copyleft_in_europe</slug>
        <title>Copyleft in Europe: How does copyleft interact with Exhaustion Of Rights</title>
        <subtitle>To what extent can a copyright owner control copyleft code once it's placed in circulation in the EEA?</subtitle>
        <track>Legal and policy issues</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Copyleft licences work by conditioning distribution of a work's binary on providing access to relevant source code. Under the European Computer Programs directive, once a copy of a computer program has been placed in circulation in the EEA by or with the consent of the copyright holder, the copyright holder can no longer control circulation ("exhaustion of rights"). Is the condition to provide source an attempt to control circulation, and is the exhaustion principle problematic for the GPL and other copyleft licences? Commentators have suggested that this is fatal to copyleft, but we argue these analyses are overblown.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1244">Amanda Brock</person>
          <person id="2547">Andrew Katz</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3393">
        <start>16:15</start>
        <duration>00:40</duration>
        <room>H.1308 (Rolin)</room>
        <slug>legal_best_practices</slug>
        <title>Towards legal criteria for best practices in free software/open source development</title>
        <subtitle/>
        <track>Legal and policy issues</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk will propose several ideas for inclusion in a set of modern
legal standards for good practices in FLOSS development and governance
beyond the traditional emphasis on software freedom-conformant source
code licensing. The theme will be maximizing diverse, egalitarian and
authentically meritocratic participation, minimizing legal
impediments, and avoiding distortion or corruption by powerful project
stakeholders. Ideas to be discussed include distributed and
symmetrical copyright licensing, fair trademark policies, appropriate
approaches to patent nonassertion by corporate participants, and
commitments by projects or associated foundations to promoting diverse
and safe environments for development work.&lt;/p&gt;

&lt;p&gt;Ideas discussed in this talk may form the basis for work done by the
Open Source Initiative during the coming year.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;It was traditionally assumed that licensing of source code under a
free software/open source license, with its basic forkability
guarantee, was sufficient for software to &lt;em&gt;be&lt;/em&gt; free. More recently,
some have suggested that source code licensing criteria is
insufficient to capture what is truly normative in the development and
governance of FLOSS projects, but no settled view on what constitutes
"open development" or "good FLOSS governance" has yet emerged.&lt;/p&gt;

&lt;p&gt;While some ideas that have been suggested for defining so-called "open
development" and good project governance focus on technical criteria,
this talk will discuss those that are essentially legal in nature, and
the policy justifications for their inclusion. At root these concern
the desire to maximize diverse participation on an egalitarian and
authentically meritocratic basis with a minimum of legal or other
structural impediments, and an avoidance of distorting or corrupting
influence by relatively powerful or influential project participants
or governance stakeholders.&lt;/p&gt;

&lt;p&gt;Important examples of such legal criteria include distributed
copyright ownership coupled with symmetrical inbound/outbound
licensing, as well as community fairness in trademark policy
formulation and the arguable need for external mechanisms of patent
nonassertion for projects dominated by corporate contribution. I will
also argue that it is an essential legal feature of good governance
for projects or their affiliated foundations to affirmatively prevent
or police abusive or exclusionary behavior by project participants.
Some focus will be placed on problems presented by large-scale,
well-known projects that receive significant corporate participation.&lt;/p&gt;</description>
        <persons>
          <person id="583">Richard Fontana</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2844">
        <start>17:00</start>
        <duration>00:25</duration>
        <room>H.1308 (Rolin)</room>
        <slug>patents</slug>
        <title>Software Patent Litigation Data: What Have We Learned? </title>
        <subtitle/>
        <track>Legal and policy issues</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The huge increase in software patent litigation over the last 15 years has produced reams of articles, cost fortunes and even snagged the US President's attention. But when something goes on for long enough, it also produces data -- lots and lots of data. So what have we learned from all the data?&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The huge increase in software patent litigation over the last 15 years has produced reams of articles, cost fortunes and even snagged the US President's attention. But when something goes on for long enough, it also produces data -- lots and lots of data. So what have we learned from all the data?&lt;/p&gt;

&lt;p&gt;Non-practicing entities are growing and litigation costs increase each year, but that's hardly the whole story. Even as defensive strategies are proliferating, software patent plaintiffs are becoming much more sophisticated. Software patent trolls are expanding their reach internationally and practicing entities are increasingly embracing troll-like behavior. Ms. Nicholson will examine data from academic and industrial sources to see what it all means for Linux, Android, GNU and the rest of the free software community. More data provides more opportunities to defend free software from the pernicious effects of vague and overly broad software patent aggression, as long as we are willing to use it.&lt;/p&gt;</description>
        <persons>
          <person id="698">Deb Nicholson</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2812">
        <start>17:30</start>
        <duration>00:40</duration>
        <room>H.1308 (Rolin)</room>
        <slug>fork_and_ignore</slug>
        <title>Fork and Ignore: Fighting a GPL Violation By Coding Instead</title>
        <subtitle>The Story of Kallithea</subtitle>
        <track>Legal and policy issues</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Typically, GPL enforcement activity involves copyright infringement actions which compel license violators to correct errors in their GPL compliance,thus yielding the policy goals of the GPL: the rights of developers and users to copy, share, modify and redistribute.&lt;/p&gt;

&lt;p&gt;While traditional enforcement is often undeniably necessary for embedded electronics products, novel approaches to GPL violations are often possible and even recommended for more traditional software distributions.&lt;/p&gt;

&lt;p&gt;Recently, Conservancy engaged in an enforcement action whereby,rather than fight the violator in court, Conservancy instead fostered and provide resources and assistance to a vetted GPL-compliant fork of a violating codebase.&lt;/p&gt;

&lt;p&gt;This talk discusses which scenarios make this remedy optimal and lessons learned. The talk includes some licensing and technical content about vetting licensing information of codebases.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="441">Bradley M. Kuhn</person>
        </persons>
        <links>
          <link href="http://ebb.org/bkuhn/talks/LinuxCon-North-America-2014/kallithea.html">Slides from an earlier version of this talk</link>
        </links>
      </event>
      <event id="2791">
        <start>18:15</start>
        <duration>00:40</duration>
        <room>H.1308 (Rolin)</room>
        <slug>termination</slug>
        <title>Discrimination &amp; Reciprocity</title>
        <subtitle>Termination Clauses in FOSS and FRAND Licenses</subtitle>
        <track>Legal and policy issues</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Termination provisions are a standard component of license agreements. FOSS licenses and FRAND commitments, however, are not standard agreements, as they are founded on ideals of non-discrimination. Termination clauses, which permit licensors to cancel rights of specific licensees, contradict these ideals. The talk will clarify the contradictions between these principles and license termination provisions, explain why termination provisions are nonetheless justified in these models, and illustrate these explanations by reference to a number of current debates.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;A fundamental principle of FOSS and FRAND licensing is that the rights under the license must be made available to all end users or willing licensees. The Open Source Definition, for example, expressly provides that open source licenses must not “restrict any party” from redistributing the licensed software, and that such licenses cannot “discriminate against any person or group of persons”. The principles of FRAND licenses are perhaps less sharply defined, but the “ND” in FRAND also imposes a similar requirement of “non-discrimination”.&lt;/p&gt;

&lt;p&gt;Notwithstanding these principles, many FOSS licenses provide that licensees that breach the terms of the license can have their rights terminated. FOSS and FRAND licenses may also include “defensive termination” provisions, which allow for the termination of rights in retaliation for patent infringement suits. Such provisions allow licensors to discriminate against specific and identifiable licensees by revoking previously granted rights. Typically, according to these provisions, once a licensee’s rights are terminated the licensor has no obligation to reinstate these rights. Even if the licensor does agree to reinstate the licensee’s rights, the licensor may discriminate against the licensee by imposing restrictions or obligations that would not be permitted under the original terms of the license.&lt;/p&gt;

&lt;p&gt;One could imagine an alternative means of structuring FOSS and FRAND licenses that, in hewing more closely to standards of non-discrimination, would not include termination provisions. Licensors would perhaps be required to allow licensees to continue exercising their rights, even as the licensor brings suit against the licensee for copyright infringement or breach of the license. Licensors would not be allowed to impose additional obligations on a licensee in exchange for the reinstatement of license rights.&lt;/p&gt;

&lt;p&gt;The talk will advance several explanations of why termination provisions are nonetheless a justified breach of the non-discrimination principles in FOSS and FRAND licenses. Such explanations will include a discussion of the basic principles of non-discrimination and reciprocity in FOSS licenses and FRAND commitments, an analysis of possible remedies available to licensors aside from termination, and an exploration of the legal risks to licensors and licensees of not including termination provisions in the license. The talk will also illustrate the tensions between termination provisions and non-discrimination principles by reference to a number of current debates.&lt;/p&gt;</description>
        <persons>
          <person id="2534">Eli Greenbaum</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="H.1309 (Van Rijn)">
      <event id="3147">
        <start>10:30</start>
        <duration>01:00</duration>
        <room>H.1309 (Van Rijn)</room>
        <slug>constructive_conversation</slug>
        <title>How to have a constructive conversation about awful infrastructure code</title>
        <subtitle/>
        <track>Configuration management</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Now that expressive infrastructure as code models nearly everything in the datacenter, we have a different problem — weeding out bad infrastructure code! Quality coding practices aren’t new but most operations teams are learning them for the first time. This talk will offer guidance on how to identify various facets of infrastructure code quality. Though examples are offered in the Puppet DSL, this talk is designed for anyone using configuration management software to manage infrastructure and applications.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Now that expressive infrastructure as code models nearly everything in the datacenter, we have a different problem — weeding out bad infrastructure code! Quality coding practices aren’t new but most operations teams are learning them for the first time. The Puppet Forge’s product manager Ryan Coleman will discuss what he’s learned from the thousands of examples available on Forge. Though examples are offered in the readable Puppet DSL, this talk is designed for anyone using configuration management software to manage infrastructure and applications. No knowledge of Puppet is required to learn from this session.&lt;/p&gt;

&lt;p&gt;Ryan has been knee-deep in infrastructure code for 4 years, starting as a user of Puppet at Penn State and moving on to manage the Puppet Forge at Puppet Labs, a shared repository for great (and not so great) infrastructure as code written in the Puppet DSL. He’ll cover how to identify various quality characteristics and why they matter in your day to day. It’s not just about conforming to a style and aligning your braces! After this talk, you should be equipped to have a conversation with your team about how to collectively improve the code base and reduce long-term maintenance.&lt;/p&gt;</description>
        <persons>
          <person id="1896">Ryan Coleman</person>
        </persons>
        <links>
          <link href="http://forge.puppetlabs.com">Puppet Forge</link>
        </links>
      </event>
      <event id="2970">
        <start>11:30</start>
        <duration>01:00</duration>
        <room>H.1309 (Van Rijn)</room>
        <slug>better_devops</slug>
        <title>Better Devops through Thievery</title>
        <subtitle>Effective Practices for Infrastructure as Code</subtitle>
        <track>Configuration management</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The advent of Infrastructure as Code (IaC) has radically changed how IT
infrastructure is built and maintained. Instead of building and maintaining
servers by hand, tools like Puppet can be used to describe and automatically
configure entire data centers.&lt;/p&gt;

&lt;p&gt;The implication of this is that the workflow of IT operations is starting to
resemble the workflow of a traditional software developer. Writing code to
make infrastructure changes instead of directly making changes opens up new
opportunities for how changes can be made. The software development field has
had 30+ years to learn how to effectively develop code, and their hard won
wisdom can be ripped off wholesale to make it a breeze to develop IaC.&lt;/p&gt;

&lt;p&gt;This talk will discuss the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Using version control tools to more effectively administer infrastructure&lt;/li&gt;
&lt;li&gt;Writing and using tests to confidently make changes and get feedback earlier&lt;/li&gt;
&lt;li&gt;Using continuous integration services to test changes and run deployments&lt;/li&gt;
&lt;/ul&gt;
</abstract>
        <description></description>
        <persons>
          <person id="2673">Adrien Thebo</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3316">
        <start>12:30</start>
        <duration>00:50</duration>
        <room>H.1309 (Van Rijn)</room>
        <slug>interfacing_infrastructure</slug>
        <title>Interfacing infrastructure as code with non-expert users</title>
        <subtitle/>
        <track>Configuration management</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Implementing a tool to automate IT infrastructure management has many undeniable benefits. But that doesn't mean there aren't some drawbacks too (usually outweighed by the benefits) that we should be considering, and working to reduce or remove.&lt;/p&gt;

&lt;p&gt;Implementing a tool like this in a team usually has a pretty significant impact: new processes, new language(s) to learn, new way of doing pretty much everything on your infrastructure. These tools are complex, so a minority of the team tends to become experts in it, and tries to lead the others. Resistance to change is common and understandable, but unfortunately, this can end up with some of the team members being left behind by the sudden and massive changes to their work. This is clearly not a Good Thing, and certainly not showing very good inclusiveness towards everyone. It is also making some configuration management projects fail, which is definitely a Bad Thing for those of us trying to implement them.&lt;/p&gt;

&lt;p&gt;How to improve this situation is a topic dear to me. This has always been the focus of the Rudder and ncf open source projects I work on - making our technologies more accessible, easier to adopt and simpler to understand. Some key points we have focused on include:
- Avoiding the &lt;em&gt;necessity&lt;/em&gt; to write code (user interfaces of course, but that can be combined with other users writing code)
- Separating roles so that experts can implement the &lt;em&gt;how&lt;/em&gt; and others can focus on the &lt;em&gt;what&lt;/em&gt;
- Minimising the amount of effort required (sane and non-surprising default values, auto-configuration where possible, ...)&lt;/p&gt;

&lt;p&gt;This talk will explain some of these concepts, and show how we have achieved considerable success using the ""ncf builder"" web interface that can be used to write configuration management policy without writing any code (see http://www.ncf.io).&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2848">Jonathan Clarke</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2661">
        <start>13:30</start>
        <duration>00:30</duration>
        <room>H.1309 (Van Rijn)</room>
        <slug>consul_first_steps</slug>
        <title>Consul first steps</title>
        <subtitle>Learning Service Discovery</subtitle>
        <track>Configuration management</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Consul is a Service discovery tool created by Hashicorp, in this talk I will guide the audience through the basics of its functionality and how to take the best out of it.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Consul is a Service discovery tool created by Hashicorp, in this talk I will guide the audience through the basics of its functionality and how to take the best out of it.
The talk will be composed of the following parts:
1- What is Service Discovery
2- What is Consul
3- Consul components
4- How does it fit in your platform (cloud, docker, hardware)
5- Advanced functionality
6- Extra modules&lt;/p&gt;</description>
        <persons>
          <person id="1729">Marc Cluet</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3188">
        <start>14:00</start>
        <duration>00:50</duration>
        <room>H.1309 (Van Rijn)</room>
        <slug>contributing_foreman</slug>
        <title>Contributing to Foreman: where and how</title>
        <subtitle/>
        <track>Configuration management</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The Foreman project and its community is varied, big, and it can take very long to understand what is really going on. Luckily, a group of people is actually working full-time on making it a better project. Contributors often scratch their own itches, and move on.&lt;/p&gt;

&lt;p&gt;This talk is meant to give you an overview about areas of Foreman that badly need help, refactoring, and some of the efforts the Foreman community is doing to mitigate technical debt and keep on improving. In short, we want to highlight our flaws so you can target your efforts to the right place.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The Foreman project and its community is varied, big, and it can take very long to understand what is really going on. Luckily, a group of people is actually working full-time on making it a better project. Contributors often scratch their own itches, and move on.&lt;/p&gt;

&lt;p&gt;This talk is meant to give you an overview about areas of Foreman that badly need help, refactoring, and some of the efforts the Foreman community is doing to mitigate technical debt and keep on improving. In short, we want to highlight our flaws so you can target your efforts to the right place.&lt;/p&gt;</description>
        <persons>
          <person id="2413">Daniel Lobato</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3323">
        <start>15:00</start>
        <duration>01:00</duration>
        <room>H.1309 (Van Rijn)</room>
        <slug>healthy_community</slug>
        <title>Is your community healthy? Metrics on the top CM software</title>
        <subtitle/>
        <track>Configuration management</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In this talk, I'll illustrate and analyze the health of the top configuration-management software, as well as making data-driven predictions and looking at major showstoppers. I'm going to draw comparisons across communities as well as within them, to make it clear where the critical mass and acceleration are.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Drawing on data from a wide variety of sources like GitHub, Stack Overflow, bug trackers, external modules, and mailing lists, I'll illustrate and analyze the health of the top configuration-management software. By looking at historical data, we can also make some rough predictions about future directions as well as pitfalls to avoid. I'll draw comparisons across communities like Puppet, Chef, CFEngine, Ansible, and SaltStack to help you understand where things stand today and where they're headed in the future.&lt;/p&gt;</description>
        <persons>
          <person id="840">Donnie Berkholz</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3312">
        <start>16:00</start>
        <duration>01:00</duration>
        <room>H.1309 (Van Rijn)</room>
        <slug>juju_orchestration</slug>
        <title>Orchestration of Services with Juju</title>
        <subtitle>How to orchestrate any machine or cloud with Juju</subtitle>
        <track>Configuration management</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Orchestration is a hot topic today. Juju has been tackling the issue of orchestration for the past four years. In this talk we'll cover how Juju handles orchestration, how Juju can fit in to your existing stack, and demonstrate how Juju can orchestrate common deployments.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2012">Marco Ceppi</person>
        </persons>
        <links>
          <link href="http://juju.ubuntu.com">Homepage</link>
          <link href="http://jujucharms.com">Charms!</link>
        </links>
      </event>
      <event id="2857">
        <start>17:00</start>
        <duration>01:00</duration>
        <room>H.1309 (Van Rijn)</room>
        <slug>consuming_foss_configuration</slug>
        <title>Consuming Open Source Configuration</title>
        <subtitle> Infrastructure and configuration is now code, and some of it is open source. What is it like to be downstream of one of these projects?</subtitle>
        <track>Configuration management</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Infrastructure and configuration are now being represented as code. This code is then put into git repositories, OSI approved licenses are attached, and the code published. This creates an Open Source project. There are several instances of this now: OpenStack, Mozilla, Wikimedia, and Jenkins all have open sourced their infrastructure. It is, however, relatively easy to say "our configuration is totally open source, anyone can use it", and it is actually much harder to actively consume someone else's configuration. My team consumes one of these open source configuration projects and sits downstream from it. I will present on we're doing, what has worked, what hasn't, and what we're going to do next. I'm going to give actionable advice for people who are consuming or want to be consuming another organization's open source infrastructure, and I'll be providing some feedback to those who are currently open sourcing their infrastructure on how to make it easier to consume.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;OpenStack's infrastructure team has an open source infrastructure primarily using the Puppet configuration management tool. Using hiera they are able to separate secrets from puppet code, and using roles they can keep OpenStack specific logic from generically reusable configuration. The infrastructure is multifaceted but the core of it is gerrit for code review, cgit for code checkout, zuul for merging/gating, jenkins and gearman for testing with apache, mysql, and zmq doing what they do best.&lt;/p&gt;

&lt;p&gt;My team at HP consumes this open source infrastructure and replicates it internally. We use their Puppet code, and do the dance of the downstream: patch/submit patch upstream/reconsume patch after it has landed upstream. We call the project Gozer and our admins are called Ghostbusters. We attend the weekly meeting that upstream holds, and some of us are well on our way to having our upstream commit bits, but our core focus is on maintaining the downstream ci/cd pipeline for HP.
Configuration management is the reason any of this is possible. I'm going to talk about specific ways Puppet code can be written to be re-consumable, and highlight a couple 'dead ends' we walked down before finding some successful patterns.&lt;/p&gt;

&lt;p&gt;In this presentation I will cover:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;The problems upstream is solving, the problems downstream is solving, where those goals align and where they differ

How we bootstrapped our infrastructure(and why that was a problem)

How we participate upstream

How the Puppet codebase has evolved to be more consumable, where it started, and where it is now

How we dealt with different network topology between our infrastructure and upstream's infrastructure

How we maintain parity with upstream (consistently consuming it)

How we consume data, not just code

Answer questions
&lt;/code&gt;&lt;/pre&gt;</description>
        <persons>
          <person id="2343">Spencer Krum</person>
        </persons>
        <links>
          <link href="http://ci.openstack.org/">Upstream open source ifnra</link>
        </links>
      </event>
      <event id="2965">
        <start>18:00</start>
        <duration>00:30</duration>
        <room>H.1309 (Van Rijn)</room>
        <slug>public_puppet</slug>
        <title>The open source OpenStack project infrastructure</title>
        <subtitle>Fully public Puppet</subtitle>
        <track>Configuration management</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The OpenStack Infrastructure team manages a fully open source infrastructure which includes a continuous integration system, as well as tools OpenStack developers around the world use on a day to day basis. This includes the OpenStack wiki, IRC bots, Etherpad, ELK stack and more.&lt;/p&gt;

&lt;p&gt;This talk will explain how we've open sourced all of our configuration with Puppet and challenges faced by both our team and downstream consumers of our infrastructure.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2671">Elizabeth K. Joseph</person>
        </persons>
        <links>
          <link href="http://ci.openstack.org">OpenStack CI Documentation</link>
        </links>
      </event>
      <event id="2669">
        <start>18:30</start>
        <duration>00:30</duration>
        <room>H.1309 (Van Rijn)</room>
        <slug>monitoring_service</slug>
        <title>Monitoring As A Service</title>
        <subtitle/>
        <track>Configuration management</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Building a modern monitoring environment is more than just using the latest awesome tools, collecting all of the data, displaying numerous graphs and knowing when things go wrong. A modern monitoring environment is more than tools and infrastructure. It's a service. A service you provide to your whole team: developers, operations, security, and the business. This talk is about how you can build monitoring environments (or extend your existing environment) that are customer-focussed rather than infrastructure focussed. We'll see how you can treat your needs and the needs of your organization as customer requirements and build monitoring that is consumable and configurable on demand.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Building a modern monitoring environment is more than just using the latest awesome tools, collecting all of the data, displaying numerous graphs and knowing when things go wrong. A modern monitoring environment is more than tools and infrastructure. It's a service. A service you provide to your whole team: developers, operations, security, and the business. This talk is about how you can build monitoring environments (or extend your existing environment) that are customer-focussed rather than infrastructure focussed. We'll see how you can treat your needs and the needs of your organization as customer requirements and build monitoring that is consumable and configurable on demand.&lt;/p&gt;

&lt;p&gt;We'll focus on:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What does monitoring as a service look like?&lt;/li&gt;
&lt;li&gt;How do we move to a customer-driven service?&lt;/li&gt;
&lt;li&gt;What tooling do we need to build, change or extend?&lt;/li&gt;
&lt;li&gt;How does this change how your monitoring environment operates?&lt;/li&gt;
&lt;li&gt;What new components and metrics do we need to collect and measure?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;By the end of the talk you should be able to build a plan to make your monitoring available as a service to anyone in your organization.&lt;/p&gt;</description>
        <persons>
          <person id="13">James Turnbull</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="H.2213">
      <event id="3161">
        <start>10:30</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>mediafloss</slug>
        <title>How to make professional media users care about FOSS</title>
        <subtitle/>
        <track>Open media</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Many professional users at broadcasters and other institutions want to use FOSS but at the same time in the eyes of others FOSS doesn't get the respect it deserves for a variety of technical and social reasons. This presentation will look at some examples of how this can be improved using examples from the speaker's experience where FOSS is used for mission critical uses, mostly in compression but also in other areas.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2514">Kieran Kunhya</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2954">
        <start>11:00</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>mmbtools</slug>
        <title>ODR-mmbTools Digital Radio Development</title>
        <subtitle>Digital Radio tools. Latest News on the Software Side of Things</subtitle>
        <track>Open media</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The ODR-mmbTools is a collection of tools that can be used to generate a Digital Audio Broadcasting signal through Software-Defined Radio. These tools are used in a 24/7 production setup in Switzerland.&lt;/p&gt;

&lt;p&gt;I have been working on improving them since my studies, and present here the current state of these tools and a small outlook on future work.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2657">Matthias P. Brändli</person>
        </persons>
        <links>
          <link href="http://opendigitalradio.org">Opendigitalradio</link>
        </links>
      </event>
      <event id="3076">
        <start>11:30</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>subtitling</slug>
        <title>Open source tools for new subtitle standards</title>
        <subtitle/>
        <track>Open media</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Open Source software can play a critical role for the roll-out of broadcast standards. This is also true for new caption and subtitle standards. The focus on the presentation will be on the OS Subtitle Conversion Framework (SCF). SCF consists of different software modules that aim at a faster and conformant adoption of the EBU-TT standard, an XML based subtitle standard defined by the EBU. Apart from SCF also other OS software that are important for the implementation of subtitles standards will be discussed (e.g. mp4box from GPAC or the WebVTT parser from Anne van Kesteren).&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2735">Andreas Tai</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2896">
        <start>12:00</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>upipe</slug>
        <title>Automatic Multicast Tunneling &amp; Upipe: a Proof of Concept</title>
        <subtitle>Multicast inside a web browser</subtitle>
        <track>Open media</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The presenter will explain Automatic Multicast Tunneling, a draft RFC allowing to extend multicast content distribution to unicast-only connected receivers, and its implementation in the flexible multimedia framework Upipe. He will also show how it is possible to take advantage of AMT in web browser, using the Native Client plug-in of Upipe.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1754">Christophe Massiot</person>
        </persons>
        <links>
          <link href="http://upipe.org/blog/amt-poc-now-available-online/">AMT proof of concept</link>
          <link href="https://datatracker.ietf.org/doc/draft-ietf-mboned-auto-multicast/">AMT RFC draft</link>
        </links>
      </event>
      <event id="2775">
        <start>12:30</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>tvopensource</slug>
        <title>Why open source lets a broadcaster sleep at night</title>
        <subtitle>Open source project within a TV Broadcast Workflow</subtitle>
        <track>Open media</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk is about how different opensource tools are use by Trace TV team&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2518">Emmanuel Aldeguer</person>
        </persons>
        <links>
          <link href="http://www.trace.tv">Trace official website</link>
        </links>
      </event>
      <event id="3160">
        <start>13:00</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>daala</slug>
        <title>Daala Video Codec</title>
        <subtitle>Research Update</subtitle>
        <track>Open media</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Daala is a next-generation royalty free video codec under development by Xiph.org and Mozilla.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2670">Nathan Egge</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2909">
        <start>13:30</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>gpac</slug>
        <title>Producing media content for the browsers using GPAC</title>
        <subtitle>Latest developments for media web distribution</subtitle>
        <track>Open media</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk will present the latest developments in GPAC regarding the media production for playback in modern browsers. This will include aspects related to subtitling (WebVTT, TTML) and graphics (SVG) streaming, MPEG-DASH and HTML5 Media Source Extensions, in particular using the MP4Box.js MP4 demuxer.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Producing media content for the browsers using GPAC: Latest developments for media web distribution&lt;/p&gt;

&lt;p&gt;This talk will present the latest developments in GPAC regarding the media production for playback in modern browsers. This will include aspects related to subtitling (WebVTT, TTML) and graphics (SVG) streaming, MPEG-DASH and HTML5 Media Source Extensions, in particular using the MP4Box.js MP4 demuxer.&lt;/p&gt;</description>
        <persons>
          <person id="2432">Romain Bouqueau</person>
        </persons>
        <links>
          <link href="http://www.gpac.io">http://www.gpac.io</link>
          <link href="http://github.com/gpac/gpac">http://github.com/gpac/gpac</link>
        </links>
      </event>
      <event id="3347">
        <start>14:00</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>gstreamer</slug>
        <title>GStreamer in the living room and in outer space</title>
        <subtitle/>
        <track>Open media</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk is targeted at anyone interested in multimedia, whether
professionally or as a hobbyist. Be it as an application developer,
framework architect, embedded system integrator, or anybody else.&lt;/p&gt;

&lt;p&gt;GStreamer is a highly versatile plugin-based multimedia framework that
caters to a whole range of multimedia needs, including desktop
applications, streaming servers or multimedia middleware; embedded
systems, desktops, or server farms. It is also easy to get started with,
and is cross-platform, with support for Linux, Android, OS/X, iOS, and
Windows, as well as *BSD and Solaris.&lt;/p&gt;

&lt;p&gt;In this talk we will present an overview of some of the many different
areas and use cases where GStreamer is deployed nowadays and what advantages
the use of GStreamer had in these areas. We will talk about web browsers,
set-top boxes, mobile devices, live video mixing applications,
audio/video editors, broadcasting applications, research of gravitational
waves and the International Space Station.&lt;/p&gt;

&lt;p&gt;Join us to find out what GStreamer can do for you!&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="671">Tim-Philipp Müller</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3166">
        <start>14:30</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>vimeo</slug>
        <title>Vimeo and the open source community</title>
        <subtitle/>
        <track>Open media</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;How Vimeo &lt;em&gt;plays nice&lt;/em&gt; with the open source community.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The Vimeo magic is a wonderful collection of Open Source multimedia tools, all able to talk together, whether processing video or audio or images. But what really matters in the Open Source philosophy is the people who are behind this incredible movement.&lt;/p&gt;

&lt;p&gt;In this presentation, we will explore how Vimeo leverages open source and how healthy it is to give back to the community whenever possible. Many Vimeo developers are also members of relevant Open Source projects, taking part in application and API design, maintainability and infrastructure discussions.&lt;/p&gt;</description>
        <persons>
          <person id="2736">Vittorio Giovara</person>
        </persons>
        <links>
          <link href="http://www.vimeo.com">Vimeo</link>
        </links>
      </event>
      <event id="2800">
        <start>15:00</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>vlc</slug>
        <title>VLC 2.2.0</title>
        <subtitle>Videolan VLC</subtitle>
        <track>Open media</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This presentation will cover the new features in VLC 2.2.0 and 3.0.0 that we introduced.&lt;/p&gt;

&lt;p&gt;It will cover also the updates in libVLC APIs for developers&lt;/p&gt;</abstract>
        <description>&lt;p&gt;This presentation will cover the new features in VLC 2.2.0 and 3.0.0 that we introduced.&lt;/p&gt;

&lt;p&gt;It will cover also the updates in libVLC APIs for developers.&lt;/p&gt;</description>
        <persons>
          <person id="2538">Jean-Baptiste Kempf</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3265">
        <start>15:30</start>
        <duration>00:40</duration>
        <room>H.2213</room>
        <slug>open_video_players</slug>
        <title>Web Video Players Architecture &amp; Open Source Community</title>
        <subtitle>In depth with Video.js, JwPlayer, and Kaltura Player</subtitle>
        <track>Open media</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk brings together presentations from three very popular web players Video.js, JwPlayer, and Kaltura Player ToolKit. Collectively these project represent a huge percentage of online video views and enable video robust video delivery for many content makers around the world. In this presentation, each project will present it’s architectural approach to contemporary multi-screen, multi-browser video playback. Projects will highlight how they work with the open source community and with tips for integration into your applications or websites. After the short presentations there will be a chance for QA for the projects.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1505">Michael Dale</person>
          <person id="2203">Itay Kinnrot</person>
          <person id="2399">Steve Heffernan</person>
          <person id="2836">Pablo Schklowsky</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3303">
        <start>16:15</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>kodi</slug>
        <title>From XBMP to XBMC to Kodi:</title>
        <subtitle>A Brief History of the Trials of a User-facing Media Center</subtitle>
        <track>Open media</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In this talk, Nathan will review many of the issues, solutions, pitfalls, and near miracles that have occurred since Kodi started out as a simple media player for the original Xbox. A number of fun toys may also be shown off.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;It's relatively rare and difficult to keep a large scale open source project going year after year without the firm financial backing of a larger organization. Since its inception in 2002, the software currently called Kodi has gone through numerous changes, both at the software level and at the organizational level, and has encountered numerous difficulties along the way, from simple communications problems both internally and with the userbase to larger organizational snafus. In this talk, we'll review how the organization has managed to overcome these problems and continue on.&lt;/p&gt;

&lt;p&gt;Topics expected to be covered will include a look at the platforms, distributions, and hardware supported today; a review of the history on the Xbox, the switch to platform agnosticism, and the creation of the Foundation; and plans for the future.&lt;/p&gt;

&lt;p&gt;Additionally, an overview of how the organization works and software is developed currently will be presented, along with a look at who uses Kodi, both from a user perspective and a business perspective.&lt;/p&gt;</description>
        <persons>
          <person id="2447">Martijn Kaijser</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3371">
        <start>16:45</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>enabling_video_preservation</slug>
        <title>Enabling video preservation through open source</title>
        <subtitle/>
        <track>Open media</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Exactly what codecs and containers should be favored in audiovisual preservation is an ongoing debate with archives while broadcast industries, media production industries, and increasingly open source communities contributing technology that supports the objectives of audiovisual preservation. As the machinery and skills needed to sustain access to film and analog video collections decay it is increasingly urgent for archives to address blocking technological issues in order to re-format legacy audiovisual recordings to digital formats efficiently. The presentation reviews the requirements and demands on technology within audiovisual preservation projects and assesses the opportunities and concerns of open media to contribute to preservation challenges, with a focus on lossless audiovisual codecs, technical and contextual metadata, and both the openness and standardization of relevant file formats.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2875">Dave Rice</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3374">
        <start>17:15</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>kaltura</slug>
        <title>Harnessing FOSS in an End to End Online Video Platform</title>
        <subtitle>Learn how the Kaltura platform builds and optimizes use of many open source components to build amazing online video experiences</subtitle>
        <track>Open media</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Kaltura is widely used to address a wide range of education, media, and enterprise video needs. In this talk covers how Kaltura interact with open source components for an end to end scalable FOSS video platform. We also cover how the core open source Kaltura platform interacts with these components, giving best practices for your own online video projects weather using a single component or integrating with a larger platform.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;In addition to contributing its core server as an open source video platform offering, Kaltura makes use of many third party FOSS projects. This session will walk attendees through major projects used by the Kaltura platform to ingest, analyze, optimize, record and play video files, and provide guidance in optimizing use&lt;/p&gt;

&lt;p&gt;The following projects and their role in our architecture will be surveyed:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Kaltura server -- Pulls together all the media services under a unified REST API.&lt;/li&gt;
&lt;li&gt;nginx-vod-module - An Kaltura developed Nginx module for On-the-fly repackaging of MP4 files to DASH, HDS, HLS, MSS&lt;/li&gt;
&lt;li&gt;Mediainfo - used to analyze source videos to determine how best to handle them&lt;/li&gt;
&lt;li&gt;FFMPEG and Mencoder - used in transcoding to optimize source videos so that they'll be best viewed by various devices; i.e: Desktops, tablets and cellphones running different OSes&lt;/li&gt;
&lt;li&gt;ImageMagic - used for image manipulation and thumbnail creation&lt;/li&gt;
&lt;li&gt;Red5 - used in order to record from webcams, and broadcast live streams.&lt;/li&gt;
&lt;li&gt;The Kaltura HTML5 player - used for playback in native and web environments.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The session will include a review of our video source detection and optimization processes as well as demos showing how each project is used within the platform.&lt;/p&gt;

&lt;p&gt;We will conclude with an overview of our current community activities and focus.&lt;/p&gt;</description>
        <persons>
          <person id="2206">Jess Portnoy</person>
          <person id="2208">Zohar Babin</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3452">
        <start>17:40</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>peer5</slug>
        <title>Peer5 content delivery network and how it uses WebRTC and FOSS</title>
        <subtitle/>
        <track>Open media</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Peer5 is a content delivery network based on WebRTC, a widely adopted open source project.
The talk will be about how we deliver media using a hybrid system of HTTP and peer-to-peer mesh network.&lt;/p&gt;

&lt;p&gt;We will review the API which is agnostic to the video technology, and show how it works with MP4, HLS, DASH and open source video players.&lt;/p&gt;

&lt;p&gt;We will also cover the advantages of being heavily based on open source projects and how it is compared to client based proprietary solutions in terms of security, portability and more.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2928">Hadar Weiss</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3331">
        <start>18:15</start>
        <duration>00:15</duration>
        <room>H.2213</room>
        <slug>openmedia</slug>
        <title>Wrapup, conclusion of Open Media Devroom</title>
        <subtitle/>
        <track>Open media</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Wrap-up and conclusion of the Open Media devroom, next activities.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Wrap-up and conclusion of the Open Media devroom, next activities.&lt;/p&gt;

&lt;p&gt;The Open Media devroom is a new at FOSDEM and co-organised by the European Broadcasting Union and FOMS. It addresses the  topics as found in broadcast(radio/TV) and Web media technologies such as video/audio encoding, playout, streaming, broadcasting, metadata . Information of related activities to this topic.&lt;/p&gt;</description>
        <persons>
        </persons>
        <links>
          <link href="http://tech.ebu.ch">EBU Technology&amp;Innovation</link>
        </links>
      </event>
    </room>
    <room name="H.2214">
      <event id="3314">
        <start>10:30</start>
        <duration>00:45</duration>
        <room>H.2214</room>
        <slug>cl_style_macroexpansion_applied_to_c</slug>
        <title>Common Lisp-Style Macroexpansion applied to C</title>
        <subtitle>A Code Generator from Lisp-Syntax to C-Syntax</subtitle>
        <track>Lisp</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;We describe a new free software project, called CGen [name might change], a C
code generator with support for Common Lisp-style macro
expansion. It is based on a new S-Expression based Syntax
for C (and C-like languages) which is transcompiled to C
(or C-like) code. Our code generator supports the simple
and efficient management of variants, ad hoc code
generation to capture reoccurring patterns, composable
abstractions as well as the implementation of embedded
domain specific languages by using the Common Lisp macro
system. We demonstrate the applicability of our approach
by numerous examples from small scale convenience macros
over embedded languages to real-world applications in
high-performance computing.&lt;/p&gt;

&lt;p&gt;After successful presentation at ELS in 2014 we decided to
polish our research prototype and make it available as
free software.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;For a full description we would like to refer to the attached paper, which was accecpted and presented at ELS this year.&lt;/p&gt;</description>
        <persons>
          <person id="2683">Kai Selgrad</person>
        </persons>
        <links>
          <link href="http://lgdv.cs.fau.de/publications/publication/Pub.2014.tech.IMMD.IMMD9.defmac/">Website of our ELS paper</link>
        </links>
      </event>
      <event id="3368">
        <start>11:20</start>
        <duration>00:30</duration>
        <room>H.2214</room>
        <slug>wikipedia_text_reflector</slug>
        <title>Wikipedia Text Reflector</title>
        <subtitle>Entity Linking in clojure for fun</subtitle>
        <track>Lisp</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Enitity Linking is a very helpfully technique to improve search on natural text. I will present
a system that allows to first spot entity's and than find related entity's using modern search engines like
solr and elasticsearch.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;In my talk I want to show how to use clojure and raw text, to get a wikipedia reflection
out of a given natural language text. A reflection is a set of related entities from
the wikipedia. I will show how to spot entity's in a given text using the Lucene FST
feature. With the spotted entities I will show how to retrieve additional informations, like related persons, and places by using elasticsearch and the wikipedia category graph. The system is entirely written in clojure, and works in form of a web application with backed and fronted.
The system makes use of the core.async library and the reactive UI library Om.&lt;/p&gt;</description>
        <persons>
          <person id="2873">Hagen Tönnies</person>
        </persons>
        <links>
          <link href="http://clojure.org/">Clojure</link>
          <link href="https://github.com/OpenSextant/SolrTextTagger">Solr text Tagger</link>
          <link href="http://www.elasticsearch.com/">elasticsearch</link>
          <link href="https://github.com/swannodette/om">Om</link>
          <link href="https://github.com/ptaoussanis/sente">Sente (Websockets via core.async)</link>
          <link href="https://github.com/aysylu/loom">loom (a in memory graph)</link>
          <link href="http://en.wikipedia.org/wiki/Entity_linking">Entity Linking</link>
        </links>
      </event>
      <event id="3442">
        <start>12:00</start>
        <duration>01:00</duration>
        <room>H.2214</room>
        <slug>elisp_small_and_useful_programs</slug>
        <title>Emacs Lisp (Elisp) small and useful programs</title>
        <subtitle/>
        <track>Lisp</track>
        <type>devroom</type>
        <language/>
        <abstract></abstract>
        <description></description>
        <persons>
          <person id="2637">Emanuel Berg</person>
        </persons>
        <links>
          <link href="http://">http://</link>
        </links>
      </event>
      <event id="3311">
        <start>13:10</start>
        <duration>00:50</duration>
        <room>H.2214</room>
        <slug>lfe_a_lisp_on_the_erlang_vm</slug>
        <title>LFE - a Lisp on the Erlang VM</title>
        <subtitle/>
        <track>Lisp</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk will discuss the issues around implemeting LFE (Lisp Flavoured Erlang) on the Erlang VM. The Erlang VM has been specially designed to implement Erlang and as such it has a number of interesting features and limitations which directly influence the design of a lisp running on top of it. We will look at the properties of the Erlang VM and our design goals for LFE and the LFE lisp which this resulted in.&lt;/p&gt;

&lt;p&gt;The talk can be adapted to either a shorter 30 mins or a longer 60 mins.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2837">Robert Virding</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2987">
        <start>14:10</start>
        <duration>01:00</duration>
        <room>H.2214</room>
        <slug>gcc_melt</slug>
        <title>GCC-MELT </title>
        <subtitle>a translated Lisp dialect inside GCC for customizing the compiler</subtitle>
        <track>Lisp</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;GCC-MELT see http://gcc-melt.org/ for more is
a Lispy domain specific language (and GPLv3+ implementation, as a GCC meta-plugin)
to extend and customize the GCC compiler (see http://gcc.gnu.org/ for more)&lt;/p&gt;

&lt;p&gt;This talk (for people familiar with Lisp, but unfamiliar with GCC internals)
will describe the MELT dialect, the implementation challenges, and some MELT usage,
with the future directions within the MELT project.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;MELT is a Lispy domain specific language to ease the customization of GCC thru particular extensions
(notably for additional coding rules checks and diagnostics, or for additional application-specific optimizations).&lt;/p&gt;

&lt;p&gt;MELT is a bootstrapped Lisp implementation (of nearly 100KLOC of GPLv3+ source code), compiled to C++ code fit for GCC internals.
The MELT dialect has several pecularities: it offers both first-class values and other stuff as data kinds;
it provides useful language features (pattern-matching, introspective reflection, meta-programming with macros)
for powerful GCC customization.&lt;/p&gt;

&lt;p&gt;MELT is integrated inside GCC by being a GCC meta-plugin. It enables adding new GCC optimization passes.
We describe some implementation challenges and how we tackled them.&lt;/p&gt;</description>
        <persons>
          <person id="2685">Basile Starynkevitch</person>
        </persons>
        <links>
          <link href="http://gcc-melt.org/">the GCC MELT website</link>
          <link href="http://gcc.gnu.org/">the GCC compiler </link>
        </links>
      </event>
      <event id="3173">
        <start>15:20</start>
        <duration>00:30</duration>
        <room>H.2214</room>
        <slug>puppet_plus_parentheses</slug>
        <title>Puppet Plus Parentheses</title>
        <subtitle/>
        <track>Lisp</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Puppet is a tool for configuration management and automation.  It’s written in Ruby, and therefore its codebase contains a notable lack of parentheses.  So, we set out to solve that problem and wrote Puppet Server: a new, open source implementation of the Puppet Master, written in Clojure.  In this talk, we’ll discuss the development of Puppet Server, our experience with Clojure, and some of the dragons slain along the way.  I’ll also give an introduction to Trapperkeeper - an open source application framework for Clojure programs, which we developed along the way.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2649">Kevin Corcoran</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3491">
        <start>16:00</start>
        <duration>01:00</duration>
        <room>H.2214</room>
        <slug>emacs_and_elisp_on_the_chromebook</slug>
        <title>Emacs and Elisp on the Chromebook</title>
        <subtitle/>
        <track>Lisp</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Emacs contains one of the most widely used Lisp dialects, Elisp. As the preferred text editor for a multitude of software developers, Emacs has been ported to a wide range of platforms. Recently, Emacs has come to the Web by way of a technology called Native Client. This talk explores the unique challenges of porting Emacs and Elisp to Native Client and the browser.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Native Client (NaCl), is an open-source technology that allows native machine code to run securely sandboxed in the browser. Two layers of sandboxing, a static verification inner sandbox combined with Chrome’s outer process sandbox, ensure users can safely run untrusted applications. Modified GCC and an LLVM based toolchains allow applications to target NaCl. An I/O API called PPAPI, mirroring the security constraints of Javascript, is provided to NaCl applications.&lt;/p&gt;

&lt;p&gt;This talk will focus on the challenges of porting Emacs to NaCl including: emulation of POSIX APIs—processes, sockets, files—on top of Web-centric APIs, porting an X11 server and client libraries, adapting Elisp to NaCl’s memory layout, and packaging for an integrated experience.  I  will talk about the challenges of debugging the lisp that is a part of the editor itself. I’ll demonstrate Emacs running in Google Chrome and explorer how it can interoperate with other developer tools we’ve ported to the browser.&lt;/p&gt;</description>
        <persons>
          <person id="2929">Pete Williamson</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3506">
        <start>17:10</start>
        <duration>00:20</duration>
        <room>H.2214</room>
        <slug>monroe_emacs_client_for_clojure_repl</slug>
        <title>Monroe</title>
        <subtitle>Emacs client for Clojure network REPL</subtitle>
        <track>Lisp</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Monroe is a lightweight network REPL client for Clojure nREPL protocol, focused on simplicity, familiarity and stability, written in pure elisp (Emacs Lisp). This talk will introduce the project, explain the reasoning for yet another implementation and compare it with existing clients.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1301">Sanel Zukan</person>
        </persons>
        <links>
          <link href="http://github.com/sanel/monrot">Monroe Home Page</link>
        </links>
      </event>
    </room>
    <room name="H.3227">
      <event id="3322">
        <start>11:00</start>
        <duration>02:00</duration>
        <room>H.3227</room>
        <slug>cert_bsdcg</slug>
        <title>BSDCG Exam Session</title>
        <subtitle/>
        <track>Certification</track>
        <type>certification</type>
        <language/>
        <abstract>&lt;p&gt;The BSDA certification is designed to be an entry-level certification on BSD Unix systems administration.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Testing candidates with a general Unix background and at least six months of work experience as a BSD systems administrator, or who wish to obtain employment as a BSD systems administrator, will benefit most from this certification.&lt;/p&gt;

&lt;p&gt;The successful BSDA candidate is able to complete common administrative and troubleshooting tasks and has a good understanding of general BSD Unix and networking principles. In addition, the successful candidate demonstrates basic skills with these BSD operating systems: Dragonfly BSD, FreeBSD, NetBSD and OpenBSD. This does not mean that the candidate needs to learn the complete details of four operating systems. It does mean that the candidate is aware of the basic utilities common to these operating systems, and where specified in the exam objectives, of features unique to some of the BSD operating systems.&lt;/p&gt;</description>
        <persons>
          <person id="625">BSDCG Team</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="AW1.120">
      <event id="3301">
        <start>10:30</start>
        <duration>00:50</duration>
        <room>AW1.120</room>
        <slug>valgrind_eclipse</slug>
        <title>Valgrind Integration in the Eclipse IDE</title>
        <subtitle>An Overview of the Valgrind Plugin</subtitle>
        <track>Valgrind</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Software development rarely has "spare" time, which often forces developers to stick to the tools they already know.  Having any sort of learning curve can be a barrier to entry for debugging and performance tools, even when the payoffs are worth the time invested learning new tools.  The Linux Tools Project aims to improve the state of C/C++ development on the Eclipse IDE by integrating popular tools, such as Valgrind.  This integration allows developers to maintain an environment they're familiar with, yet leverage new development tools.&lt;/p&gt;

&lt;p&gt;This talk is aimed at people of varying experience with the Valgrind tool who have never used it within the Eclipse IDE.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;An overview of the Eclipse Valgrind plugin provided by the Linux Tools Project will be given. Topics discussed will include :&lt;/p&gt;

&lt;p&gt;Quick overview of the Linux Tools Project
Introduction to the Eclipse Valgrind plugin
Demonstration of
* Memcheck
* Massif
* Helgrind
* Cachegrind
* Eclipse Platform specific integrations (Error markers, Problems View)
* Simple Auto-correction for common Memcheck/Helgrind problems
* Support for execution on remote targets&lt;/p&gt;

&lt;p&gt;Possible improvements to Valgrind tool&lt;/p&gt;

&lt;p&gt;Challenges faced regarding Valgrind tool&lt;/p&gt;</description>
        <persons>
          <person id="2304">Lukas Berk</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3464">
        <start>11:30</start>
        <duration>00:50</duration>
        <room>AW1.120</room>
        <slug>valgrind_tuning</slug>
        <title>Tuning Valgrind for your Workload</title>
        <subtitle>Hints, tricks and tips to effectively use Valgrind on small or big applications</subtitle>
        <track>Valgrind</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Valgrind with its set of tools provides a lot of powerful/sophisticated
functionalities. However, this power has a price in CPU and memory.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;This talk will discuss various ways to balance CPU and/or memory
versus more (or less) functionalities.&lt;/p&gt;

&lt;p&gt;Among others, we will explore command line options that control
tools such as memcheck or helgrind, in order to detect more (or less)
classes of errors, or tune the amount of data recorded by these tools.&lt;/p&gt;

&lt;p&gt;We will analyse the impact of such command line options on the CPU
and memory.&lt;/p&gt;

&lt;p&gt;We will also look at the various ways to investigate the behaviour
of Valgrind regarding memory or cpu behaviour.&lt;/p&gt;

&lt;p&gt;Demo and small test cases will be used to illustrate the discussed
functionalities.&lt;/p&gt;</description>
        <persons>
          <person id="1402">Philippe Waroquiers</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2980">
        <start>12:30</start>
        <duration>00:25</duration>
        <room>AW1.120</room>
        <slug>valgrind_extending_cachegrind</slug>
        <title>Extending Cachegrind: L2 Cache Inclusion &amp; TLB Measuring</title>
        <subtitle/>
        <track>Valgrind</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Description: I have extended Cachegrind to include L2 Cache Inclusion &amp;amp; TLB Measuring. The main goal of this talk is to present and explain how these two extensions work; why they might be useful, what one can do with them, how did I test them, etc. (see full description for the points to be covered)&lt;/p&gt;

&lt;p&gt;Intended Audience: Valgrind core developers and Cachegrind users&lt;/p&gt;</abstract>
        <description>&lt;ul&gt;
&lt;li&gt;Overview of Cachegrind and its limitations

&lt;ul&gt;
&lt;li&gt;Functionality added by my extensions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;And then, for both TLB measuring and L2 cache inclusion the following points will be
covered:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt; Usage&lt;/li&gt;
&lt;li&gt; Example use&lt;/li&gt;
&lt;li&gt; Available options&lt;/li&gt;
&lt;li&gt; How does the extension interact with the original code&lt;/li&gt;
&lt;li&gt; How to extend it&lt;/li&gt;
&lt;li&gt; Validity of results&lt;/li&gt;
&lt;li&gt; Introduced slowdown&lt;/li&gt;
&lt;/ul&gt;
</description>
        <persons>
          <person id="2635">Stavros Kaparelos</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3465">
        <start>14:00</start>
        <duration>00:50</duration>
        <room>AW1.120</room>
        <slug>valgrind_multi_prototype</slug>
        <title>Running Valgrind on multiple processors</title>
        <subtitle>a prototype</subtitle>
        <track>Valgrind</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Valgrind runs properly multi-threaded applications, but effectively only uses one CPU at a time to run them.
In other words, Valgrind cannot make use of multi-core CPUs when running a multi-threaded application.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;A prototype of a 'multi-core' Valgrind was developped. This talk will describe this prototype and discuss the challenges to obtain a production quality Valgrind that makes use of multiple core.&lt;/p&gt;</description>
        <persons>
          <person id="1402">Philippe Waroquiers</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3466">
        <start>15:00</start>
        <duration>00:50</duration>
        <room>AW1.120</room>
        <slug>valgrind_inlining</slug>
        <title>Partial inlining of Memcheck helper function fast paths</title>
        <subtitle/>
        <track>Valgrind</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Memcheck's performance is significantly limited by the need for the JIT generated code to call a helper function for every memory access. This talk will describe ongoing work to inline the fast cases of these helpers into the generated code, with the goal of getting a significant speedup.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Valgrind's Memcheck tool performs address checking at the byte level and definedness checking at the bit level.  Most of the definedness checking code is generated by Valgrind's JIT (VEX) as in-line code. But address checking is done by calling small C helper functions. That means one function call for each memory access to be checked, which is expensive.  And it's wasteful because those checks are actually very simple, so the overhead of the calls is significant.&lt;/p&gt;

&lt;p&gt;This talk describes ongoing work to inline the fast paths of such helper functions into the generated code.  The fast paths deal with the common case -- naturally aligned addresses and fully defined values -- with all other cases being pushed "off-trace" onto cold paths, possibly with helper calls to C land.&lt;/p&gt;

&lt;p&gt;Modifying the until-now simple JIT to support the arbitrary control flow this requires would be a big and complex task.  Instead we use a system of machine code templates which allow precise control of branching and register use without significantly complicating the JIT. Making the templates architecture-neutral yet capable of generating good straight-line code is an interesting challenge.&lt;/p&gt;</description>
        <persons>
          <person id="143">Julian Seward</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3415">
        <start>16:00</start>
        <duration>00:50</duration>
        <room>AW1.120</room>
        <slug>valgrind_easy_hack</slug>
        <title>How to start hacking on Valgrind by example</title>
        <subtitle>Easy hacks for valgrind</subtitle>
        <track>Valgrind</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;If you always wanted to hack on Valgrind, but haven't yet really looked at the code yet, then this talk is for you. We'll go over the basics of writing a new Valgrind tool. How to add a missing syscall. Show where to start when adding a new x86/amd64 instruction and translating it to VEX IR. After attending this talk, you should be all set to attend the hackaton in the Valgrind devroom at the end of the day.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="160">Mark Wielaard</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3416">
        <start>17:00</start>
        <duration>01:00</duration>
        <room>AW1.120</room>
        <slug>valgrind_hackaton</slug>
        <title>Valgrind Hackaton</title>
        <subtitle>Come and hack on Valgrind together</subtitle>
        <track>Valgrind</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Hacking on Valgrind together.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="AW1.121">
      <event id="3382">
        <start>10:30</start>
        <duration>01:00</duration>
        <room>AW1.121</room>
        <slug>edgebsd</slug>
        <title>EdgeBSD: Status report</title>
        <subtitle>News from the benevolent dictator</subtitle>
        <track>BSD</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This presentation will summarize the status and current roadmap of the
EdgeBSD Project, which started from the NetBSD codebase in mid-2013. The
aims at broadening and community development around NetBSD thanks to a
tentatively more modern development workflow, based on Git.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2105">Pierre Pronchery</person>
        </persons>
        <links>
          <link href="https://www.edgebsd.org/">The EdgeBSD Project</link>
        </links>
      </event>
      <event id="3007">
        <start>11:45</start>
        <duration>00:45</duration>
        <room>AW1.121</room>
        <slug>enlightenment_freebsd</slug>
        <title>Enlightenment, a cross-platform window manager and toolkit</title>
        <subtitle>Dealing with Enlightenment portability issues in FreeBSD and elsewhere</subtitle>
        <track>BSD</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The EFL is a toolkit for writing cross-platform applications. Enlightenment
is a desktop shell built using this toolkit. Both the EFL and Enlightenment
are fast and light on resources (which made them the toolkit of choice in
places such as the Tizen operating system and embedded environments) while
remaining scalable, but their low level approach complicates portability.
In this talk I'd like to summarize our past portability issues and tackle
current ones, as well as talk about our future direction. The talk will be
focused on FreeBSD, using it as an example, but will also cover our general
issues and portability to other operating systems including Windows and OS X.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The EFL (Enlightenment Foundation Libraries) is a toolkit for writing
applications (desktop and mobile alike), notably used by the Tizen operating
system as well as other places. Enlightenment itself is a desktop shell built
upon this toolkit. It's clean, lightweight and written entirely in C. However,
its low-level implementation approach has, besides small size and high
performance, a flaw, which is portability, an issue I have to deal with
very often as part of my work at Samsung.&lt;/p&gt;

&lt;p&gt;Enlightenment/EFL developers have always tried to write relatively portable
code, but there are still quite a few issues (major and minor) that remain.
As a FreeBSD user I think that portability is a very important topic that
should not be overlooked, and that's why I would like to cover these issues
in this talk as well as propose some solutions. The problems we're currently
facing include dependency on certain very Linux specific things, such as udev,
Wayland etc. as well as differences between APIs provided by those operating
systems and differences in tooling (build systems...).&lt;/p&gt;

&lt;p&gt;By coming up with solutions to these issues, we can make the EFL and E work
better on non-Linux operating systems (including but not limited to the BSD
family, Mac OS X or even Windows) as well as make it work better in those
places where it already runs, making it more accessible to more developers.&lt;/p&gt;

&lt;p&gt;In this talk I will introduce the EFL and Enlightenment, cover portability
problems across different operating systems with a focus on *BSD (and
lesser coverage of OS X and Windows) and present our future plans as far
as platform coverage is concerned.&lt;/p&gt;</description>
        <persons>
          <person id="2589">Daniel Kolesa</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3313">
        <start>13:05</start>
        <duration>01:00</duration>
        <room>AW1.121</room>
        <slug>fuzzing_freebsd</slug>
        <title>Fuzzing (on) FreeBSD</title>
        <subtitle>(Mostly) automated bug discovery with security/afl</subtitle>
        <track>BSD</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Fuzzing can help to find various kinds of bugs automatically, I'll present a couple of bugs that were already found with it.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Fuzzing can help to find various kinds of bugs automatically.
It may also highlight "weak" spots that deserve manual code inspection.&lt;/p&gt;

&lt;p&gt;Both FreeBSD itself and the ports we use daily contain bugs that have
yet to be discovered and fixed.&lt;/p&gt;

&lt;p&gt;American fuzz lop (security/afl) is a fast intrumented fuzzer available
in ports.&lt;/p&gt;

&lt;p&gt;I'll present a couple of bugs that were already found with it
and describe the code modifications that were used to increase
the efficiency.&lt;/p&gt;</description>
        <persons>
          <person id="2215">Fabian Keil</person>
        </persons>
        <links>
          <link href="http://lcamtuf.coredump.cx/afl/">American fuzzy lop website</link>
        </links>
      </event>
      <event id="3289">
        <start>14:15</start>
        <duration>00:45</duration>
        <room>AW1.121</room>
        <slug>bsdrp</slug>
        <title>BSD Router Project</title>
        <subtitle>A brief introduction</subtitle>
        <track>BSD</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;BSDRP is a software router based on FreeBSD&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Here is the Agenda:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Why a software router ?&lt;/li&gt;
&lt;li&gt;Presenting nanobsd&lt;/li&gt;
&lt;li&gt;Feature list&lt;/li&gt;
&lt;li&gt;Benchmarking forwarding performance&lt;/li&gt;
&lt;li&gt;Virtual lab&lt;/li&gt;
&lt;/ul&gt;
</description>
        <persons>
          <person id="2832">Olivier Cochard-Labbé</person>
        </persons>
        <links>
          <link href="http://bsdrp.net">Project homepage</link>
        </links>
      </event>
      <event id="3153">
        <start>15:05</start>
        <duration>00:45</duration>
        <room>AW1.121</room>
        <slug>xen_freebsd</slug>
        <title>FreeBSD/Xen status update</title>
        <subtitle>Current status and future development of FreeBSD/Xen</subtitle>
        <track>BSD</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;During the last year (2014) a lot of interesting development happened around the FreeBSD/Xen port. FreeBSD slowly moved from running as a PV with HVM drivers, to running as a PVHVM guests and finally as a PVH DomU. The last step into getting full Xen support into FreeBSD was to get it to run as a PVH Dom0, which is now finished and in a tech-preview status.&lt;/p&gt;

&lt;p&gt;This talk will include a high-level description of the modifications needed in order to get FreeBSD running as a Dom0, and a demo of FreeBSD running as a PVH Xen Dom0.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The goal of this talk is to provide information about the Xen PVH and FreeBSD architecture, and to encourage other OS hackers to work on it.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Basic Xen description and specific Xen concepts.&lt;/li&gt;
&lt;li&gt;How the Xen community works (compared to BSD communities).&lt;/li&gt;
&lt;li&gt;A look into new Xen features (PVH).&lt;/li&gt;
&lt;li&gt;Work being done in FreeBSD improving Xen support.&lt;/li&gt;
&lt;li&gt;Demo of a FreeBSD PVH Dom0.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <persons>
          <person id="1851">Roger Pau Monné</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3381">
        <start>16:05</start>
        <duration>01:00</duration>
        <room>AW1.121</room>
        <slug>4yearofpkg</slug>
        <title>4 years of pkg(8)</title>
        <subtitle>A end less journey</subtitle>
        <track>BSD</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;A summary of four years working on pkg:&lt;/p&gt;</abstract>
        <description>&lt;ul&gt;
&lt;li&gt;why a new packages manager;&lt;/li&gt;
&lt;li&gt;what happened in the different versions;&lt;/li&gt;
&lt;li&gt;mistakes made;&lt;/li&gt;
&lt;li&gt;lesson learned&lt;/li&gt;
&lt;li&gt;What is cooking for the future:

&lt;ul&gt;
&lt;li&gt;within pkg(8) itself;&lt;/li&gt;
&lt;li&gt;packaging the FreeBSD base system;&lt;/li&gt;
&lt;li&gt;improvement in the ports tree.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        <persons>
          <person id="553">Baptiste Daroussin</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="AW1.124">
      <event id="3480">
        <start>10:30</start>
        <duration>00:30</duration>
        <room>AW1.124</room>
        <slug>ada_arrival</slug>
        <title>Arrival &amp; Informal Discussions</title>
        <subtitle/>
        <track>Ada</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Feel free to arrive early, to start the day with some informal
discussions while the set-up of the DevRoom is finished.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
        </persons>
        <links>
          <link href="http://www.cs.kuleuven.be/~dirk/ada-belgium/events/15/150131-fosdem.html#arrival">More info on Ada-Belgium web site</link>
        </links>
      </event>
      <event id="3479">
        <start>11:00</start>
        <duration>00:05</duration>
        <room>AW1.124</room>
        <slug>ada_welcome</slug>
        <title>Welcome</title>
        <subtitle/>
        <track>Ada</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Welcome to the Ada Developer Room at FOSDEM 2015, which is organized
by Ada-Belgium in cooperation with Ada-Europe.&lt;/p&gt;

&lt;p&gt;Ada-Belgium and Ada-Europe are non-profit organizations set up
to promote the use of the Ada programming language and related
technology, and to disseminate knowledge and experience into academia,
research and industry in Belgium and Europe, resp.  Ada-Europe has
member-organizations, such as Ada-Belgium, in various countries.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;More information on this DevRoom is available on the Ada-Belgium web-site.&lt;/p&gt;</description>
        <persons>
          <person id="581">Dirk Craeynest</person>
        </persons>
        <links>
          <link href="http://www.cs.kuleuven.be/~dirk/ada-belgium/events/15/150131-fosdem.html#welcome">More info on Ada-Belgium web site</link>
        </links>
      </event>
      <event id="3481">
        <start>11:05</start>
        <duration>00:50</duration>
        <room>AW1.124</room>
        <slug>ada_introduction</slug>
        <title>Ada, an Introduction</title>
        <subtitle/>
        <track>Ada</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk will introduce the Ada programming language to people used
to more classical, weak-typed languages.&lt;/p&gt;

&lt;p&gt;We will focus on how Ada uses its strong typing basis to prevent the
most common programming errors at the language level, allowing the
compiler to check them before they cause problems.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="590">Jérémy Rosen</person>
        </persons>
        <links>
          <link href="http://www.cs.kuleuven.be/~dirk/ada-belgium/events/15/150131-fosdem.html#introduction">More info on Ada-Belgium web site</link>
        </links>
      </event>
      <event id="3482">
        <start>12:00</start>
        <duration>00:50</duration>
        <room>AW1.124</room>
        <slug>ada_gtkada</slug>
        <title>Building a GUI for an Ada Application with GtkAda</title>
        <subtitle/>
        <track>Ada</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;GTK+ is an open-source library that allows to quickly and easily
build a graphical user interface, using standard widgets like buttons,
combo boxes, text and tree views, scroll bars, etc.  Even though GTK+
is written in C, it can be used from an Ada application thanks to
GtkAda, an object-oriented Ada/C binding.&lt;/p&gt;

&lt;p&gt;Illustrated by a poker game application, this presentation will
explain the essential concepts of GtkAda.  It will show how to create
the most common widgets and how to interact with the user.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2957">Serge Vanschoenwinkel</person>
        </persons>
        <links>
          <link href="http://www.cs.kuleuven.be/~dirk/ada-belgium/events/15/150131-fosdem.html#gtkada">More info on Ada-Belgium web site</link>
        </links>
      </event>
      <event id="3483">
        <start>13:00</start>
        <duration>00:25</duration>
        <room>AW1.124</room>
        <slug>ada_phcpack</slug>
        <title>Opening the Development of PHCpack</title>
        <subtitle/>
        <track>Ada</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;PHCpack originated from bundling programs to solve polynomial
systems with symbolic-numeric and polyhedral methods.  The core of
PHCpack consists mainly of Ada code, with interfaces to C and Python.
Its blackbox solver is accessible from various scientific software
packages such as Macaulay2, Maple, MATLAB, Octave, and Sage.&lt;/p&gt;

&lt;p&gt;The goal of the talk is to explain the application of software
engineering principles and the role of Ada in the development of
PHCpack.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1899">Jan Verschelde</person>
        </persons>
        <links>
          <link href="http://www.cs.kuleuven.be/~dirk/ada-belgium/events/15/150131-fosdem.html#phcpack">More info on Ada-Belgium web site</link>
        </links>
      </event>
      <event id="3484">
        <start>13:30</start>
        <duration>00:30</duration>
        <room>AW1.124</room>
        <slug>ada_informal</slug>
        <title>Informal Discussions</title>
        <subtitle/>
        <track>Ada</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;A half-hour slot has been reserved for much needed interaction
and informal discussion among Ada DevRoom participants and anyone
potentially interested in Ada.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
        </persons>
        <links>
          <link href="http://www.cs.kuleuven.be/~dirk/ada-belgium/events/15/150131-fosdem.html#informal">More info on Ada-Belgium web site</link>
        </links>
      </event>
      <event id="3485">
        <start>14:00</start>
        <duration>00:50</duration>
        <room>AW1.124</room>
        <slug>ada_contracts</slug>
        <title>Contract-based Programming - A Route to Finding Bugs Earlier</title>
        <subtitle/>
        <track>Ada</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Contract-based programming is a software development technique, which
is used to find programming errors earlier in the development process.
"Contract" refers to formal declarations of how types and subprograms
("functions and methods" if you aren't an Ada programmer already)
behave.  In the strictest form, the contracts are checked as a part
of the compilation process, and only a program which can be proven
to conform with the contracts will compile.
In a less strict form, it is more similar to "preventive debugging",
where the contracts are inserted as run-time checks, which makes it
more likely to identify errors during testing.&lt;/p&gt;

&lt;p&gt;Ada provides a quite extensive support for contract-based programming.
The checks are specified as a mix of compile-time checks, obligatory
run-time checks, and optional run-time checks.  In addition to that,
SPARK defines a subset of Ada with full compile-time checks.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The presentation will introduce the Ada features related to
contract-based programming, and provide suggestions for how to make use
of the features in practice.  It is organized in three main sections:
type/object invariants; pre- and postconditions for operations;
making the contracts for entire packages consistent.
If there is time, the presentation will close with a live test of
the guidelines on an example problem selected by the audience.&lt;/p&gt;

&lt;p&gt;The intended audience is anybody with enough programming experience
to know concepts like types, encapsulation and packages.  Having seen
source text in Pascal-like programming languages will be a benefit.&lt;/p&gt;</description>
        <persons>
          <person id="862">Jacob Sparre Andersen</person>
        </persons>
        <links>
          <link href="http://www.cs.kuleuven.be/~dirk/ada-belgium/events/15/150131-fosdem.html#contracts">More info on Ada-Belgium web site</link>
        </links>
      </event>
      <event id="3486">
        <start>15:00</start>
        <duration>00:50</duration>
        <room>AW1.124</room>
        <slug>ada_arm</slug>
        <title>Ada for ARM Bare Board</title>
        <subtitle/>
        <track>Ada</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In 2014, AdaCore has released two new components in the GNAT GPL
Edition: GNAT GPL for ARM Bare Board and SPARK 2014.  I present the
content of GNAT GPL for ARM, its Ravenscar runtime, how to build and
deploy an embedded application in Ada and how it was used to teach Ada.&lt;/p&gt;

&lt;p&gt;Two different demos will be presented: a Tetris game and a train
signalling system.  Both are fully written in Ada, with some parts
written and proven with SPARK 2014.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2958">Tristan Gingold</person>
        </persons>
        <links>
          <link href="http://www.cs.kuleuven.be/~dirk/ada-belgium/events/15/150131-fosdem.html#arm">More info on Ada-Belgium web site</link>
        </links>
      </event>
      <event id="3487">
        <start>16:00</start>
        <duration>00:50</duration>
        <room>AW1.124</room>
        <slug>ada_multithreading</slug>
        <title>Multithreading Made Easy, part 3 - Bounded Work Queues</title>
        <subtitle/>
        <track>Ada</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Ada is one of very few programming languages that support
multithreading as part of the language, as opposed to libraries.&lt;/p&gt;

&lt;p&gt;In the previous two episodes, we showed how Ada makes it easy to turn
a single-threaded program into a multi-threaded program. We ended
up with ten thousand threads working concurrently then introduced
a task pool and work queue wherein a small number of threads (one
per processor core) process thousands of small work units.  But the
work queue could become very big.  In this third and last episode,
we show how to restrict the size of the work queue to a fixed limit,
thereby preventing denial-of-service attacks.&lt;/p&gt;

&lt;p&gt;This presentation will feature live editing of source code, compilation
and debugging.  Questions from beginners are encouraged.  It is not
necessary to have attended the first installments.  The sources of our
example program will be provided to those who want to tinker with them.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="19">Ludovic Brenta</person>
        </persons>
        <links>
          <link href="http://www.cs.kuleuven.be/~dirk/ada-belgium/events/15/150131-fosdem.html#multithreading">More info on Ada-Belgium web site</link>
        </links>
      </event>
      <event id="3488">
        <start>17:00</start>
        <duration>00:50</duration>
        <room>AW1.124</room>
        <slug>ada_cairo</slug>
        <title>2D Drawing with Ada and Cairo</title>
        <subtitle/>
        <track>Ada</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Cairo is a 2D graphics library with support for multiple output
devices.  It is designed to produce consistent output on all output
media while taking advantage of display hardware acceleration
when available.  The Cairo API provides operations similar to
the drawing operators of PostScript and PDF.  Operations in Cairo
including stroking and filling cubic Bézier splines, transforming
and compositing translucent images, and antialiased text rendering.
All drawing operations can be transformed by any affine transformation
(scale, rotation, shear, etc.).&lt;/p&gt;

&lt;p&gt;Illustrated by a poker game application, this presentation will show
you how to do nice drawings with Cairo, still programming with your
preferred language: Ada!&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2957">Serge Vanschoenwinkel</person>
        </persons>
        <links>
          <link href="http://www.cs.kuleuven.be/~dirk/ada-belgium/events/15/150131-fosdem.html#cairo">More info on Ada-Belgium web site</link>
        </links>
      </event>
      <event id="3489">
        <start>18:00</start>
        <duration>00:25</duration>
        <room>AW1.124</room>
        <slug>ada_simulations</slug>
        <title>Building Economic Simulations in Ada</title>
        <subtitle/>
        <track>Ada</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Virtual Worlds Research has been using Ada to build large scale
economic simulations for 10 years now.  These simulations have been
used by Governments and others to model the effects of, amongst
other things, changing Legal Aid and reforming Social Care funding
- many billions of pounds of annual spending.  Here, I discuss our
experiences, good and bad, with the Ada language, and provide a live
demonstration of the most recent model.  I'll also discuss work in
progress to build a new forecasting model in association with the
University of Southampton.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2959">Graham Stark</person>
        </persons>
        <links>
          <link href="http://www.cs.kuleuven.be/~dirk/ada-belgium/events/15/150131-fosdem.html#simulations">More info on Ada-Belgium web site</link>
        </links>
      </event>
      <event id="3490">
        <start>18:30</start>
        <duration>00:30</duration>
        <room>AW1.124</room>
        <slug>ada_wrapup</slug>
        <title>Informal Discussions &amp; Closing</title>
        <subtitle/>
        <track>Ada</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Informal discussion on ideas and proposals for future events.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
        </persons>
        <links>
          <link href="http://www.cs.kuleuven.be/~dirk/ada-belgium/events/15/150131-fosdem.html#wrapup">More info on Ada-Belgium web site</link>
        </links>
      </event>
    </room>
    <room name="AW1.125">
      <event id="3191">
        <start>10:30</start>
        <duration>00:15</duration>
        <room>AW1.125</room>
        <slug>graph_hello</slug>
        <title>Welcome to the GraphDevroom</title>
        <subtitle>A short introduction an overview to this years graph devroom</subtitle>
        <track>Graph processing</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;We, the organizers of the the GraphDevroom, will give a warm welcome and a review on the graphy year 2014.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;We, the organizers of the the GraphDevroom, will give a warm welcome and a review on the graphy year 2014.&lt;/p&gt;</description>
        <persons>
          <person id="308">Achim Friedland</person>
          <person id="2896">Pere Urbon-Bayes</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3255">
        <start>10:45</start>
        <duration>00:45</duration>
        <room>AW1.125</room>
        <slug>graph_fink</slug>
        <title>Large-scale graph processing with Apache Flink</title>
        <subtitle/>
        <track>Graph processing</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Apache Flink (incubating) is a general-purpose platform for batch and streaming distributed data processing. This talk describes how Flink’s powerful APIs, iterative operators and other unique features make it a competitive alternative for large-scale graph processing as well. We take a close look at how one can elegantly express graph analysis tasks, using common Flink operators and how different graph processing models, like vertex-centric, can be easily mapped to Flink dataflows. Next, we get a sneak preview into Flink's upcoming Graph API, which further simplifies graph application development in Flink. Finally, we show how to perform end-to-end data analysis, mixing common Flink operators and the Graph API, without having to build complex pipelines and combine different systems. We will go through a step-by-step example, demonstrating how to perform loading, transformation, filtering, graph creation and analysis, with a single Flink program.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2634">Vasia Kalavri</person>
        </persons>
        <links>
          <link href="https://flink.incubator.apache.org/">Apache Flink</link>
          <link href="https://github.com/apache/incubator-flink">Apache Flink on Github</link>
          <link href="https://github.com/project-flink/flink-graph">Flink's Graph API development repo</link>
        </links>
      </event>
      <event id="3354">
        <start>11:30</start>
        <duration>01:00</duration>
        <room>AW1.125</room>
        <slug>graph_manylines</slug>
        <title>Manylines</title>
        <subtitle> a graph web publication platform with storytelling features</subtitle>
        <track>Graph processing</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;More and more people work with graphs nowadays, but it is not always easy to publish and share the graph interpretation on the web.
&lt;strong&gt;Manylines&lt;/strong&gt; is a web tool built at Sciences Po médialab to solve this issue.
Some researchers and students use network visualizations to explore their data, but networks are not as clear as maps and sharing one’s interpretation is difficult.
Manylines main innovation is to allow the user to &lt;strong&gt;explain and share a narrative about his network&lt;/strong&gt;: an interactive story where each “slide” is a particular zoom, pan and filtering of the network, completed by a title and description, with fluid transitions like in Prezi.&lt;/p&gt;

&lt;p&gt;Published as an open source prototype with the source code available on GitHub, Manylines is currently built around three screens:
- The first screen allows applying the ForceAtlas2 layout to the network, in order to &lt;strong&gt;settle the “basemap”&lt;/strong&gt;: the definitive positions of nodes and edges used to support further interpretations.
- The second screen allows zooming and filtering the network to explore the data and &lt;strong&gt;“take snapshots”&lt;/strong&gt; representing different insights.
- The third screen allows &lt;strong&gt;composing narratives&lt;/strong&gt; by building  a series of snapshots, adding a title and short description for each step.
The result is &lt;strong&gt;an interactive slideshow widget&lt;/strong&gt; where the user's exploration of the network is guided step by step, revealing the key interpretation points one by one.&lt;/p&gt;

&lt;p&gt;Manylines is a single webpage app built for HTML5 browsers.
It makes an &lt;strong&gt;extensive use of the sigma.js library&lt;/strong&gt; to deal with networks within the browser and it implements different features inspired from Gephi, the reference desktop graph viz platform.
The WebGL visualization (with Canvas fallback) implemented by Sigma.js allows great performance for networks up to 1000 nodes on an average computer.
To reach this level of performance, &lt;strong&gt;we optimized the javascript version of the ForceAtlas2 algorithm&lt;/strong&gt; used by sigma.js.
We ported it to use &lt;strong&gt;web workers&lt;/strong&gt; and we optimized the &lt;strong&gt;Barnes-Hut quadtree approximation&lt;/strong&gt; in this context by implementing it &lt;strong&gt;as an iterative and not recursive process&lt;/strong&gt;.
We made an extensive use of &lt;strong&gt;sigma.js' custom renderers and cameras&lt;/strong&gt; to build dynamic graph thumbnails, snapshots and widgets.
The server side stores the networks, snapshots and narrative data in a &lt;strong&gt;Couchbase database&lt;/strong&gt;  (which we discovered in FOSDEM 2014) accessed by a &lt;strong&gt;Node.js express REST API&lt;/strong&gt;.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2865">Paul Girard</person>
        </persons>
        <links>
          <link href="http://tools.medialab.sciences-po.fr/manylines/app#/upload">manylines prototype for testing only</link>
          <link href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0098679">ForceAtlas 2 algorithm in details</link>
          <link href="https://github.com/medialab/manylines">manylines' source code</link>
          <link href="http://sigmajs.org/">sigma.js library</link>
        </links>
      </event>
      <event id="3364">
        <start>12:30</start>
        <duration>01:00</duration>
        <room>AW1.125</room>
        <slug>graph_timeflows</slug>
        <title>Time flows on Graph</title>
        <subtitle>Managing event sequences and time series with a Document-Graph Database</subtitle>
        <track>Graph processing</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Time dimension is fundamental in many different contexts, from statistical analysis to representation of cause-effect relationships, from forecasting to automatic control systems.&lt;/p&gt;

&lt;p&gt;Representing this kind of data in "traditional" databases can lead to performance problems, due to their quantity, frequency and domain model; this is why NoSQL solutions are widely used in this field.&lt;/p&gt;

&lt;p&gt;In this talk we will show how to use OrientDB, a Document-Graph Database, to store, process and query this type of information in an efficient and effective way.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Time dimension is fundamental in many different contexts, from statistical analysis to representation of cause-effect relationships, from forecasting to automatic control systems.&lt;/p&gt;

&lt;p&gt;Representing this kind of data in "traditional" databases can lead to performance problems, due to their quantity, frequency and domain model; this is why NoSQL solutions are widely used in this field.&lt;/p&gt;

&lt;p&gt;In this talk we will show how to use OrientDB, a Document-Graph Database, to store, process and query this type of information in an efficient and effective way.&lt;/p&gt;</description>
        <persons>
          <person id="2869">Emanuele Tagliaferri</person>
          <person id="2939">Enrico Risa</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3366">
        <start>13:30</start>
        <duration>00:30</duration>
        <room>AW1.125</room>
        <slug>graph_sigmajs</slug>
        <title>sigma.js, two years later</title>
        <subtitle>A presentation of the latest version of sigma.js</subtitle>
        <track>Graph processing</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk will present how to solve some graph visualization use cases with sigma.js, an open JavaScript library dedicated to graph drawing.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Sigma.js is an open JavaScript library dedicated to graph drawing.
It can display some medium graphs (tens of thousands of nodes, hundreds of thousands of edges, under some conditions), using Canvas, WebGL or SVG.
Its API has been designed to facilitate the development of Web applications highly customized renderings and interactions as well as the most simple use cases.
This talk will show how sigma can solve in action some common use cases, such as:
 - static graph visualizations:
   typically a graph that has already been "mapped" and exported from Gephi
 - dynamic exploration:
   for instance a neighborhoods exploration of a large graph
 - customized rendering:
   for example to make the graphs being displayed with a specific graphic guidelines
 - customized interactions:
   to adapt the behaviours to specific UX needs&lt;/p&gt;

&lt;p&gt;Website:
Repository:&lt;/p&gt;</description>
        <persons>
          <person id="1171">Alexis  Jacomy </person>
        </persons>
        <links>
          <link href="http://sigmajs.org">Sigma.js website</link>
          <link href="http://github.com/jacomyal/sigma.js">Github repository</link>
        </links>
      </event>
      <event id="3430">
        <start>14:00</start>
        <duration>00:45</duration>
        <room>AW1.125</room>
        <slug>osm2graphdb</slug>
        <title>From Open Street Map to your preferred graph database...</title>
        <subtitle>...and perhaps back again</subtitle>
        <track>Graph processing</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;From Open Street Map to your preferred graph database (and perhaps back again)...&lt;/p&gt;</abstract>
        <description>&lt;p&gt;From Open Street Map to your preferred graph database (and perhaps back again)...&lt;/p&gt;</description>
        <persons>
          <person id="308">Achim Friedland</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3376">
        <start>14:45</start>
        <duration>00:45</duration>
        <room>AW1.125</room>
        <slug>graph_structr</slug>
        <title>Using Neo4j as a Document Database</title>
        <subtitle>With Structr 1.1, Neo4j can be used as a Document Database</subtitle>
        <track>Graph processing</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;With the current Structr version 1.1, you can use deeply nested JSON documents to create graph structures in Neo4j. In this talk, I will demonstrate how to use Structr and Neo4j as a document database and explain how it works under the hood.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1172">Axel  Morgner</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3410">
        <start>15:30</start>
        <duration>00:30</duration>
        <room>AW1.125</room>
        <slug>graph_meetup</slug>
        <title>Analysing London's NoSQL meetups using R &amp; Graphs</title>
        <subtitle/>
        <track>Graph processing</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The majority of NoSQL meetups in London are hosted on meetup.com and luckily for us meetup.com has an API that allows us to extract all the corresponding data - groups, events, venues, members and RSVPs.&lt;/p&gt;

&lt;p&gt;In this talk Mark will show how we can use R to gain quick insights into the data using tools like dplyr and ggplot2. We'll also do some social network analysis of the attendees of London's meetup scene using igraph.&lt;/p&gt;

&lt;p&gt;Finally we'll look at how we could bring together all these insights into a brand new Clojure front end for the meetup website.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The majority of NoSQL meetups in London are hosted on meetup.com and luckily for us meetup.com has an API that allows us to extract all the corresponding data - groups, events, venues, members and RSVPs.&lt;/p&gt;

&lt;p&gt;In this talk Mark will show how we can use R to gain quick insights into the data using tools like dplyr and ggplot2. We'll also do some social network analysis of the attendees of London's meetup scene using igraph.&lt;/p&gt;

&lt;p&gt;Finally we'll look at how we could bring together all these insights into a brand new Clojure front end for the meetup website.&lt;/p&gt;</description>
        <persons>
          <person id="2844">Mark Needham</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3401">
        <start>16:00</start>
        <duration>01:00</duration>
        <room>AW1.125</room>
        <slug>graph_spark</slug>
        <title>Big Graph Analytics on Neo4j with Apache Spark</title>
        <subtitle>A Docker Image for Graph Analytics on Neo4j with Apache Spark GraphX </subtitle>
        <track>Graph processing</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In this talk I will introduce you to a Docker container that provides you an easy way to do distributed graph processing using Apache Spark GraphX and a Neo4j graph database. You'll learn how to analyze big data graphs that are exported from Neo4j and consequently updated from the results of a Spark GraphX analysis. The types of analysis I will be talking about are PageRank, connected components, triangle counting, and community detection.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Database technologies have evolved to be able to store big data, but are largely inflexible. For complex graph data models stored in a relational database there may be tedious transformations and shuffling around of data to perform large scale analysis.&lt;/p&gt;

&lt;p&gt;Fast and scalable analysis of big data has become a critical competitive advantage for companies. There are open source tools like Apache Hadoop and Apache Spark that are providing opportunities for companies to solve these big data problems in a scalable way. Platforms like these have become the foundation of the big data analysis movement.&lt;/p&gt;</description>
        <persons>
          <person id="2898">Kenny Bastani</person>
        </persons>
        <links>
          <link href="http://www.kennybastani.com/2014/11/using-apache-spark-and-neo4j-for-big.html">Using Apache Spark and Neo4j for Big Data Graph Analytics </link>
          <link href="http://www.kennybastani.com/2014/11/graph-analytics-docker-spark-neo4j.html">A Docker Image for Graph Analytics on Neo4j with Apache Spark GraphX </link>
        </links>
      </event>
      <event id="3444">
        <start>17:00</start>
        <duration>00:30</duration>
        <room>AW1.125</room>
        <slug>graph_recom</slug>
        <title>Recommendation Engines with Graph Databases</title>
        <subtitle>Building a high-performance recommendation engine using open-source software (Neo4j &amp; GraphAware Framework)</subtitle>
        <track>Graph processing</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Graph Databases are naturally well-suited for building recommendation engines. In this talk, Michal will share his experience building a number of high-performance production-ready recommendation engines using Neo4j and introduce the open-source GraphAware Recommendation Engine Library, which enables Java developers to rapidly build their own recommender systems.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;This presentation starts by a brief explanation of why graphs are a suitable data model for building recommender systems. A summary of typical recommendation engine requirements follows, including the business and technical challenges these requirements introduce. Afterwards, the talk dives into possible solutions of these challenges, both from business and architectural/design perspectives, and introduces the GraphAware Recommendation Engine Library.&lt;/p&gt;

&lt;p&gt;What follows is a demonstration of how this open-source recommendation engine skeleton solves many of the issues and how it handles the "plumbing", so that developers can focus on expressing the business logic specific to their domain.&lt;/p&gt;

&lt;p&gt;The talk concludes by presenting complexities yet to be solved, and a brief survey of alternative approaches.&lt;/p&gt;

&lt;p&gt;A majority of examples in this talk are drawn from real-world use cases and the speaker's personal experience building recommendation engines. Attendees should have a very basic understanding of graph theory. Prior experience with Neo4j and the Cypher query language is a plus, but not necessary. Ability to read Java is recommended.&lt;/p&gt;

&lt;p&gt;Attendees will learn:
* what is a recommendation engine and what it is good for
* why graphs are a good fit for building one
* what business and technical challenges one faces building a recommender
* what possible solutions there are for these challenges
* how to build a high-performance graph-based recommendation engine in minutes
* real-world case studies&lt;/p&gt;</description>
        <persons>
          <person id="2919">Michal Bachman</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2979">
        <start>17:30</start>
        <duration>00:30</duration>
        <room>AW1.125</room>
        <slug>graph_tesseract</slug>
        <title>Tesseract: Distributed Graph Database and Computation platform</title>
        <subtitle>Unlocking the connected nature of the world</subtitle>
        <track>Graph processing</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The Tesseract is a &lt;strong&gt;distributed&lt;/strong&gt; graph processing and computation platform, purpose built, from the ground up.
This talk will present the new algorithms developed to create an efficient platform for native distributed graph traversals and computations.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The last 10 years has had provable uses of graph processing systems. As we aim to do more, we stretch existing technologies far beyond what they were intended for. Remarkable efforts like &lt;em&gt;Apache Giraph&lt;/em&gt; or the &lt;em&gt;Titan&lt;/em&gt; project are examples that are pushing the bounds. Ultimately the brute force techniques are inefficient, often don't scale very well and come with their own problems. In the ideal world, a scalable graph processing system would evenly distribute both vertices and edges. Richard Karp has shown this to be an np-complete problem (i.e. the clique problem / complete subgraphs).&lt;/p&gt;

&lt;p&gt;The talk will give a brief introduction to &lt;em&gt;CRDT - Convergent &amp;amp; Commutative Replicated Data types&lt;/em&gt; and how commutative &amp;amp; idempotent operations enable the three contributions.
Three key contributions The Tesseract makes include partitioning "super vertices" with a technique called "&lt;strong&gt;cascading vertices&lt;/strong&gt;",  an optimization called "&lt;strong&gt;wormhole traversal&lt;/strong&gt;" and a computational framework, "&lt;strong&gt;TQL&lt;/strong&gt;" able to make use of two aforementioned techniques. The talk will give an introduction to the first two and a very brief overview of the third.&lt;/p&gt;</description>
        <persons>
          <person id="2255">Courtney Robinson (zcourts)</person>
        </persons>
        <links>
          <link href="http://en.wikipedia.org/wiki/NP-complete#NP-complete_problems">List of np-complete problems</link>
          <link href="http://en.wikipedia.org/wiki/Clique_problem">The Clique problem</link>
          <link href="http://en.wikipedia.org/wiki/Karp%27s_21_NP-complete_problems">Karp's 21 NP-complete problems</link>
          <link href="http://cgi.di.uoa.gr/~sgk/teaching/grad/handouts/karp.pdf">Reducibility among combinatorial problems (Richard M. Karp)</link>
        </links>
      </event>
      <event id="3459">
        <start>18:00</start>
        <duration>00:25</duration>
        <room>AW1.125</room>
        <slug>graphgen</slug>
        <title>Graphgen - Graph prototyping made easy</title>
        <subtitle/>
        <track>Graph processing</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Graphgen aims at helping people prototyping a graph database, by providing a visual tool that ease the generation of nodes and relationships with a Cypher DSL.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Many people struggle with not only creating a good graph model of their domain but also with creating sensible example data to test hypotheses or use-cases.&lt;/p&gt;

&lt;p&gt;Graphgen aims at helping people with no time but a good enough understanding of their domain model, by providing a visual dsl for data model generation which borrows heavily on Neo4j Cypher graph query language.&lt;/p&gt;

&lt;p&gt;The ascii art allows even non-technical users to write and read model descriptions/configurations as concise as plain english but formal enough to be parseable. The underlying generator combines the DSL inputs (structure, cardinalities and amount-ranges) and combines them with a comprehensive fake data generation library to create real-world-like datasets of medium/arbitrary size and complexity.&lt;/p&gt;

&lt;p&gt;The genrated data can be visualized, directly imported into a remote Neo4j database or exported in a variety of formats.&lt;/p&gt;

&lt;p&gt;Users can create their own models combining the basic building blocks of the dsl and share their data-descriptions with others with a simple link.&lt;/p&gt;</description>
        <persons>
          <person id="1544">Christophe Willemsen</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="AW1.126">
      <event id="3356">
        <start>11:00</start>
        <duration>00:50</duration>
        <room>AW1.126</room>
        <slug>youd_better_have_tested_backups</slug>
        <title>You'd better have tested backups...</title>
        <subtitle/>
        <track>PostgreSQL</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;A PostgreSQL data recovery tale from a true story, where we dig deeper and deeper into the PostgreSQL internals in order to be able to get back some data from a destroyed cluster.&lt;/p&gt;

&lt;p&gt;If that story doesn't leave you wanting to check all your backups before the talk has ended, I don't know what will.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="233">Dimitri Fontaine</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3357">
        <start>12:00</start>
        <duration>00:50</duration>
        <room>AW1.126</room>
        <slug>new_wal_record_format_in_postgresql_95</slug>
        <title>New WAL record format in PostgreSQL 9.5</title>
        <subtitle/>
        <track>PostgreSQL</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The WAL record format was revamped in version 9.5. This presentation goes into the details of the WAL format, and the reasons for the change.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="234">Heikki Linnakangas</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3358">
        <start>13:00</start>
        <duration>00:50</duration>
        <room>AW1.126</room>
        <slug>json_and_postgresql_the_state_of_the_art</slug>
        <title>JSON and PostgreSQL, the State of the Art</title>
        <subtitle/>
        <track>PostgreSQL</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;PostgreSQL 9.4 introduces a new type, JSONB, index types, operators... all kinds of new infrastructure for processing JSON. It's all rather overwhelming.&lt;/p&gt;

&lt;p&gt;We'll look at the current set of tools, including real-life applications and performance metrics, and talk about options as to when it is a great and perhaps still not-as-great idea to use JSON.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1429">Christophe Pettus</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3359">
        <start>14:00</start>
        <duration>00:50</duration>
        <room>AW1.126</room>
        <slug>foreign_data_wrappers_in_postgresql_where_are_we_now</slug>
        <title>Foreign Data Wrappers in PostgreSQL : Where are we now ?</title>
        <subtitle/>
        <track>PostgreSQL</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Since the introduction of the Foreign Data Wrapper API in 9.1, things have evolved rather quickly on the SQL-MED front&lt;/p&gt;

&lt;p&gt;We will look at the promising things coming (hopefully!) for 9.5 in core, but also at the numerous innovative use-cases for FDW: IMPORT FOREIGN SCHEMA, foreign table inheritance, new ways of storing data, and how to combine those features to use PostgreSQL as an ETL.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2866">Ronan Dunklau</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3360">
        <start>15:00</start>
        <duration>00:50</duration>
        <room>AW1.126</room>
        <slug>modern_sql_in_postgresql</slug>
        <title>Modern SQL in PostgreSQL</title>
        <subtitle/>
        <track>PostgreSQL</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;SQL has gone out of fashion lately—partly due to the NoSQL movement, but mostly because SQL is often still used like 20 years ago. As a matter of fact, the SQL standard continued to evolve during the past decades resulting in the current release of 2011. In this session, we will go through the most important additions since the widely known SQL-92, explain how they work and how PostgreSQL supports and extends them. We will cover common table expressions and window functions in detail and have a very short look at the temporal features of SQL:2011 and the related features of PostgreSQL.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2867">Markus Winand</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3361">
        <start>16:00</start>
        <duration>00:50</duration>
        <room>AW1.126</room>
        <slug>large_scale_quality_assurance_in_the_postgresql_ecosystem</slug>
        <title>Large Scale Quality Assurance in the PostgreSQL Ecosystem</title>
        <subtitle/>
        <track>PostgreSQL</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The apt.postgresql.org repository hosts PostgreSQL server packages for seven major releases: all the stable branches plus beta and the devel versions. Targetting two architectures and seven Debian and Ubuntu releases, this is almost 100 combinations in the cross product. On top of that, we build binary packages for various PostgreSQL extensions and applications. Of course no one is able to test thousands of packages manually.&lt;/p&gt;

&lt;p&gt;We are putting much effort into running regression tests on all extensions using pg_regress, and creating system integration tests to be run with the autopkgtest tool. All tests are integrated with our Jenkins build server.&lt;/p&gt;

&lt;p&gt;This talk presents recent advances made in the area and includes examples of bugs found.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1427">Christoph Berg</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="UA2.114 (Baudoux)">
      <event id="3494">
        <start>10:30</start>
        <duration>00:05</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>search_welcome</slug>
        <title>Welcoming Remarks</title>
        <subtitle>Open Source Search Dev Room</subtitle>
        <track>Open source search</track>
        <type>devroom</type>
        <language/>
        <abstract></abstract>
        <description></description>
        <persons>
          <person id="1064">Leslie Hawthorn</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3391">
        <start>10:35</start>
        <duration>00:45</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>search_sphinx</slug>
        <title>Sphinx Search technical highlights</title>
        <subtitle/>
        <track>Open source search</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk will provide you key technical highlights about Sphinx as a full text search engine from internal architecture overview to scalability and high availability strategies.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Detailed talk line up:
- What is Sphinx
- Internal architecture
- Key full text and non-full-text functionality
- Application integration
- On-disk vs Real-time indexes.
- Performance tricks
- Scalability and high availability&lt;/p&gt;</description>
        <persons>
          <person id="549">Vlad Fedorkov</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3474">
        <start>11:25</start>
        <duration>00:45</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>effective_spelling_correction_with_term_relation_graphs_using_lucene_fsts</slug>
        <title>Effective spelling correction with term relation graphs using Lucene FSTs</title>
        <subtitle/>
        <track>Open source search</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Our approach for doing spelling correction has deviated considerably from the default approach Lucene is offering. While Lucene's FuzzyQuery uses a compiled Automaton to filter the dictionary rather efficiently, we directly use normal Automatons and intersect that automaton with a separate FST. This proves to be more efficient for our use case, since it saves memory and time to compile the automaton and also part of the time to identify the matching terms in the dictionary.&lt;/p&gt;

&lt;p&gt;This approach gives us the possibility to store any meta-information with each term, which is used then to pick the top N spellcorrections. We build a term co-occurence graph, where each vertex is a possible spelling correction of a term and each link is the co-occurence in the same document. Each vertex and link get a score based on the meta-information and edit distance. Then we use graph reduction techniques until the graph contains the desired number of spellcorrections.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2949">Anna Ohanyan</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3388">
        <start>12:15</start>
        <duration>00:45</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>apache_solr_as_a_compressed,_scalable_and_high_performance_time_series_database</slug>
        <title>Apache Solr as a compressed, scalable and high performance time series database</title>
        <subtitle/>
        <track>Open source search</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;How can you store 86 billion measurement points in 30 gigabytes and search through it within a few milliseconds on your laptop? A relational database? No! Apache Solr empowers you to do this if you follow a few concepts. The horizontal scalability capabilities of Solr bores away the borders of your laptop and allows you easily to scale out to your needs. In this code intense session we give an introduction how to store time series data in Apache Solr.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;How can you store 86 billion measurement points in 30 gigabytes and search through it within a few milliseconds on your laptop? A relational database? No! Apache Solr empowers you to do this if you follow a few concepts. The horizontal scalability capabilities of Solr bores away the borders of your laptop and allows you easily to scale out to your needs.&lt;/p&gt;

&lt;p&gt;In this session we give an introduction how to store time series data in Apache Solr. QAware has developed an Enterprise Application Performance Analysis Platform on top of Solr. Based on code examples you will see how easy multi-dimensional time series data can be stored and retrieved. We show how Solr features like Facets, Filters and Queries can be used to build graphical user interfaces with an outstanding performance and usability. We also compare this approach to other time series databases like InfluxDB and relational databases like MySQL.&lt;/p&gt;</description>
        <persons>
          <person id="2890">Florian Lautenschlager</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3473">
        <start>13:05</start>
        <duration>00:45</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>elasticsearch_from_the_bottom_up</slug>
        <title>Elasticsearch from the Bottom Up</title>
        <subtitle/>
        <track>Open source search</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk will teach you about Elasticsearch and Lucene's architecture.&lt;/p&gt;

&lt;p&gt;The key data structure in search is the powerful inverted index, which is actually simple to understand. We start there, then ascend through abstraction layers to get an overview of how a distributed search cluster processes searches and changes.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2947">Alex Brasetvik</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3453">
        <start>14:00</start>
        <duration>00:45</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>apache_lucene_5</slug>
        <title>Apache Lucene 5</title>
        <subtitle>New Features and Improvements for Apache Solr and Elasticsearch</subtitle>
        <track>Open source search</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Around FOSDEM 2015, the first alpha/beta releases of Apache Lucene 5 will likely be downloadable. This talk will present the improvements and new features, but also some incompatible changes in the Lucene 5 release. Lucene 5 will focus on data safety: The move to Java 7 will be completed. Lucene now uses all the brand new features (NIO.2) of Java 7 to make the indexing process more stable and resulting indexes durable. Checksums are used during merging to prevent bugs in the underlying JVM or data corruption due to networking errors (e.g., while distributing indexes during recovery in Elasticsearch) to persist in newly created index segments.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The previous major version, Lucene 4 was a major release that introduced index codecs. In Lucene 5, the API around codecs will be cleaned up and will likely get more stable. There are also new features, like a common FilterCache that can be reused by Solr and Elasticsearch.&lt;/p&gt;

&lt;p&gt;In parallel Apache Solr 5 will be released, the first version that will now work as a server out of the box, so Solr is no longer exposed as a webapp. Init.d scripts are included and configuration is managed easier through Zookeeper.&lt;/p&gt;</description>
        <persons>
          <person id="2927">Uwe Schindler</person>
        </persons>
        <links>
          <link href="http://lucene.apache.org">Apache Lucene</link>
        </links>
      </event>
      <event id="3477">
        <start>14:50</start>
        <duration>00:45</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>searching_over_streams_with_luwak_and_apache_samza</slug>
        <title>Searching over streams with Luwak and Apache Samza</title>
        <subtitle/>
        <track>Open source search</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Traditional searches take the form of individual queries over large mostly-stable corpuses of documents.  In this talk, we'll show how we invert this paradigm to allow for searching over streams of documents by combining Samza, a distributed stream-processing framework, with Luwak, a library for efficiently running large numbers of queries over individual documents.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Real-time searching over streams is useful in a number of contexts.  For example, companies may want to detect whenever they are mentioned in a news feed; or a Twitter user might want to see a continuous stream of tweets for a particular hashtag.&lt;/p&gt;

&lt;p&gt;Luwak provides a mechanism for running many thousands of queries over a single document in a highly efficient manner, by filtering out queries that it can detect will not match.  Luwak is designed to run on a single node, holding all registered queries in RAM.  Scaling to higher document throughput, or to more queries, requires parallelization across multiple machines.&lt;/p&gt;

&lt;p&gt;Samza provides a framework for such parallelization, by partitioning and recombining both the document streams and the query set (which can be treated as just another stream), and also provides fault-tolerance mechanisms that allows swift recovery from machine failure, without losing documents or queries.&lt;/p&gt;</description>
        <persons>
          <person id="2953">Alan Woodward</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3449">
        <start>15:45</start>
        <duration>00:30</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>ebisearch_biological_data_search_engine</slug>
        <title>EBISearch - Biological data search engine</title>
        <subtitle/>
        <track>Open source search</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;EBISearch is a text search engine providing access to biological data
resources hosted at EMBL-EBI. We will speak about the history of this
engine, the infrastracture used, some statistics and future plans.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;EBISearch is a text search engine providing access to biological data
resources hosted at EMBL-EBI. These Lucene indexes are organized in a
hierarchy and we offer an easy 'inter-index' (or, in Lucene terms:
inter-domain) navigation via a network of cross-references.&lt;/p&gt;

&lt;p&gt;The data resources represented in the EBI Search engine include:
biological sequences, chemicals and macro-molecular structures,
bio-medical literature abstracts and meta-information related to
biological entities (e.g. genes, transcripts, proteins, etc.)&lt;/p&gt;

&lt;p&gt;The EBISearch evolution/development is influenced by the EMBL-EBI IT
infrastructure, which is designed to cope with great amount of data and
relies on technical choices about data storage on network/distributed
filesystem and heterogeneous type of hosts.&lt;/p&gt;

&lt;p&gt;The EBISearch engine provides search accross ~1.1bn documents updated
to the last biologial data available; we will provide some statistics
about the amount of data we index; indexing parallelisation and the
lifecycle of these indexes.&lt;/p&gt;

&lt;p&gt;At search time the engine organize the indexes in a hierarchy and searches
are executed across most domains. This allows us to benefit of homogeneus
score across the indexes. We rely heavily on the use facets for
filtering results (Lucene taxonomies)..&lt;/p&gt;

&lt;p&gt;EBISearch usage is monitored and analyzed through our application logs
as well as web logs; we will present some statistics about usage and
discuss which kind of theme we are looking into; the focus is in
understanding usage patterns to drive our next development.&lt;/p&gt;

&lt;p&gt;In the future, we need to explore how to cope with the increasing
volume of data that are being generated in the bio-medical fields and on
how to handle requests for new functionalities; for these reasons we will
investigate the usage of other technologies and existing
search engines based on Lucene.
We are also interested in different types of data visualization and we
will briefly present what we have done in this area.&lt;/p&gt;</description>
        <persons>
          <person id="2920">Nicola Buso</person>
        </persons>
        <links>
          <link href="http://www.ebi.ac.uk/ebisearch/">EBI Search</link>
        </links>
      </event>
      <event id="3463">
        <start>16:30</start>
        <duration>00:45</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>the_typed_index</slug>
        <title>The Typed Index</title>
        <subtitle/>
        <track>Open source search</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Besides issues of scaling your search, there are very important aspects concerning search-quality that should not be neglected. Search-quality is mainly controlled by analysis and query parsing. I will talk about frequent problems concerning Lucene analysis and I will show on several examples that usually one analyzer (normal form) is not sufficient, even in a mono-lingual environment but especially in multilingual environments. I will show how our typed index approach allows to solve many of these problems and how we plan to properly treat even mixed-language documents based on this approach.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;If you want to search in a multilingual environment with high-quality language-specific word-normalization you soon realize, that you need different types of terms. For example you cannot use morphologically normalized terms or stemmed terms for every kind of search. For Wildcard- and Fuzzy-Search you need terms that have not been normalized at all or that have been normalized only slightly. Phonetic search adds another kind of normal form. Sometimes search should be case-sensitive (e.g. if you want to distinguish between search for the company "MAN" and the word "man") sometimes it shouldn´t. Semantic search (search for persons, organizations and places) might add another type of terms. Usually one uses different fields to distinguish between different types of terms. I will show that putting different types of terms into the same field and representing their type by e.g. a prefix, has an important advantages. It allows you to use the important information about their relative positions. I even challenge the standard approach of having different fields for different languages because it requires so much configuration effort and because it prevents a reasonable treatment of mixed-language documents. At IntraFind we decided to implement a language chunker based on Ted Dunnings paper "Statistical Identification of Language" and to include it into our next-generation linguistic analyzer for Lucene/Solr/Elasticsearch. It identifies chunks of the same language within text and delegates the analysis to a specified language-specific analyzer, which might be a high-quality IntraFind morphological analyzer, a third-party analyzer or one of the high-quality Lucene Open-Source analyzers e.g. for Chinese and Japanese. Terms of different languages are distinguished by different prefixes (types). In this way we can provide an easy-to-use and very powerful linguistic analyzer that requires almost no configuration effort. You simply index your content and don’t have to care about the language. If there is enough time I would like to add a deep dive into Lucene Analysis with position increments and position length and why this is important e.g. for analyzers that decompose terms such as Lucenes WorldDelimiter Analyzer and IntraFinds German Analyzer which also does word decomposition.&lt;/p&gt;</description>
        <persons>
          <person id="2932">Christoph Goller</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3472">
        <start>17:20</start>
        <duration>00:45</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>querying_your_datagrid_with_lucene,_hadoop_and_spark</slug>
        <title>Querying your datagrid with Lucene, Hadoop and Spark</title>
        <subtitle/>
        <track>Open source search</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Key/Value stores rely on a simple data model represented by a map, where each key appears once. Using such a structure does not necessarily mean giving up on query expressiveness and capability.
This talk will demonstrate what Infinispan can do to empower your analytics needs, from directly running Lucene Queries in a cluster to Hadoop Map Reduce and Spark.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2946">Gustavo Fernandes</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3400">
        <start>18:05</start>
        <duration>00:45</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>elk,_making_sense_of_your_data_not_just_for_logs!</slug>
        <title>ELK, making sense of your data (not just for logs!)</title>
        <subtitle/>
        <track>Open source search</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Elasticsearch, together with his cousins Logstash and Kibana, provide you with a great environment to analyse your data. In this talk we’re going to get inside the eclipse project, analysing what going on, their bugs, etc. If you were wondering what can ELK do for you, this is your talk.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;By ingesting the some parts of the source code, plus the bugzilla repos into elasticsearch we’re able to analyse how the project is performing, getting insides on the project evolution during time. The purpose of this talk is to have a real demo on how to process, store and query data using Elasticsearch and friends, if you always had not much time, after that talk you will be able to start analysing your data.&lt;/p&gt;</description>
        <persons>
          <person id="2896">Pere Urbon-Bayes</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3495">
        <start>18:50</start>
        <duration>00:10</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>search_closing</slug>
        <title>Closing Remarks</title>
        <subtitle>Open Source Search Dev Room</subtitle>
        <track>Open source search</track>
        <type>devroom</type>
        <language/>
        <abstract></abstract>
        <description></description>
        <persons>
          <person id="1064">Leslie Hawthorn</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="UB2.147">
      <event id="3372">
        <start>11:00</start>
        <duration>02:00</duration>
        <room>UB2.147</room>
        <slug>tdf_exam_1</slug>
        <title>LibreOffice Exam Session</title>
        <subtitle/>
        <track>Certification</track>
        <type>certification</type>
        <language/>
        <abstract>&lt;p&gt;LibreOffice Certifications are designed to recognize professionals in the areas of development, migrations and trainings who have the technical capabilities and the real-world experience to provide value added services to enterprises and organizations deploying LibreOffice on a large number of PCs.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;In the future, LibreOffice Certifications will be extended to Level 1 and Level 2 Support professionals.&lt;/p&gt;

&lt;p&gt;The LibreOffice Certification is not targeted to end users, although Certified Training Professionals will be able to provide such a service upon request (although not as a LibreOffice Certification). In general, end user certification is managed by organizations with a wider reach such as the Linux Professional Institute.&lt;/p&gt;</description>
        <persons>
          <person id="2876">LibreOffice Team</person>
        </persons>
        <links>
          <link href="http://www.documentfoundation.org/certification/">The Document Foundation certification program</link>
        </links>
      </event>
      <event id="3317">
        <start>13:30</start>
        <duration>01:45</duration>
        <room>UB2.147</room>
        <slug>lpi_1</slug>
        <title>LPI Exam Session 1</title>
        <subtitle/>
        <track>Certification</track>
        <type>certification</type>
        <language/>
        <abstract>&lt;h3&gt;LPI offers discounted certification exams at FOSDEM&lt;/h3&gt;</abstract>
        <description>&lt;p&gt;As in previous years, the Linux Professional Institute (LPI) will offer discounted certification exams to FOSDEM attendees.
LPI offers level 1, level 2 and level 3 certification exams at FOSDEM with an almost &lt;strong&gt;50% discount&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;For further information and instructions see &lt;a href="https://fosdem.org/certification"&gt;https://fosdem.org/certification&lt;/a&gt;.&lt;/p&gt;</description>
        <persons>
          <person id="1083">LPI Team</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3319">
        <start>16:00</start>
        <duration>01:45</duration>
        <room>UB2.147</room>
        <slug>lpi_2</slug>
        <title>LPI Exam Session 2</title>
        <subtitle/>
        <track>Certification</track>
        <type>certification</type>
        <language/>
        <abstract>&lt;h3&gt;LPI offers discounted certification exams at FOSDEM&lt;/h3&gt;</abstract>
        <description>&lt;p&gt;As in previous years, the Linux Professional Institute (LPI) will offer discounted certification exams to FOSDEM attendees.
LPI offers level 1, level 2 and level 3 certification exams at FOSDEM with an almost &lt;strong&gt;50% discount&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;For further information and instructions see &lt;a href="https://fosdem.org/certification"&gt;https://fosdem.org/certification&lt;/a&gt;.&lt;/p&gt;</description>
        <persons>
          <person id="1083">LPI Team</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="UD2.218A">
      <event id="2960">
        <start>11:00</start>
        <duration>00:30</duration>
        <room>UD2.218A</room>
        <slug>stateful_open_vswitch</slug>
        <title>Connection tracking and stateful services with Open vSwitch</title>
        <subtitle/>
        <track>Network management and SDN</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Open vSwitch has traditionally focused on stateless L2-L4 packet processing. The introduction of stateful connection tracking, NAT, and L7 service integration extend the scope of Open vSwitch usage. In this talk, we will discuss the introduction of stateful services and cover the implementation of reflexive ACL and integration of L7 DPI on the data center edge.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2662">Thomas Graf</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3335">
        <start>11:30</start>
        <duration>00:30</duration>
        <room>UD2.218A</room>
        <slug>openstack_opencontrail</slug>
        <title>SDN for Massively Scalable Clouds</title>
        <subtitle>Combining OpenStack and OpenContrail</subtitle>
        <track>Network management and SDN</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In this presentation, Kristian Köhntopp and Martin Loschwitz from SysEleven in Berlin will explain how SysEleven uses OpenContrail to create decent SDN networking for the company's OpenStack platform.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;A lot has been said about Software Defined Networking in the Cloud Computing context. Most modern solutions are based on technologies such as OpenFlow, Open vSwitch and Open Daylight. And they almost all have serious technical issues avoiding proper scale out and sometimes even impacting normal operations in small-scale environments. If you’re out for SDN today, you will find yourself soon looking out for alternatives. OpenContrail is one of them: Based on standard protocols such as MPLS, OpenContrail allows you to realize virtual networks while retaining the advantages provided by real hardware.&lt;/p&gt;

&lt;p&gt;At SysEleven, we’ve been working on an OpenStack-based cloud offering over the last year. One of the major design decisions was to go with OpenContrail as the stack for Software Defined Networking. This presentation will give you an insight into why we found other solutions such as OpenFlow inappropriate and what the challenges were in getting OpenContrail up and running. You will learn what our current SDN scenario looks like and what conclusions we have come to based on the experience that we’ve made.&lt;/p&gt;</description>
        <persons>
          <person id="2856">Martin Loschwitz</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2910">
        <start>12:00</start>
        <duration>00:30</duration>
        <room>UD2.218A</room>
        <slug>midonet_101</slug>
        <title>Midonet 101! Face to face with the distributed SDN solution</title>
        <subtitle/>
        <track>Network management and SDN</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Midonet, our distributed SDN solution, has been finally released to the the community and we’d like to share our excitement with you.
You’ll learn about the core concepts, why it’s different, its core design and why you would choose it for your project/business. Or not.
You’ll be introduced to concepts like Topology Aware Edges and JIT Datapath flow computation as well as our distributed agent model.
You’ll learn why we strongly believe in having intelligent edges and how this impact the overlay topology definition as well as the NFV implementation.
We’ll share with you the challenges we’re facing, our ideas and our product vision.
If you believe in the SDN future, please join us, bring your ideas and be part of the community we’re building.  Fun included!&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2624">Antonio Sagliocco</person>
          <person id="2962">Alex Bikfalvi</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2938">
        <start>12:30</start>
        <duration>00:30</duration>
        <room>UD2.218A</room>
        <slug>openlisp</slug>
        <title>OpenLISP: Open source Locator/ID Separation Protocol implementation </title>
        <subtitle/>
        <track>Network management and SDN</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Due to scalability issues that the current Internet is facing, the research community has re-discovered the Locator/ID Split
paradigm. Among the various proposals, the most successful is LISP (Locator/ID Separation Protocol), which is currently
discussed at the IETF and strongly pushed by Cisco.The talk  overviews OpenLISP (www.openlisp.org), an open source
implementation of LISP. The talk is organized in two parts. A first part will overview the main principles of LISP and the way it works.
The second part, which is also the main part of the presentation, will describe the kernel implementation work done.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;In the last years both academia and industry have worked toward new Internet architecture proposals, due to the awareness that the current architecture is facing unforeseen scalability issues, concerning the restless increase of the BGP routing tables, addressing, mobility, multihoming, and inter-domain traffic engineering.
The general consensus is that splitting the locator and identifier roles of IP addresses solves these issues and is necessary for the Future Internet architecture.
However, in practice, several constraints have to be taken into account in order to design a viable solution that can be incrementally deployed, without disrupting the existing communication infrastructure, whilst providing benefits, hence incentives, for early adopters.
An instance of such a paradigm is the Locator/ID Separation Protocol (LISP). LISP was first proposed by Cisco in the IRTF (Internet Research Task Force) and is now under development in the IETF (Internet Engineering Task Force). Aiming at being incrementally deployable, LISP has evolved from its initial design in order to accommodate the constraints that the current Internet imposes, but still offering an effective solution for the scalability issues.
Our goal is not to convince the reader about the merits of LISP, or the general Locator/ID Split paradigm, and neither to provide numerical results of its performance.
Rather, the talk aims providing an overview on how LISP works and what are the basic principles, including its implementation aspects.&lt;/p&gt;</description>
        <persons>
          <person id="2643">Luigi Iannone</person>
        </persons>
        <links>
          <link href="http://www.lisp4.net">Experimental Deployment</link>
          <link href="http://datatracker.ietf.org/wg/lisp/charter/">IETF LISP WG Page</link>
          <link href="http://www.openlisp.org">OpenLISP Project</link>
        </links>
      </event>
      <event id="3047">
        <start>13:00</start>
        <duration>00:30</duration>
        <room>UD2.218A</room>
        <slug>packet_filtering_pflua</slug>
        <title>High-performance packet filtering with Pflua</title>
        <subtitle/>
        <track>Network management and SDN</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Pflua is a fresh implementation of the well-known pcap-filter language (pflang), designed to filter network traffic in the Snabb Switch.  It is, to our knowledge, the fastest pflang implementation. This talk introduces pflua, its two compilation pipelines, its performance, and shows a demonstration of pflua filtering traffic at 10Gb line-speed in a Snabb Switch.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Packet filtering generally works by taking pflang expressions and compiling them to bytecode for the BPF virtual machine. Pflua, a new pflang implementation, instead compiles pflang expressions to Lua code, which are then optimized at run-time to native machine code by a trace compiler (LuaJIT). Tracing seems a particularly appropriate strategy for the packet filtering use case, as you end up with linear machine code that reflects the shape of actual network traffic.&lt;/p&gt;

&lt;p&gt;Pflua is a project that lives at the intersection of networking and compilers. Its pflang to Lua compiler builds an AST that is exhaustively optimized, folding constants and tests, inferring ranges of expressions and packet offset values, hoisting assertions that post-dominate success  continuations, etc. For compatibility, pflua also has a BPF bytecode to Lua compiler, whch leaves the first layer of compilation to libpcap, while benefitting from pflua's much better run-time performance.&lt;/p&gt;

&lt;p&gt;Join us in this Pflua presentation and learn about:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt; The architecture of Pflua.&lt;/li&gt;
&lt;li&gt; Compiler optimization techniques implemented in Pflua.&lt;/li&gt;
&lt;li&gt; Benchmarking. How Pflua compares to other packet-filtering solutions. Spoiler: it is sometimes several times faster.&lt;/li&gt;
&lt;li&gt; Real-world demo: filtering with pflua and Snabb Switch.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <persons>
          <person id="446">Andy Wingo</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2723">
        <start>13:30</start>
        <duration>00:30</duration>
        <room>UD2.218A</room>
        <slug>dpdk_performance</slug>
        <title>DPDK performance</title>
        <subtitle>How to not just do a demo with DPDK</subtitle>
        <track>Network management and SDN</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The Intel DPDK provides a platform for building high performance Network Function Virtualization applications. But it is hard to get high performance unless certain design tradeoffs are made. This talk focuses on the lessons learned in creating the Brocade vRouter using DPDK. It covers some of the architecture, locking and low level issues that all have to be dealt with to achieve 80 Million packets per second forwarding.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2453">Stephen Hemminger</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2877">
        <start>14:00</start>
        <duration>00:30</duration>
        <room>UD2.218A</room>
        <slug>dpdk_and_kernel</slug>
        <title>Use DPDK and the Linux Kernel</title>
        <subtitle>Open and High Performance Network Function Virtualization Infrastructure (NFVI)</subtitle>
        <track>Network management and SDN</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The SDN Community is building network automation along with OpenStack Neutron's capabilities. This creates connectivity based on Linux kernel functions, prevents single vendor solution lock-in and avoids building proprietary data paths. With DPDK and packet processing software to create NFVI, it is possible to keep this openness while both introducing performance and avoiding Neutron plugins for proprietary technologies. In this presentation, Vincent will show how DPDK applications can be combined on the host and guest of the network, and compute nodes of OpenStack scenarios, in order to sustain high performance for north-south and east-west traffic that is required for NFV solutions. 100 Gbps of packet processing throughput examples will be demonstrated.&lt;/p&gt;

&lt;p&gt;Down the road, this openness shall apply on any packet processing data plane logic: on x86 hypervisors, ARM CPUs, new IBM Power8 or PCI SmartNICs (Cavium, Broadcom, Tilera).&lt;/p&gt;

&lt;p&gt;Vincent will show that in networking, "Open" and "SPEED MATTERS" mean:
- keep Linux kernel stack
- freedom of Hardware IOs&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2600">Vincent Jardin</person>
        </persons>
        <links>
          <link href="http://dpdk.org">DPDK</link>
          <link href="https://www.opnfv.org/">OPNFV</link>
        </links>
      </event>
      <event id="3306">
        <start>14:30</start>
        <duration>00:30</duration>
        <room>UD2.218A</room>
        <slug>project_calico</slug>
        <title>Project Calico: A pure Layer 3 approach to virtual networking.</title>
        <subtitle/>
        <track>Network management and SDN</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;An important part of building a virtual datacenter is networking. The common wisdom in the field is that providing virtual layer 2 networks built using one of the many open source vSwitches is the correct approach. This talk covers Project Calico, an open source attempt to provide an alternative approach by re-architecting the data center in the image of the Internet, aiming for simplicity, scale and efficiency.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2843">Cory Benfield</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2836">
        <start>15:00</start>
        <duration>00:30</duration>
        <room>UD2.218A</room>
        <slug>haka</slug>
        <title>HAKA : A security oriented language</title>
        <subtitle/>
        <track>Network management and SDN</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Haka is an open source, security oriented, language and framework that allows to
analyze live (or captured) traffic and easily dissect and modify it. Haka is
based on Lua which is a simple, lightweight and efficient scripting language.
The goal of Haka is to simplify the writing of network filtering rules using
a common high-level language, hide the complexity of network protocol dissection
to the end-user while still allowing complex tasks (such as packet injection)
to happen transparently on a live stream.&lt;/p&gt;

&lt;p&gt;This presentation will introduce HAKA's capabilities and show
some examples of data manipulation both at the packet and at the stream level.
An example of packet dissector and grammar implementation  will also be shown
to demonstrate how protocol management is handled in Haka&lt;/p&gt;

&lt;p&gt;more information at http://www.haka-security.org/&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="590">Jérémy Rosen</person>
        </persons>
        <links>
          <link href="http://www.haka-security.org/">http://www.haka-security.org/</link>
        </links>
      </event>
      <event id="2937">
        <start>15:30</start>
        <duration>00:30</duration>
        <room>UD2.218A</room>
        <slug>vxvde</slug>
        <title>VXVDE: almost zero configuration virtual networking</title>
        <subtitle/>
        <track>Network management and SDN</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;VXVDE does not require any program to dispatch packets: vxvde has been implemented as a module of the libvdeplug library. It does not need
any infrustructure other than a well configured IPv4 or IPv6 network supporting IP multicast. VXVDE has a very simple configuration. A valid IP multicast address is enough to configure a "switchless switched" virtual network.&lt;/p&gt;

&lt;p&gt;Unlike VXLAN, VXVDE does not require any Virtual Tunnel End Point (VTEP). Virtual Machines manage their own access to the virtual network. VXVDE unicast packets are mapped on UDP packets traveling on a direct path from the sending virtual machine to the receiving one, without any copy, any packet retransmission or extra header.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2639">Renzo Davoli</person>
        </persons>
        <links>
          <link href="http://sourceforge.net/p/vde/svn/HEAD/tree/branches/rd235/vde-2/">source code</link>
        </links>
      </event>
      <event id="2959">
        <start>16:00</start>
        <duration>00:30</duration>
        <room>UD2.218A</room>
        <slug>pyroute2_netlink</slug>
        <title>[pyroute2] On the peaceful uses of the Netlink protocol</title>
        <subtitle/>
        <track>Network management and SDN</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The Netlink protocol is a Linux framework, that implements an easy to use communication channel between the kernel and userspace. This discussion is planned to highlight some common Netlink issues and practices, that can be interesting to other low-level network related projects.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The purpose of the pyroute2 project is to provide [not only] Python developers with a simple and reliable Netlink library, which could be used for the network setup as well as for the traffic processing, or even process monitoring and audit. While implementing it, we've met a number of issues coming from different parts of different Netlink subsystems. No one of the issues is a bug sensu stricto, but all of them seriously affect the final implementation.&lt;/p&gt;

&lt;p&gt;So, it would be nice to share and discuss shortly the experience of the implementation solutions. Almost every low-level network related project has to work with the Netlink features and issues, and some of this knowledge can and, probably, should be generalized.&lt;/p&gt;

&lt;p&gt;The agenda of the discussion is to show Netlink tricks and their impact on different levels: from the lowest protocol level to the high-level OS network setup. Will be prepared a demo of different projects interoperability, including Netlink proxying.&lt;/p&gt;</description>
        <persons>
          <person id="1733">Peter V. Saveliev</person>
        </persons>
        <links>
          <link href="https://github.com/svinota/pyroute2/">the project home</link>
        </links>
      </event>
      <event id="2948">
        <start>16:30</start>
        <duration>00:30</duration>
        <room>UD2.218A</room>
        <slug>hardware_switches</slug>
        <title>hardware switches - the opensource approach</title>
        <subtitle/>
        <track>Network management and SDN</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Imagine buying off the shelf switch hardware, install Fedora (or any other
distribution) and configure it using standard linux tools. This is not
possible at the moment primarily because of lack of unified and consistent
platforms and driver interfaces. We are working to change that.&lt;/p&gt;

&lt;p&gt;The current state of support for switch chips in Linux is not good. Each
vendor provides userspace binary sdk blob that only works with their
chips. Each of this blobs has proprietary APIs. To get switch chips
properly supported there's need to introduce a new infrastructure directly
into Linux kernel and to work with vendors to adopt it.&lt;/p&gt;

&lt;p&gt;This talk presents the current effort to unify and uphold the Linux
networking model across the spectrum of devices which is necessary to make
Linux the cornerstone of industrial grade networking. The scope of this
talk covers state of art with current implementation of standard commodity
switches such as top of rack switches, small home gateway device as well
as SR-IOV NIC embedded switches.&lt;/p&gt;

&lt;p&gt;A device model and driver infrastructure will be presented for
accelerating the Linux bridge, Linux router, accelerated host virtual
switches and flow level offloads when supported by the hardware
underneath.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2620">Jiří Pírko</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3200">
        <start>17:00</start>
        <duration>00:30</duration>
        <room>UD2.218A</room>
        <slug>knot_dns</slug>
        <title>Knot DNS</title>
        <subtitle>independent high-performance DNS server</subtitle>
        <track>Network management and SDN</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Knot DNS is a high-performance authoritative-only modern open-source DNS server.  In this talk Knot DNS will be presented we will present the motivation, the goals and the current state of the project.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The Knot DNS supports most of the DNS standards and it has been already deployed at several TLDs and DNS hosters.  Deployment at two root servers are already planned in upcoming months as an alternative to Bind 9 and NSD.  The goal of the presentation is to show the audience the alternative DNS server that can be used to increase code diversity of used DNS software on the Internet.&lt;/p&gt;</description>
        <persons>
          <person id="2933">Jan Včelák</person>
        </persons>
        <links>
          <link href="https://www.knot-dns.cz/">Knot DNS Homepage</link>
          <link href="https://www.knot-dns.cz/pages/documentation.html">Knot DNS Documentation</link>
        </links>
      </event>
      <event id="2868">
        <start>17:30</start>
        <duration>00:30</duration>
        <room>UD2.218A</room>
        <slug>managing_networks_snmp</slug>
        <title>Managing Networks in a Software-Defined Future</title>
        <subtitle>How OpenNMS is coping, and: is SNMP finally dead?</subtitle>
        <track>Network management and SDN</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Since the late 1980s, the discipline of network management has kept up well enough with virtual notions in networks while continuing to rely heavily on the Simple Network Management Protocol (SNMP). The rise of software-defined networks poses similar challenges to the ones brought to the systems management space by server virtualization and cloud computing, leaving practitioners to wonder how much retooling will be needed to cope in this new world.&lt;/p&gt;

&lt;p&gt;As the oldest enterprise-grade, open-source network management platform, OpenNMS has proved fairly adaptable so far. This talk will cover where we've been, what's possible given today's realities, and what we expect will be the toughest challenges in the future.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2597">Jeff Gehlbach</person>
          <person id="2935">Markus Neumann</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3324">
        <start>18:00</start>
        <duration>00:30</duration>
        <room>UD2.218A</room>
        <slug>networkd_status</slug>
        <title>networkd status update</title>
        <subtitle/>
        <track>Network management and SDN</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;A brief introduction to networkd and an update on recent features&lt;/p&gt;</abstract>
        <description>&lt;p&gt;systemd-networkd is the network management stack that comes with systemd. In this talk I'll introduce the basic concepts, and outline where we are headed next. I will also discuss the possibility of code-reuse and colaboration with similar projects (in particular ConnMan and NetworkManager), how we have done this so far, and how we plan to do it going forward.&lt;/p&gt;</description>
        <persons>
          <person id="2762">Tom Gundersen</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2951">
        <start>18:30</start>
        <duration>00:30</duration>
        <room>UD2.218A</room>
        <slug>networkmanager_update</slug>
        <title>NetworkManager v1.0 status update</title>
        <subtitle>What happened. Where are we. What comes next for NetworkManager</subtitle>
        <track>Network management and SDN</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Give a status update on NetworkManager and talk about the current 1.0 release&lt;/p&gt;</abstract>
        <description>&lt;p&gt;NetworkManager 1.0 will be released by the time of FOSDEM15.&lt;/p&gt;

&lt;p&gt;Talk shortly the major changes from the last year.
Show highlights of 1.0 and discuss future plans.&lt;/p&gt;</description>
        <persons>
          <person id="2656">Thomas Haller</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="K.3.201">
      <event id="3332">
        <start>11:00</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_optimizing_main_loop</slug>
        <title>Optimizing the Libre Office Main Loop</title>
        <subtitle>Munich students get their hands on Libre Office</subtitle>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;A Lightning Talk with a Munich student, about his first project in Libre Office: Optimizing the Libre Office Main Loop.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2853">Tobias Madl</person>
        </persons>
        <links>
          <link href="https://wiki.documentfoundation.org/Development/LHM_LiMux/Main_Loop">Main Loop</link>
        </links>
      </event>
      <event id="3221">
        <start>11:20</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_cpp11_libreoffice</slug>
        <title>C++11 and LibreOffice</title>
        <subtitle>The future has arrived (it was about time)</subtitle>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;C++ has evolved quite a bit over the years, and the new C++11 standard finally has usable implementations on all relevant platforms.
We aim to give an overview of the current status of C++11 adoption in the LibreOffice project.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2803">Michael Stahl</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3333">
        <start>11:40</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_opengl</slug>
        <title>OpenGL backend for LibreOffice</title>
        <subtitle>Rendering everything through OpenGL</subtitle>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk will present the work to integrate an OpenGL vcl backend.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="775">Markus Mohrhard</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3350">
        <start>12:00</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_openglcanvas_libreoffice</slug>
        <title>OpenGLCanvas in Libreoffice</title>
        <subtitle/>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Munich student talks about his first project for libreoffice: Implementing a OpenGL canvas backend.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2854">Michael Jaumann</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3362">
        <start>12:20</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_ide_integration</slug>
        <title>LibreOffice IDE integration</title>
        <subtitle/>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;LibreOffice recently has finished to use a consistent build system, this made it easy to now allow it to be debugged, modified and improved in an IDE for developers.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;This lecture will show how we improved LibreOffice to be debugged, edited and hacked upon in an IDE with nice features like code-completion. It will show some examples on how easy this makes contributing to LibreOffice and how the support of such tools can make you an contributor too.&lt;/p&gt;</description>
        <persons>
          <person id="2082">Bjoern Michaelsen</person>
        </persons>
        <links>
          <link href="http://skyfromme.wordpress.com/2013/12/04/libreoffice-ide-integration/">the first IDE integration implemented: Kdevelop</link>
        </links>
      </event>
      <event id="3337">
        <start>12:40</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_pdf_signing</slug>
        <title>PDF signing in LibreOffice: no longer experimental</title>
        <subtitle/>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;During the Google Summer of Code in 2012, Gökçen Eraslan implemented digital signatures for LibreOffice's PDF export. There were some glitches left in the feature, for instance it did not really work well on Windows, which is where most of our users are. Because of that, the functionality was marked as "experimental" and was thus not easily available to users. Recently, thanks to a crowdfunding effort, we had the opportunity to improve this feature. The presentation will describe that work and show how to use the feature.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2013">Tor Lillqvist</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3233">
        <start>13:10</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_continuous_integration</slug>
        <title>CI for LibreOffice</title>
        <subtitle>Jenkins-Gerrit Integration and other woes</subtitle>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;LibreOffice has been using gerrit for some time. This present an on-going effort to integrate jenkins into the mix
to provide multi-platform build verification and test as early in the dev process as possible.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2808">Norbert Thiebaud</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3348">
        <start>13:30</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_gerrit_code_review</slug>
        <title>New features in Gerrit Code Review 2.11</title>
        <subtitle>Support for browser based Gerrit workflow</subtitle>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Gerrit Code Review is Git based pre-merged code review tool, used by LibreOffice
project. And as thus is heavily used by LibreOffice developers in different roles,
either as a contributor or as a core reviewer.&lt;/p&gt;

&lt;p&gt;In this talk the long awaited feature (that GitHub and other platforms already support):
the ability to create, populate and amend Gerrit changes directly in browser is explained.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Priot to Gerrit 2.11 to address reviewer comments, (even typos) The Gerrit
change must be amended in local environment and repushed to Gerrit again.&lt;/p&gt;

&lt;p&gt;Starting from gerrit 2.11 changes can be created and edited directly in the browser.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;New changes can be created and populated directly in the browser via
a 'Create Change' button on the project info screen.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;New follow-up changes can be created via a 'Follow-Up' button on the change
screen&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Content editing takes place in a full screen CodeMirror window with support for
themes, syntax highlighting, different key maps (Emacs, Vim, Default).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The CodeMirror screen can be configured in the same way as the side-by-side
diff screen.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The file table in the change screen supports edit mode with seamless navigation
to CodeMirror for editing.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Edit mode can be started from the side-by-side diff screen with seamless
navigation to CodeMirror.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The commit message can be changed in context of change edit. The 'Edit Message'
button is still supported, but now it creates a change edit that must be published.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Files can be added, deleted, restored and modified directly in browser.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;User-specific configuration dedicated to edit mode in CodeMirror are stored in
the &lt;code&gt;All-Users&lt;/code&gt; repository rather than in the database.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In this talk i will present the concepts and go into implementation details.&lt;/p&gt;</description>
        <persons>
          <person id="2861">David Ostrovsky</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3205">
        <start>13:50</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_texboxes_writer</slug>
        <title>TextBoxes: complex shapes with complex content in LibreOffice Writer</title>
        <subtitle/>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;LibreOffice Writer was always capable of handling complex content in a floating
TextFrame, which allows fields, tables, embedded objects and similar features.
But what about non-rectangular shapes? Or even rectangular ones, but with
rounded corners? TextBoxes is a new concept that allows attaching complex
Writer content to a drawinglayer custom shape: having both custom geometry
without being limited to simple editeng content. Come and see where we are,
what still needs to be done, and how you can help.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="779">Miklos Vajna</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3256">
        <start>14:10</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_calc_dependency_performance</slug>
        <title>LibreOffice Calc dependency &amp; performance work</title>
        <subtitle>how we made things faster &amp; better</subtitle>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Calc has undergone some revolutionary changes in recent years to improve parallelism and enable OpenCL calculation, I'll explain
this base-line that we've reached. I'll then explain recent improvements from Collabora in the dependency engine to further accelerate computation, and to shrink memory usage of the spreadsheet. Then we'll look at the next steps, and where you can get involved.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="425">Michael Meeks</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3370">
        <start>14:30</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_reaching_out</slug>
        <title>OpenOffice reaches out: the technical angle</title>
        <subtitle/>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;It is time for Apache OpenOffice to change direction and focus outwards, including collaboration with other projects. Leaving all the non-technical issues out, we will discuss what the technical ones are and how they can be solved.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1013">Jan Iversen</person>
          <person id="1275">Andrea Pescetti</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3334">
        <start>15:00</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_improving_libreoffice_quality</slug>
        <title>Improving LibreOffice quality</title>
        <subtitle>Coverity and crash testing</subtitle>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk will present some of the automated tools that the LibreOffice project is using to improve the quality of the code. This includes coverity where the LibreOffice project managed to reach a nearly perfect defect density score of 0.00 and the import/export crash testing with about 75000 documents.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="775">Markus Mohrhard</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3012">
        <start>15:20</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>documents_torturing</slug>
        <title>Torturing your software with 124 ODF file formats</title>
        <subtitle>Bringing gleeful sadism back to software development and base your opinions on facts</subtitle>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Good software can take a hit. Most software can't. The OpenDocument Format (ODF) specification is quite large and very important. Now that it is being adopted more and more, many strange and wonderful documents will be created by custom software that claim to be ODF documents. The ODF softwares of the world should be prepared. That's why ODFAutoTests helps you to create outlandish documents and lets you run them through your software.&lt;/p&gt;

&lt;p&gt;This talk will include an enticing argument for writing tests and will present the audience with the data of running the current tests on the current software.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="101">Jos van den Oever</person>
        </persons>
        <links>
          <link href="http://github.com/vandenoever/odfautotests">git repo</link>
        </links>
      </event>
      <event id="3352">
        <start>15:40</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_ux_easy_hacks</slug>
        <title>LibreOffice Design/UX Easy Hacks</title>
        <subtitle>How you can get involved</subtitle>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;LibreOffice 4.4 has got many user interface improvements - but there's still much more to do.  Come and hear how you can get involved, and can help make LibreOffice more usable &amp;amp; more beautiful!&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="779">Miklos Vajna</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3329">
        <start>16:00</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_document_liberation_project</slug>
        <title>Document Liberation Project</title>
        <subtitle>Tools and framework for achieving preservation of digital content</subtitle>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The Document Liberation Project has already developed a dozen of import libraries which have been integrated by software such as: Abiword, Calligra, CorelDRAW File Viewer, Inkscape, LibreOffice and Scribus.
Besides short overview of motivations behind the project creation, this lecture will present the technical details of the framework used by the Document Liberation Project, as well as the different home-brewed introspection tools that we use. This are all free software tools that can be of use for wide range of other FLOSS projects.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="315">Fridrich Strba</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3355">
        <start>16:20</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_libreoffice_odf</slug>
        <title>LibreOffice and ODF</title>
        <subtitle/>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Open Document Format (ODF) is the native file format of LibreOffice. It means that all features of the document model must be represented at the ODF level, too. The features, which cannot be represented in ODF version 1.2, need to be submitted to OASIS to be included in the next version of the standard. My talk gives an overview of recent work and plans of the LibreOffice project related to ODF standardization.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="313">Andras Timar</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3365">
        <start>16:40</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_corinthia_mobile</slug>
        <title>Corinthia a new idea for document handling</title>
        <subtitle>editing on mobile devices or using multiple document formats?</subtitle>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Corinthia is a brand new apache project, based on the very successfull UXwrite editor. Peter Kelly decided earlier this year to make his editor open source (Thanks), and we rapidly built a community around it. Corinthia is firstly a toolkit for document format conversion, that ffacilitates round trip conversion without data loss. The engine us a complete new idea comming from desktop editors like LO and AOO. The idea of the editor is not to replace a full fledged desktop editor, but merely to let you correct minor things when you discuss your work with friends wich of course happens on a tablet.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The corinthia project is a new apache project, and while we look at lot at LO and AOO we look for new ideas.....actually some of the LO/AOO developers told us to start fresh......here we are, cone listen to what we are and will do.....one person named us AOO light, for sure that is not who we are, but we would love to have discussions and participation with the people if both LO and AOO.&lt;/p&gt;

&lt;p&gt;The presentation will show where we are and where we would like to be.....but honestly a big debate is hoped for, and stay sure,  some remarks will be made to provoke a debate.&lt;/p&gt;

&lt;p&gt;The preseneter is a commiitter in AOO (former PMC) and a STRONG believer in cooperation.&lt;/p&gt;</description>
        <persons>
          <person id="1013">Jan Iversen</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3351">
        <start>17:00</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_libreoffice_android</slug>
        <title>LibreOffice on Android</title>
        <subtitle/>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Come and hear about what we had to do to get LibreOffice on the Android platform - how we stripped down Fennec (Firefox for Android), combined it with the LibreOfficeKit, and still got an .apk that fits the 50M limit of the Play store.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="317">Jan Holesovsky</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3330">
        <start>17:20</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_android_vision</slug>
        <title>A vision about a LibreOffice document manager for Android</title>
        <subtitle/>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The document manager will bridge the Android port of LibreOffice with the services provided by this operating system. We will show the current status, specially regarding the implementation of the cloud storage support funded by The Document Foundation, and present a vision of the future of this component as a full featured, Android-centric document manager.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2852">Jacobo Aragunde Pérez</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3367">
        <start>17:40</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_public_administration</slug>
        <title>Adapting Apache OpenOffice for adoption in a public administration: configuration, Sharepoint webdav integration and an extension to help users exchange ODF files</title>
        <subtitle/>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk aims to give an overview of the introduction of the ODF standard and Apache OpenOffice in an Italian public administration with more than 3000 users, addressing briefly the main technical issues and solutions. In particular we will talk about: 1) the configuration of OpenOffice, extended with community developed and custom extensions to help users in the everyday work 2) the interoperability with Sharepoint through the webdav protocol and what we developed in Apache OpenOffice for the correct interaction 3) our extension to simplify picking the right format for file exchange, to answer the users' ubiquitous question "Ok but… should I use ODF to send/share this?”, in relation to our ODF census project in Italy.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2872">Maurizio Berti</person>
          <person id="2977">Giovanni Grazia</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3230">
        <start>18:00</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>editors_lightning_talks</slug>
        <title>Lightning talk slot</title>
        <subtitle>Demo your cool hack in 5 minutes!</subtitle>
        <track>Open Document editors</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Lightning Talks&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2006">Thorsten Behrens</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="K.3.401">
      <event id="3507">
        <start>10:30</start>
        <duration>00:05</duration>
        <room>K.3.401</room>
        <slug>perl_devroom</slug>
        <title>Welcome to the Perl devroom!</title>
        <subtitle>And oh man, this year is special!</subtitle>
        <track>Perl</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Introduction to the Perl devroom.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="582">Claudio Ramirez</person>
          <person id="2442">Wendy G.A. van Dijk</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3502">
        <start>10:35</start>
        <duration>00:20</duration>
        <room>K.3.401</room>
        <slug>metacpan</slug>
        <title>CPAN is amazing, MetaCPAN is amazing, and APIs are great</title>
        <subtitle/>
        <track>Perl</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;CPAN is Perl's killer feature. The information available in CPAN is massive, but without a proper API, it's difficult to work with. MetaCPAN provides this API, and MetaCPAN::Client provides the ability to work with the API in a sophisticated and comfortable way.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2968">Mickey Nasriachi</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3498">
        <start>10:55</start>
        <duration>00:40</duration>
        <room>K.3.401</room>
        <slug>modules_ecosystem_perl6</slug>
        <title>Leapfrogging the bootstrap</title>
        <subtitle>Bringing whole module ecosystems to Perl 6. </subtitle>
        <track>Perl</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Perl 6 and its implementation Rakudo are rapidly becoming ready for serious use. What's missing now is the huge module ecosystem that makes Perl 5 the swiss army chain saw it is.&lt;/p&gt;

&lt;p&gt;Inline::Perl5 attempts to solve this by allowing you to use Perl 5 modules (including XS modules) in Perl 6. If that's not enough, Inline::Python may jump in and safe the day.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2965">Stefan 'nine' Seifert</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3496">
        <start>11:35</start>
        <duration>00:50</duration>
        <room>K.3.401</room>
        <slug>perl6_lang_spec_lessons_learned</slug>
        <title>How (not) to create a language specification for Perl 6</title>
        <subtitle> Lessons learned</subtitle>
        <track>Perl</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In the process of designing, implementing, and using Perl 6 (or any programming language), people often refer to ""the language specification"" as a commonly understood and perhaps self-evident fixed reference point.  For mature languages this can be reasonable, because the people using that language have generally developed a shared understanding of what constitutes the language's specification.
But languages are not all specified in the same manner, and in a new or rapidly evolving language it may be unwise to prematurely commit to an inflexible specification.  Perl 6 has gone through several imprecise notions of what constitutes its specification, such as design documents like the Synopses, reference implementations of certain features, and the ""official"" test suite.  This imprecision sometimes leads to misunderstandings among developers, confusion for newcomers to the language, and difficulty communicating with external audiences.
This talk presents a historical perspective on how Perl 6's specification process has evolved over the past decade: identifying things we've done (or are doing) wrong, things we've gotten very right, and ideas of what that process ought to look like going forward.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2963">Patrick 'pmichaud' Michaud</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3497">
        <start>12:25</start>
        <duration>00:50</duration>
        <room>K.3.401</room>
        <slug>c_bindings_a_journey</slug>
        <title>Binding C libraries</title>
        <subtitle>A journey</subtitle>
        <track>Perl</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Pure Perl is awesome. But often there are situartions where Pure Perl™ means that your program will either be slow, or it will not comply with industry standards. On the other hand, using battle tested open source libraries is a sane choice, but implementing the bindings to a language like Perl can be quite challenging. This talk is a walk-through this business, illustrating the bindings to the library libxml.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2964">Tobias 'FROGGS' Leich</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3501">
        <start>13:15</start>
        <duration>00:40</duration>
        <room>K.3.401</room>
        <slug>dancer_status</slug>
        <title>Dancer Status</title>
        <subtitle/>
        <track>Perl</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The status of Dancer. Version 1 vs version 2. Development efforts. Progress, lack of progress, and everything in between.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="210">Sawyer X</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3504">
        <start>13:55</start>
        <duration>00:50</duration>
        <room>K.3.401</room>
        <slug>perl6_for_mortals</slug>
        <title>Perl 6</title>
        <subtitle>A Dynamic Language for Mere Mortals</subtitle>
        <track>Perl</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;With the complete failure of security forces to contain the impending threat of Perl 6, developers are beginning to investigate it themselves. Unfortunately, many of the combatants who wield Camelia are so enraptured that they post long sermons extolling the virtues of hyperoperators, meta-object protocols, and composable concurrency, scaring off the faithful.
Those sermons are important. However, it turns out Perl 6 is actually a fairly easy weapon to use and for day-to-day use, it's simple. This talk will take things down a notch or three and show you how simple basic Perl 6 really is. The talk might even be less objectionable than this description.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1554">Curtis 'Ovid' Poe</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3503">
        <start>14:45</start>
        <duration>00:50</duration>
        <room>K.3.401</room>
        <slug>perl5_22_things_to_come</slug>
        <title>Perl 5.22</title>
        <subtitle>The Shape of Things to Come</subtitle>
        <track>Perl</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Every spring, there's a new version of perl.  Every new version of perl ships with "perldelta," the comprehensive list of changes in that version.  Every summer, rjbs (the Perl 5 project lead) tries to summarize the perldelta, omitting the tedious and obscure in favor of the awesome and exciting.  This winter only, you can get a sneak preview of the yet-unreleased Perl 5.22's planned changes, a recap of the best bits of 5.20, and the faintest whiff of changes under discussion for next&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2969">Ricardo Signes</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3499">
        <start>15:35</start>
        <duration>00:50</duration>
        <room>K.3.401</room>
        <slug>life_without_plastic_bags</slug>
        <title>Life without plastic bags</title>
        <subtitle>On reducing the amount of Collectable Garbage, for better performance and greater glory</subtitle>
        <track>Perl</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;We've grown quite careless about trash in our developed civilization; with the abundance of resources we bring less attention to efficiency and frugality. What about situations when we &lt;em&gt;do&lt;/em&gt; need to care about the amount of garbage we produce? Let's take a journey through computer games, Perl 6 internals and bad practices and see what we can squeeze out of it when we really need to.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2973">Tadeusz 'tadzik' Sosnierz</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3500">
        <start>16:25</start>
        <duration>00:50</duration>
        <room>K.3.401</room>
        <slug>perl_syntactic_legacy</slug>
        <title>Perl's Syntactic Legacy</title>
        <subtitle>Using the future to improve the past</subtitle>
        <track>Perl</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The Perl programming language is currently enjoying a resurgence in popularity, and for good reason!
Perl 5 development continues to move forward with new features being introduced and many old ones improved, meanwhile the development of Perl 6 is making significant progress and has reached a major milestone, the details of which will be announced by Larry Wall at this very conference.
For many years now the development of these sister languages have affected and influenced one another in a myriad of ways. Over the last few years I have been working on a design proposal for enhancing and extending the object system of Perl 5 which borrows a number of elements from the Perl 6 object system.
In this talk we will explore the various evolutionary stages of that work, as well as discuss the complexities of adding new features to such a mature and well established language like Perl 5. Along the way we will also examine the various meanings of "legacy" in each context and show how it informed the design decisions that were made.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2967">Stevan Little</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3505">
        <start>17:15</start>
        <duration>00:50</duration>
        <room>K.3.401</room>
        <slug>devops_logique</slug>
        <title>Devops Logique</title>
        <subtitle/>
        <track>Perl</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Most of us already owe Prolog a debt indirectly via Erlang.  However, logic programming in and of itself has much to teach us about approaches to systems - taking declarative system descriptions to a new level of abstraction, and finding ways to integrate these ideas back into more common workflows.
From Prolog to Erlang to Haskell to Lisp to TLC and then back to Prolog I have journeyed, and I'd like to share some of the beautiful and brilliant things I've discovered along the way and why I think they might make us better operations geeks.
And when approaching new languages, always remember: You can't scare us, we've used m4.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2970">Matt 'mst' Trout</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3492">
        <start>18:05</start>
        <duration>00:50</duration>
        <room>K.3.401</room>
        <slug>perl6_beyond_dynamic_vs_static</slug>
        <title>Perl 6: beyond dynamic vs. static</title>
        <subtitle/>
        <track>Perl</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Is Perl 6 dynamic? Well, it sure looks like it: you can eval code at runtime, do all kinds of late-bound lookups, write code without a type declaration in sight, dynamically generate types, and even mutate the language and the way its object model works.
But hang on a moment! Misspell a variable or object attribute? That's a compile time error. Call a subroutine that doesn't exist? Yup, same deal. Passing just one argument to a sub that needs two? There's a good chance you'll be told about that too...at compile time. Want to write code that uses native integers and floating point numbers? Go right ahead and throw in some types. Oh, and those super-dynamic modules that extend the language? They can get in on the act, and flag up things to the programmer at compile time too!
In this session, we'll explore how Perl 6 strikes a balance between static and dynamic, how the Rakudo Perl 6 compiler takes advantage of this careful design work, and how the language and implementation are flexible enough to let the programmer pick their own trade-offs if the defaults don't fit their problem.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2164">Jonathan 'jnthn' Worthington</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="K.4.201">
      <event id="3413">
        <start>10:30</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>state_of_openjdk</slug>
        <title>The State of OpenJDK</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;A review of the past year in the life of the OpenJDK Community, and a look at what's ahead.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="218">Mark Reinhold</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3418">
        <start>11:00</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>beyond_java_nine</slug>
        <title>Beyond Java 9</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Is there life after Java 9?  Yes!  This session will offer a highly-speculative sneak preview of advanced features currently in development for the Java language and virtual machine.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="218">Mark Reinhold</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2730">
        <start>11:30</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>mapped_byte_buffer</slug>
        <title>MappedByteBuffer.hurray()</title>
        <subtitle>Programming the Linux Framebuffer in Java. #essentialtools and #allthethings #rgb</subtitle>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Java is a great language for rapid prototyping. For those interested in multimedia and UI design in Linux, however, there are limited options that provide a varying degree of performance and feasibility. It is quite straightforward to perform I/O on a Video 4 Linux device or the Linux framebuffer in C, but not as straightforward in Java. The end result of this project enables Java programmers program devices like the Linux framebuffer much ease as they use byte[] and int[] classes. An interactive demonstration will be made available as part of the workshop. Moreover, the implementation demonstrates speedups of up to 150x in MappedByteBuffer I/O.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;This patchset [1], currently implemented as a proof of concept using
JamVM and GNU Classpath, enables&lt;/p&gt;

&lt;p&gt;1) the JVM to mmap special files (i.e. those in /dev) - something no
other VM can do AFAIK
2) a true, direct, MappedByteBuffer from any mapping or pointer in the CRT
3) provides a safe, memory-managed Java backing array, via
MappedByteBuffer.array()
4) speeds up MappedByteBuffer I/O by factor of up to 150 times!!&lt;/p&gt;

&lt;p&gt;In human terms, it lets me draw to the FB[4] using pure Java :-) Since
originally posting my patchset, I have made a few changes including
removing the custom JNI calls in favour of using sun.misc.Unsafe API.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If possible describe why Free Java is helpful or perhaps even
essential to your project.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This would have been practically impossible to do with a closed-source
JVM and class library. JamVM and GNU Classpath have been open source
for as long as I've known, and that's enabled me to become familiar
enough with the source to make it do whatever I needed in various
embedded environments.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What the audience will learn from the talk.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I will provide a fairly minimal VMWare image so that the audience can
easily download the VM, modify some Java code, and draw whatever
demo's they would like to to the FB - using pure Java! My forks are up
on github [2,3]&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;How can people help out with the project, what feedback are you looking for?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I would like to have some feedback about the patchset to get it in
good enough shape for acceptance to GNU Classpath and JamVM. I would
like to entice some other tinkerers to port the changes to OpenJDK as
well, and would like to get some feedback about possibly using JNA in
combination with my /dev/fb and /dev/event classes. Lastly, I would
very much like to open up the discussion about forming a
performance-optimization group.&lt;/p&gt;

&lt;p&gt;Recording me on audio and/or video: YES (acceptable)&lt;/p&gt;

&lt;p&gt;[1] https://plus.google.com/+ChristopherFriedt/posts/N4eVKvn2oL4
[2] https://github.com/cfriedt/jamvm
[3] https://github.com/cfriedt/classpath
[4] https://plus.google.com/+ChristopherFriedt/posts/XkNYEfgESea&lt;/p&gt;</description>
        <persons>
          <person id="2465">Chris Friedt</person>
        </persons>
        <links>
          <link href="https://github.com/cfriedt/jamvm">JamVM Fork</link>
          <link href="https://github.com/cfriedt/classpath">Classpath Fork</link>
          <link href="https://plus.google.com/+ChristopherFriedt/posts/XkNYEfgESea">Demo Video</link>
        </links>
      </event>
      <event id="3419">
        <start>12:00</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>diagnosing_with_thermostat</slug>
        <title>Diagnosing Performance Issues Using Thermostat</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Debugging performance problems can be a daunting task, especially when you are short on time and lack proper tools that integrate nicely with your custom application landscape. Thermostat was designed to answer the most interesting questions related to performance measurement and application monitoring. It takes advantage of performance metrics and serviceability features of OpenJDK to provide a holistic view of the system. In this session, attendees will get a chance to see Thermostat in action as it is used to analyse programs, gather data, and debug issues affecting performance and functionality.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="222">Mario Torre</person>
          <person id="2909">Severin Gehwolf</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3420">
        <start>12:30</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>java_restart_webfx</slug>
        <title>Java restart with WebFX</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The purpose of the WebFX project is to investigate the capabilities of using JavaFX to build rich web applications. Actually, it is an attempt to create a new web where HTML is replaced with FXML — the markup language for JavaFX UI, and the logic can be written in any programming language that is available on top of Java platform from JavaScript, Groovy, JRuby to Java, Kotlin and Scala. Java ReStart is a complimentary project that acts as transport layer for WebFX allowing FXML pages to reference arbitrary Java byte code on a web server and hence any custom JavaFX UI components and Java third-party libraries. In addition, Java ReStart allows to run arbitrary Java applications
instantly from a web server downloading only required parts of applications on demand and executing them in parallel with downloading.&lt;/p&gt;

&lt;p&gt;I would like to give an overview of the projects, make a live demo, compare the proposed technologies with traditional web and native clients, show how the technologies differ from Java applets and Java Webstart, reveal benefits in compare with RDP-like approaches. Finally, I will share my vision on how to evolve the projects.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2910">Nikita Lipsky</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3421">
        <start>13:00</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>caciocavallo</slug>
        <title>Caciocavallo, or how we ported OpenJDK from embedded to cloud and still liked it</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Caciocavallo has been one of the very first external projects to land in the OpenJDK repository and sponsored by the OpenJDK Porters Group. Named after a delicious cheese we're never tired of eating, it had the original purpose of refactoring the AWT peers to allow different implementations to be added to OpenJDK. The project evolved very quickly until it became itself a full implementation of AWT based on Swing with just enough abstraction to allow custom plugging into the Java2D system for rendering. As time passed, this characteristic was used to implement a GUI testing framework running on offscreen buffers to avoid the usual problems of focus stealing and random mouse moving that plague every other GUI testing framework (here everything is emulated!), and finally a full Web based backend to allow application to run remotely but still be visible on the local screen. This talk will cover the progress we have done over the years, we will show how easy is to implement a new backend and how this project could be used to give Wayland support to OpenJDK. We will show the testing framework and finally we will discuss about WebJDK, an idea to give more web oriented functionality to OpenJDK and use the web backend to enable fully cloud based applications.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="222">Mario Torre</person>
          <person id="740">Roman Kennke</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3422">
        <start>13:30</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>packed_objects</slug>
        <title>Packed Objects, Object Layout &amp; Value Types - a Survey</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Java is often criticized for its lack of supporting C-style structs. This makes it hard to efficiently implement certain type of data structures (like for example arrays of small objects) in Java.&lt;/p&gt;

&lt;p&gt;However, recently there have been several different approaches which try to address this problem. My talk will briefly introduce "Packed Objects", an extension available in IBM's Java SDK 8, "Object Layout", a layout-optimized Java data structure package proposed by Azul Systems and Value Types [3][4], an OpenJDK proposal for immutable, reference-free value objects.&lt;/p&gt;

&lt;p&gt;I will describe the commonalities and differences of the three approaches and explain how they can improve the memory overhead and locality of Java objects.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1289">Volker Simonis</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3423">
        <start>14:00</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>jitsi_crypto</slug>
        <title>Jitsi Videobridge in Cryptoland: the adventures of a Java WebRTC video router on the road to supporting 1000s of video streams</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In Jitsi Videobridge (https://jitsi.org/Projects/JitsiVideobridge), a WebRTC video conferencing router, encryption and packet signing were among the most expensive components in terms of CPU intensity. We therefore set out on a journey to optimize them as much as possible.&lt;/p&gt;

&lt;p&gt;We would like to share this journey with the Java FLOSS community.&lt;/p&gt;

&lt;p&gt;We are going to present a comparison we have made on the execution times of popular open source implementations of AES and SHA-1 in search of the best performer. Our reference implementations are provided by the pure-Java Bouncy Castle cryptography APIs. Our contenders are an assortment of widely-used Java and cross-platform C code: the SunJCE security provider optimized by Java Runtime Environment (JRE) 8, the Mozilla Network Security Services (NSS) libraries employed through the SunPKCS11 security provider and the OpenSSL Crypto library accessed with the help of the Java Native Interface (JNI).&lt;/p&gt;

&lt;p&gt;We're going to pit software against hardware in our examination how we can leverage the Advanced Encryption Standard New Instructions (AES-NI).&lt;/p&gt;

&lt;p&gt;We're going to look at the performance compromises of transferring bytes between Java and C. Can we beat Java's intrinsics? Will Java New/Non-blocking I/O (NIO) be better?&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2911">Lyubomir Marinov</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3424">
        <start>14:30</start>
        <duration>00:50</duration>
        <room>K.4.201</room>
        <slug>arm_micro_it</slug>
        <title>The ARM microJIT, a JIT for the IoT</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;We have all got used to memory being essentially infinite, however the IoT reopens the constrained device with devices having 256M or less. This project looks at developing an ARM microJIT targeted at these devices. The project is based on the original work I did on the Thumb2 JIT (FOSDEM 2010).&lt;/p&gt;

&lt;p&gt;The project targets the Raspberry PI which is an ideal IoT development/demonstration platform. Unfortunately the Thumb2 JIT does not support the Raspberry PI because the Raspberry PI does not have the Thumb2 instruction set. This is a project which I am working on in my 'free' time and I hope to have a demonstrable port by FOSDEM.&lt;/p&gt;

&lt;p&gt;Finally I would like to have a discussion about the future of this work.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2912">Edward Nevill</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3425">
        <start>15:30</start>
        <duration>00:50</duration>
        <room>K.4.201</room>
        <slug>hacking_openjdk</slug>
        <title>What Lies Beneath?: Lessons learned hacking the OpenJDK interpreter/compilers</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;What really happens to your Java code along the way to becoming machine code?&lt;/p&gt;

&lt;p&gt;Red Hat has been developing an almost pauseless GC for OpenJDK which requires adding read barriers to every object access. We've also developed ARM64 versions of both the server and the client compilers.  This has given us quite a bit of experience with the internals of the various methods of generating machine code inside the JVM.  This talk will start with a brief tour of the various levels of code generation available and then open up the floor for questions from our panel.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="719">Andrew Haley</person>
          <person id="740">Roman Kennke</person>
          <person id="742">Andrew Dinn</person>
          <person id="2913">Christine H Flood</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3426">
        <start>16:30</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>jfree</slug>
        <title>JFree - The Long and Winding Road (Ahead)</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This year the JFree project (that’s JFreeChart and friends) turns 15!  Though looking forward not backward is the JFree way, so this session will cover a couple of the latest free things we’ve been working on. We fly &lt;em&gt;high&lt;/em&gt; above the low level virtual machine technology, even above the standard Java APIs, so if you want to soar with eagles (and your brain hurts from some other talks about complex low-level &lt;em&gt;magic&lt;/em&gt;) then come a see some shiny graphical things and we’ll promise not to talk about anything that’s complicated!&lt;/p&gt;

&lt;p&gt;In this session, you will hear about our recent JavaFX work, or get a quick demo of JFreeSVG, or maybe we’ll surprise you with something else graphical, awesome and free. :-)&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2914">David Gilbert</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3427">
        <start>17:00</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>iot_eclipse</slug>
        <title>Building an open Internet of Things with Java and Eclipse IoT</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Java is a platform of choice for many IoT applications, from building smart gateways that bridge sensors to the cloud, to device management infrastructures or home automation systems. This session provides you with concrete examples of how to build end-to-end solutions with the Eclipse IoT Java stack and in particular how to use open-source projects such as Paho, Kura, Californium and Concierge on top of OpenJDK. You should join this session if you have Java developments skills that you'd like to put to good use for your next IoT project, and if you are interested in learning more about how to use open standards like CoAP, MQTT, 6LoWPAN, … in your Java applications.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2694">Benjamin Cabé</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3428">
        <start>17:30</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>fortress</slug>
        <title>Fortress</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In this talk we will talk about some of the most interesting aspects of Fortress and the challenges with targeting them to the JVM&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2913">Christine H Flood</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3429">
        <start>18:00</start>
        <duration>01:00</duration>
        <room>K.4.201</room>
        <slug>debugging_hotspot</slug>
        <title>Open Heart Surgery: HotSpot Debugging at the OS Level</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Debugging Java applications is comfortable and simple, but if you want to look beyond the Java horizon, you need special knowledge and and different tools.&lt;/p&gt;

&lt;p&gt;This interactive session shows you how to debug a running VM or analyze a VM core file with a native debugger like gdb. You will also learn how to use some of the more than 1,200 VM options to trace or
modify the VM behavior. This knowledge can greatly help you identify, isolate and reproduce the root cause of hard VM crashes, and it can also be pure fun to see which actual machine instruction the CPU is executing for your Java code.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1289">Volker Simonis</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="K.4.401">
      <event id="3207">
        <start>11:10</start>
        <duration>00:45</duration>
        <room>K.4.401</room>
        <slug>rubinius_and_the_yak</slug>
        <title>Rubinius And The Eternal Yak</title>
        <subtitle>Covering what it takes to maintain a Ruby implementation and the process behind it</subtitle>
        <track>Ruby</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;What exactly does it take to maintain a Ruby implementation? What is the process
of porting over features? Why can this often take a considerable amount of time?
This talk aims to dive into these topics in general but also how it affects
Rubinius.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;This talk will focus on what it takes to maintain a Ruby implementation and the
process behind it. While there will be a strong focus on how Rubinius handles
this, most of the topics also apply to other implementations such as JRuby and
Opal. We'll also look into writing tests for Ruby, how this has been handled
historically and why it's so important to have good tests.&lt;/p&gt;

&lt;p&gt;One of the examples I'll be showcasing is how String#scrub, a new method in Ruby
2, was implemented in co-operation with Charles Nutter from JRuby and why this
took quite a large amount of time (nearly a month). Another example will be
Kernel#caller_locations, a method recently added to Rubinius which highlighted
a potential bug in the implementation of MRI itself &lt;a href="this"&gt;1&lt;/a&gt;.&lt;/p&gt;</description>
        <persons>
          <person id="2797">Yorick Peterse</person>
        </persons>
        <links>
          <link href="http://rubini.us">Rubinius Website</link>
          <link href="http://rubyspec.org/">RubySpec Website</link>
        </links>
      </event>
      <event id="2721">
        <start>12:05</start>
        <duration>00:45</duration>
        <room>K.4.401</room>
        <slug>peeling_back_ruby_c_extensions</slug>
        <title>Ruby-red onions: Peeling back Ruby's layers in C extensions</title>
        <subtitle>Dive into using the Ruby C extension API to understand more about MRI</subtitle>
        <track>Ruby</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The fact that Ruby has different implementations is strange but also powerful as it allows us to write extensions. Although writing an extension can be a daunting task, there's no better way to get to the heart of what exactly Ruby objects are and the reason for some of the language's quirks.&lt;/p&gt;

&lt;p&gt;In this talk, we'll use an example of writing a C extension for Ruby to use a third-party C security library. We'll peel back the layers of Ruby objects to deepen our knowledge of MRI and to understand in a little more detail what it really means to write object-oriented code.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Ruby is a very high-level language and I've found that Rubyists often lack more lower-level knowledge concerning operating systems, memory management, differences with other languages, and typing. Writing a C or Java extension exposes some of these concepts to the Rubyist and highlights the uniqueness of the language. I would like to share some of what I've learned from writing C and Java extensions with the RubyConf audience.&lt;/p&gt;

&lt;p&gt;In this presentation I'll use an example of writing a C extension so that Ruby code can make use of a third-party C security library. The topics I'll touch on are:&lt;/p&gt;

&lt;p&gt;How to write a rake task so that your extension compiles when your gem installs
How Ruby objects are represented in C code
The appropriate C functions to use when going back and forth between Ruby objects and C code&lt;/p&gt;

&lt;p&gt;Here is the c code: https://github.com/mongodb/mongo-ruby-driver/blob/1.x-stable/ext/csasl/csasl.c&lt;/p&gt;

&lt;p&gt;Why I'm qualified as a speaker on this topic:&lt;/p&gt;

&lt;p&gt;I had to write both a Java and C extension for the MongoDB Ruby driver using a sasl library for GSSAPI authentication against MongoDB. There was minimal documentation available for how to write extensions in Java or C and I learned a ton from having to figure it out on my own.
Having written the extensions gives me a much deeper understanding of MRI in particular and general knowledge about programming languages.&lt;/p&gt;

&lt;p&gt;I've given numerous talks at conferences, including RubyConf '13, invited to BaRuCo '14, RailsConf '13, RailsIsrael, RuLu, GoGaRuCo '13, GoRuCo '13, ScottishRuby, etc. I love giving talks and put a lot of heart and soul into the preparation. I've heard people usually think they're high quality = )&lt;/p&gt;</description>
        <persons>
          <person id="2452">Emily Stolfo</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3093">
        <start>13:00</start>
        <duration>00:45</duration>
        <room>K.4.401</room>
        <slug>concurrent_ruby</slug>
        <title>Concurrent Ruby: low and high-level concurrency abstractions for the Ruby language</title>
        <subtitle>Discussion of concurrency patterns available and how they're implemented for Ruby</subtitle>
        <track>Ruby</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The concurrent-ruby is a gem which provides a variety of concurrency abstractions at high and low levels. It is an unopinionated toolbox allowing users to pick the right tool for a given concurrent problem. The gem has Agents, Actors, STM and many more.&lt;/p&gt;

&lt;p&gt;The talk will cover:
-   Overview of the available tools.
-   Examples of some abstractions.
-   Java and C specific implementations.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2732">Petr Chalupa</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3130">
        <start>13:55</start>
        <duration>00:45</duration>
        <room>K.4.401</room>
        <slug>the_future_of_jruby</slug>
        <title>Over 9000: The Future of JRuby</title>
        <subtitle>A talk on JRuby 9000 and where it will take Ruby in the next year</subtitle>
        <track>Ruby</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;JRuby 9000 represents the biggest-ever leap forward for JRuby. Not only have we caught up on compatibility (9000 will be 2.2-compatible from release), but we've completely redesigned our JVM-based runtime and have opened our codebase up to the JRuby+Truffle research project from Oracle Labs. The changes we've made will make it easier to keep up with MRI on compatibility and give us the potential to run Ruby as fast as Java or C. The entire Ruby world will change over the next year, and JRuby 9000 will be leading the way. We'll talk about what Ruby's going to look like once JRuby is "over 9000".&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="743">Charles Nutter</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2752">
        <start>14:50</start>
        <duration>00:45</duration>
        <room>K.4.401</room>
        <slug>jruby_truffle_deep_dive</slug>
        <title>Truffle: A tour through a new Ruby implementation</title>
        <subtitle>An in-depth walk-through of JRuby+Truffle, a new high performance Ruby implementation</subtitle>
        <track>Ruby</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;JRuby+Truffle is a new high performance implementation of Ruby being built as an open-source research project at Oracle Labs. It uses state-of-the-art research into techniques for writing interpreters and dynamic compilers that allows it to be both significantly faster than any other implementation of Ruby, but also conceptually simpler.&lt;/p&gt;

&lt;p&gt;In this talk we'll explain how JRuby+Truffle works. We'll cover the whole system from the parser to emitting the actual machine code bytes - and we won't have to leave our Java IDE to do it.&lt;/p&gt;

&lt;p&gt;We won't shy away from technical depth where it's needed to uncover all the details, but Truffle is designed to be a high-level and simple system accessible to non-experts. Novices will get an insight into the big ideas, and experts will be able to find out how it all really works.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2451">Chris Seaton</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3206">
        <start>15:45</start>
        <duration>00:45</duration>
        <room>K.4.401</room>
        <slug>ruby_mri_vs_father_time</slug>
        <title>MRI vs. Father Time</title>
        <subtitle>Covering the Past, Present and Future of the MRI interpreter</subtitle>
        <track>Ruby</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;h1&gt;MRI vs. Father Time&lt;/h1&gt;

&lt;p&gt;Matz Ruby Implementation has grown into a fast and effective option for building dynamic applications. Thanks to the advancements such as YARV virtual machine and Incremental GC introduced in Ruby 2.2.&lt;/p&gt;

&lt;p&gt;In this talk we will cover the Past, Present and Future of the MRI interpreter. We'll see how it performs under various conditions, such as static content generation and web services.&lt;/p&gt;

&lt;p&gt;With the help of new and improved MRI tooling, you'll get to see the path to profiling your applications and enlightenment.&lt;/p&gt;

&lt;p&gt;Join the author of MRI’s new Virtual Machine and Garbage Collector Koichi Sasada along with Terence Lee and Zachary Scott. As they dig through the internals of Matz Ruby Implementation.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2796">Zachary Scott</person>
          <person id="2903">Koichi Sasada</person>
          <person id="2904">Terence Lee</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="K.4.601">
      <event id="3073">
        <start>12:00</start>
        <duration>00:50</duration>
        <room>K.4.601</room>
        <slug>efl</slug>
        <title>EFL - A UI Toolkit Designed for the Embedded World</title>
        <subtitle/>
        <track>Graphics</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Enlightenment Foundation Library is a set of libraries designed to use the full potential of any hardware to do great UI. It has been designed with the embedded devices in mind, but it is a desktop class toolkit. Being done in C, it is providing a stable API/ABI, high efficiency, low memory and low battery usage for all kind of Linux device. Enabling development of modern UI adapted to any hardware that run Linux. These are the reason why Samsung use it in its Tizen devices. This talk after a short overview of what this libraries cover, will focus on last year improvement and where it is heading. It will also be an opportunity to learn about project around EFL that will help people develop product with it. And it would also be a good opportunity to see where EFL are used with some real use case.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2722">Cedric Bail</person>
        </persons>
        <links>
          <link href="http://enlightenment.org">Enlightenment</link>
        </links>
      </event>
      <event id="2654">
        <start>13:00</start>
        <duration>00:50</duration>
        <room>K.4.601</room>
        <slug>webx11</slug>
        <title>X11 on the Web</title>
        <subtitle>Using Native Client to run X11 applications in the Browser</subtitle>
        <track>Graphics</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The clever minimalism and flexibility of the X-Windows system has allowed it to be ported to a diverse range of platforms. Recently, that flexibility has allowed the X.org server, client libraries, several window managers, and a range of applications to be ported to run stand-alone inside the Chrome web browser using a technology called Native Client. This talk explores the unique challenges of porting X11 to Native Client and the browser.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Native Client (NaCl), is an open-source technology that allows native machine code to run securely sandboxed in the browser. Two layers of sandboxing, a static verification inner sandbox combined with Chrome’s outer process sandbox, ensure users can safely run untrusted applications. Modified GCC and LLVM based toolchains allow applications to target NaCl. An I/O API called PPAPI, mirroring the security constraints of Javascript, is provided to NaCl applications.&lt;/p&gt;

&lt;p&gt;This talk will discuss the central porting challenges including: emulation of POSIX APIs—processes, sockets, files—on top of Web-centric APIs, packaging, and protocol transport. I’ll demonstrate several X11 applications running the browser, including Emacs, Tcl/Tk, and Xeyes! We’ll look at how X11 applications can interoperate with our in-browser development environment and discuss how you can use this technology to bring your X11 application to the Web.&lt;/p&gt;

&lt;p&gt;Check out our ports collection at: https://code.google.com/p/naclports/wiki/PortList&lt;/p&gt;

&lt;p&gt;Learn more about Native Client: https://developer.chrome.com/native-client/overview&lt;/p&gt;</description>
        <persons>
          <person id="2253">Brad Nelson</person>
        </persons>
        <links>
          <link href="http://naclports.googlecode.com/">NaCl Ports collection</link>
          <link href="https://developer.chrome.com/native-client/io2014">NaCl Dev Environment</link>
        </links>
      </event>
      <event id="2635">
        <start>14:00</start>
        <duration>00:50</duration>
        <room>K.4.601</room>
        <slug>v4l_testing</slug>
        <title>Testing Video4Linux Applications and Drivers</title>
        <subtitle/>
        <track>Graphics</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The video4linux subsystem of the kernel is a very large API with many ioctls, settings, options and capabilities. This poses a problem both for the kernel developer and for the application developer. Since early 2014 major improvements have been made to both the v4l2-compliance utility for verifying drivers, and to the virtual video driver that applications can use as a reference input. This presentation will explain and demonstrate this utility and driver and show how to use them to ensure your driver or application works correctly.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1637">Hans Verkuil</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2636">
        <start>15:00</start>
        <duration>00:50</duration>
        <room>K.4.601</room>
        <slug>colorspace</slug>
        <title>Video Capture and Colorspaces</title>
        <subtitle/>
        <track>Graphics</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The video4linux kernel subsystem reports which colorspace the captured video uses. But what does that really mean, and what do you have to do to correctly reproduce those colors? This talk will dive into the crazy world of colorspaces and give you a practical guide to colorspace handling. I will also demonstrate colorspace handling, both right and wrong.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1637">Hans Verkuil</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3336">
        <start>16:00</start>
        <duration>00:50</duration>
        <room>K.4.601</room>
        <slug>intel_gfx</slug>
        <title>Sync points in the Intel gfx driver</title>
        <subtitle>Why and how we're adding a sync API to the Intel gfx driver</subtitle>
        <track>Graphics</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Discussion of the motivation for explicit sync points and how we're implementing them in the Intel gfx driver, called i915 in the Linux kernel sources.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Explicit synchronization APIs like NV&lt;em&gt;fence or ARB&lt;/em&gt;sync allow rendering clients to manage their GPU usage explicitly, rather than relying on an underlying implementation to implicitly synchronize activity reading and writing multiple buffers.  In cases where the low level driver (generally in the kernel) doesn't have information about buffer usage, an explicit synchronization mechanism becomes necessary, and in the current i915 environment of implicit synchronization, an additional explicit API can still be useful for tracking performance, non-rendering activity like mode sets, and explicitly queueing unsynchronized activity that an implicit synchronization approach would prevent.&lt;/p&gt;</description>
        <persons>
          <person id="899">Jesse Barnes</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3383">
        <start>17:00</start>
        <duration>00:50</duration>
        <room>K.4.601</room>
        <slug>gl_testing</slug>
        <title>How to test OpenGL drivers using Free Software</title>
        <subtitle/>
        <track>Graphics</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;OpenGL is an API for rendering 2D and 3D graphics now managed by the non-profit technology consortium Khronos Group. Implementors are free to provide their own implementation of the API. For example, in GNU/Linux systems NVIDIA provides its own proprietary version while other manufacturers like Intel are using Mesa, the most popular open source OpenGL implementation.&lt;/p&gt;

&lt;p&gt;Because of this implementation freedom, ensuring compliance with the specification is important. Khronos provides their own OpenGL conformance test suite but there are several unofficial open source alternatives.&lt;/p&gt;

&lt;p&gt;This talk will explain some of these open source OpenGL conformance test suites and give an introduction about how to use them, including sharing tips between the speaker and the audience.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2881">Samuel Iglesias</person>
        </persons>
        <links>
          <link href="http://piglit.freedesktop.org/">Piglit</link>
          <link href="http://www.drawelements.com/products/deqp">dEQP</link>
        </links>
      </event>
    </room>
  </day>
  <day index="2" date="2015-02-01">
    <room name="Janson">
      <event id="2600">
        <start>10:00</start>
        <duration>00:50</duration>
        <room>Janson</room>
        <slug>apache_celix</slug>
        <title>Modularizing C software with Apache Celix</title>
        <subtitle/>
        <track>Languages</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;Join the world of service oriented programming with all its benefits - but without its usually found shortcomings - with Apache Celix. Apache Celix is a framework for service oriented programming in C, with a focus on a low overhead, and a small footprint.&lt;/p&gt;

&lt;p&gt;Service oriented programming brings a lot to table. It enables the design and development of software applications in small cohesive modules, which interact based on loosely coupled services.&lt;/p&gt;

&lt;p&gt;In this presentation the history and concepts behind Apache Celix will be explained.&lt;/p&gt;</abstract>
        <description>&lt;h2&gt;Apache Celix&lt;/h2&gt;

&lt;p&gt;With Apache Celix, C applications can be designed and developed in small modules. Modules run in the same process, but are not visible for each other. When developing applications with Apache Celix it is more natural and compelling to develop modules which do one thing (and do it well), and thus avoiding monolithic and complex applications.&lt;/p&gt;

&lt;p&gt;Apache Celix has taken the approach to add the service oriented programming paradigm to the C language without deviating too much from developing plain C, and at the same time deliver a better solution for present-day challenges when working with ever increasing time to market demands and ever changing customer requirements (e.g. Agile Development).&lt;/p&gt;

&lt;h2&gt;OSGi&lt;/h2&gt;

&lt;p&gt;Apache Celix follows the Java OSGi specification with some adaptations needed because of the language differences.
The OSGi specification is an open standard specification, describing a framework for modular and service oriented development without entailing too much technical details. The specification contains a core specification, describing the minimal OSGi framework, and a considerable selection of compendium specifications: The Event Admin specification for async message, the Configuration Admin specification for decoupling code and configuration, the Remote Services specification for distributed development, to name but a few.&lt;/p&gt;</description>
        <persons>
          <person id="2315">Pepijn Noltes</person>
        </persons>
        <links>
          <link href="http://celix.apache.org">Apache Celix</link>
          <link href="http://www.osgi.org">OSGi Alliance</link>
        </links>
      </event>
      <event id="3447">
        <start>11:00</start>
        <duration>00:50</duration>
        <room>Janson</room>
        <slug>the_story_of_rust</slug>
        <title>The Story of Rust</title>
        <subtitle/>
        <track>Languages</track>
        <type>maintrack</type>
        <language/>
        <abstract></abstract>
        <description></description>
        <persons>
          <person id="2923">Steve Klabnik</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2597">
        <start>12:00</start>
        <duration>00:50</duration>
        <room>Janson</room>
        <slug>design_and_implementation_of_a_perl_number_theory_module</slug>
        <title>Design and Implementation of a Perl Number Theory Module</title>
        <subtitle/>
        <track>Languages</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;This talk describes the history, design, and implementation details of a number theory module for Perl.  With implementations for most functions in C, C+GMP, and Perl this offers speed on most platforms as well as portability.  Comparisons will be made with tools such as Pari/GP, SymPy, SAGE, Primo, OpenPFGW, and others.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The Perl ntheory module (aka Math::Prime::Util) offers a portable solution for many integer number theory tasks in Perl.  While not offering the full feature set of robust and mature packages such as Pari/GP and SAGE, there are many areas where this package offers improvements.&lt;/p&gt;

&lt;p&gt;With implementations in C, C+GMP, and Perl, there were a number of design choices made.  We describe the choices and tradeoffs of making a package that is both portable, robust, and performant.  Design choices for some algorithms (e.g. primality tests) are also discussed.&lt;/p&gt;

&lt;p&gt;Highlights of this open source package include:
  - Fastest single threaded open source prime count and nth&lt;em&gt;prime
  - Fastest 64-bit primality testing
  - Fastest bigint probable prime testing to 10k digits
  - Fastest next&lt;/em&gt;prime, prev_prime
  - Fastest open source AKS primality proofs
  - Fastest open source ECPP primality proofs
  - Support for random primes and random proven primes
  - Ability to compile standalone C programs for tasks such as prime count, primality tests, primality proving, and primality certificate verification.&lt;/p&gt;

&lt;p&gt;The random primes and primality testing/proving have been used in some new crypto modules, replacing older CPAN modules that were slower and had defects.  The ECPP verifier written as part of this project is being used by FactorDB.  In less than a year of use, simple Perl scripts using this module have been able to find over 37% of all current record prime gaps.  Numerous defects in other open source packages have been identified during testing of this module.&lt;/p&gt;</description>
        <persons>
          <person id="2324">Dana Jacobsen</person>
        </persons>
        <links>
          <link href="https://metacpan.org/pod/ntheory">ntheory module description</link>
          <link href="https://metacpan.org/pod/Math::Prime::Util">Detailed documentation</link>
          <link href="http://sti15.com/talk/2014-06-24/MPU-2014yapcna.pdf">A version of my YAPC lightning talk on the subject.</link>
        </links>
      </event>
      <event id="2725">
        <start>13:00</start>
        <duration>00:50</duration>
        <room>Janson</room>
        <slug>get_ready_to_party</slug>
        <title>Get ready to party!</title>
        <subtitle/>
        <track>Languages</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;The last pieces are finally falling into place.  After years of design and implementation, 2015 will be the year that Perl 6 officially launches for production use.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;In this talk, the creator of Perl reflects on the history of the effort, how the team got some things right, and how it learned from its mistakes when it got them wrong. But mostly how a bunch of stubbornly fun-loving people outlasted the naysayers to accomplish the extraordinary task of implementing a language that was so ambitious, even its designers said it was impossible. Prepare to be delightfully surprised.&lt;/p&gt;</description>
        <persons>
          <person id="2457">Larry Wall</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2724">
        <start>14:00</start>
        <duration>00:50</duration>
        <room>Janson</room>
        <slug>sdaps</slug>
        <title>SDAPS</title>
        <subtitle>Surveying Made Easy</subtitle>
        <track>Typesetting</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;This talk will give an introduction into SDAPS how it works and how it can be used automate surveys or even examinations on paper. In the core SDAPS is an optical mark recognition software that is integrated with LaTeX and LibreOffice. It provides all the utilities to automate simple surveys, including questionnaire creation, manual error correction, and a simple report generation module. Also important is its flexibility to be used for data acquisition by either exporting the data or even interfacing with SDAPS python API directly for specialized applications.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;While the core of SDAPS is the optical mark recognition there is a lot more to creating a good utility. Both usability and technical aspects have to be taken into account to achieve the goal of a simple to use utility that is still flexible enough for more complex use cases. With a background for conducting anonymous survey a lot of the feature development to support different use cases was driven by suggestions from the community. Further changes and improvements are now on the way thanks to input from academic users using SDAPS both for surveys and examinations. Especially examinations pose a unique challange as there is a multitude of different ways to conduct these, making custom data processing and workflows necessary. All this poses new challenges to the development of SDAPS as the different requirements should be realized on top of a common core SDAPS code base either by extending SDAPS itself or allowing it to be extended using own code.&lt;/p&gt;</description>
        <persons>
          <person id="1045">Benjamin Berg</person>
        </persons>
        <links>
          <link href="http://sdaps.org">Project Homepage</link>
        </links>
      </event>
      <event id="2492">
        <start>15:00</start>
        <duration>00:50</duration>
        <room>Janson</room>
        <slug>introducing_sile</slug>
        <title>Introducing SILE: A New Typesetting System</title>
        <subtitle/>
        <track>Typesetting</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;SILE is a system for creating beautiful printed documents. It borrows extensively from TeX, but brings some of TeX's ideas into the 21st century with frame-based layouts, native support for Unicode, PDF, Opentype and XML processing, and extensibility and programmability in a modern, high-level language.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Hello, my name's Simon and I wrote a typesetting system by mistake. Then I found out that people needed to use it. Come and hear about how SILE got started, how it's developed since then, and how you can use it to make printed documents.&lt;/p&gt;

&lt;p&gt;SILE is a typesetter designed to meet the needs of a particular translation community, with an emphasis on extensibility and layout flexibility. Existing solutions (TeX and friends) were not able to provide the required features in these areas, and so translators and publishers have been looking around for an alternative solution for many years. SILE takes a lot of inspiration from TeX, but updates many of its ideas to match the changes in the software ecosystem in the past 35 years.&lt;/p&gt;

&lt;p&gt;SILE does not, however, aim to be a replacement for TeX, but is a separate system for document layout and rendering. Because of this, functionality which is a challenge for TeX users - for instance, laying out text on a grid, or magazine-style frame based layouts - becomes very easy in SILE. SILE is written in an interpreted language, so parts of the system's operation, including core typesetting algorithms, can be redefined at run time.&lt;/p&gt;

&lt;p&gt;SILE is also designed to meet the realities of today's data processing. Documents these days are often prepared in authoring software and stored in XML format. This applies both to document-specific XML DTDs, such as DocBook and the Text Encoding Initiative, and also tagged text database formats, such as those for storing linguistic and other annotation data such as the LIFT standard for dictionary data and the USX format used by translators. SILE classes can define processing expectations for XML elements, which means that XML files can then be read in and typeset directly. We will look at examples of complex book layouts driven by XML data sources.&lt;/p&gt;</description>
        <persons>
          <person id="2243">Simon Cozens</person>
        </persons>
        <links>
          <link href="http://github.com/simoncozens/sile">SILE github repository</link>
          <link href="http://www.sile-typesetter.org/">SILE home page</link>
        </links>
      </event>
      <event id="3408">
        <start>16:00</start>
        <duration>00:50</duration>
        <room>Janson</room>
        <slug>algorithmic_graph_drawing_in_tikz</slug>
        <title>Algorithmic Graph Drawing in TikZ</title>
        <subtitle/>
        <track>Typesetting</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;Graph drawing aims at computing pleasing layouts of graphs algorithmically. The talk will present a new framework, implemented in Lua and integrated into TikZ, that allows an easy implementation of graph drawing algorithms and that pays special attention to typography in this context.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Visualizing graphs is a time-consuming and complicated process, even when the to-be-drawn graphs have only a few nodes, and thus best left to special graph drawing algorithms. At the heart of every good such algorithm lies an efficient procedure for assigning canvas positions to a graph's nodes and the bend points of its edges. However, every real-world implementation of such an algorithm must address numerous problems that have little to do with the actual algorithm, like handling input and output formats, formatting node texts, or typesetting node texts and edge labels. In the talk I will present a new framework, implemented in the Lua programming language and integrated into the TikZ graphics description language, that aims at simplifying the implementation of graph drawing algorithms. Implementers using the framework can focus on the core algorithmic ideas and will automatically profit from the framework's pre- and post-processing steps as well as from the extensive capabilities of the TikZ graphics language and the TeX typesetting engine.&lt;/p&gt;</description>
        <persons>
          <person id="2900">Till Tantau</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2633">
        <start>17:50</start>
        <duration>00:10</duration>
        <room>Janson</room>
        <slug>closing_fosdem</slug>
        <title>Closing FOSDEM 2015</title>
        <subtitle/>
        <track>Keynotes</track>
        <type>keynote</type>
        <language/>
        <abstract>&lt;p&gt;Some closing words.  Don't miss it!&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="6">FOSDEM Staff</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="K.1.105 (La Fontaine)">
      <event id="3456">
        <start>10:00</start>
        <duration>00:50</duration>
        <room>K.1.105 (La Fontaine)</room>
        <slug>the_cheri_cpu</slug>
        <title>The CHERI CPU</title>
        <subtitle>RISC in the age of risk</subtitle>
        <track>Security</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;The CHERI research CPU extends the 64-bit MIPS ISA with byte-granularity memory protection.  CHERI enables language memory model enforcement and fault isolation in hardware rather than software.  In contrast to past capability models, CHERI complements, rather than replaces, the ubiquitous page-based protection mechanism, providing a migration path towards deconflating data-structure protection and OS memory management. Furthermore, CHERI adheres to a strict RISC philosophy: it maintains a load-store architecture and requires only single-cycle instructions, and supplies protection primitives to the compiler, language runtime, and operating system.&lt;/p&gt;

&lt;p&gt;This talk will present the CHERI softcore and associated software stack and describe how building on open source has enabled full-stack security research.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;2014 saw memory safety vulnerabilities such as Heartbleed in the mainstream press on several times, yet modern CPUs provide a memory model that does nothing to prevent them.  Modern security-critical applications such as web browsers split themselves into components to minimise the damage done by a compromise, but are forced to do so using hardware mechanisms (the MMU) designed to protect small numbers of programs from each other and which don't scale to the hundreds or thousands of components that modern software demands.&lt;/p&gt;

&lt;p&gt;The CHERI research CPU was created to attempt to apply the RISC philosophy to addressing these problems: To provide a simple hardware primitive that could be used to enforce everything from object-granularity memory protection to library-granularity sandboxing, with the policy under the control of software.  The resulting design has undergone several significant revisions and is the focus of ongoing research on OS and programming language security policies.&lt;/p&gt;

&lt;p&gt;Our software stack uses a modified FreeBSD and LLVM/Clang, co-designed along with the CPU.  This allows us to evaluate real programs, running at a useable (if not spectacular) speed.&lt;/p&gt;</description>
        <persons>
          <person id="391">David Chisnall</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2808">
        <start>11:00</start>
        <duration>00:50</duration>
        <room>K.1.105 (La Fontaine)</room>
        <slug>keccak_and_sha3</slug>
        <title>Keccak and SHA-3: code and standard updates</title>
        <subtitle>From the Keccak Code Package to a wide range of cryptographic applications</subtitle>
        <track>Security</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;In April 2014, the American National Institute of Standards and Technology (NIST) published the draft FIPS 202 standard for the SHA-3 hash functions and the SHAKE extendable-output functions (XOFs), all based on the Keccak sponge function. Since the selection of Keccak as the winner of the SHA-3 cryptographic open competition, NIST announced that they will exploit Keccak's abilities for other purposes than just hashing, including key derivation, pseudo-random bit generation, authentication and (authenticated) encryption.&lt;/p&gt;

&lt;p&gt;A first part of the talk will be to give a summary of the current developments around Keccak and the FIPS 202 standard.&lt;/p&gt;

&lt;p&gt;In the meantime, we have gathered the most efficient implementations of Keccak, SHA-3 hash functions and SHAKE XOFs in the Keccak Code Package. These open source implementations are organized in a way that aims satisfying both the developer of optimized code and the cryptographic user. Central to this organization is a specific internal interface that allows interchangeable optimized codes and a user-friendly set of external services.&lt;/p&gt;

&lt;p&gt;As a second part of the talk, we will briefly present the current status of this development and how the FOSS community can benefit from (and contribute to) this effort.&lt;/p&gt;

&lt;p&gt;This is a follow-up of the talk "Keccak: more than sha3sum" at FOSDEM 2013.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1105">Gilles Van Assche</person>
          <person id="1108">Joan Daemen</person>
          <person id="1465">Michaël Peeters</person>
        </persons>
        <links>
          <link href="http://csrc.nist.gov/groups/ST/hash/sha-3/Aug2014/documents/vanassche_keccak_code.pdf">August presentation on the Keccak Code Package</link>
          <link href="http://csrc.nist.gov/groups/ST/hash/sha-3/Aug2014/documents/dworkin_sha3_update.pdf">August presentation on the SHA-3 standard status</link>
          <link href="http://csrc.nist.gov/groups/ST/hash/sha-3/Aug2014/documents/perlner_XOFs.pdf">August presentation on the use of extendable-output functions (XOFs)</link>
          <link href="http://csrc.nist.gov/groups/ST/hash/sha-3/Aug2014/documents/sonmez-turan_sha3_2014_workshop.pdf">August presentation on authenticated encryption using Keccak</link>
          <link href="http://csrc.nist.gov/groups/ST/hash/sha-3/Aug2014/documents/perlner_kmac.pdf">August presentation on MACs based on Keccak</link>
          <link href="http://csrc.nist.gov/groups/ST/hash/sha-3/Aug2014/documents/dworkin_domain_ext.pdf">August presentation on SHA-3 domain extensions</link>
          <link href="http://keccak.noekeon.org/">Keccak</link>
          <link href="https://github.com/gvanas/KeccakCodePackage">Keccak Code Package</link>
        </links>
      </event>
      <event id="3475">
        <start>12:00</start>
        <duration>00:50</duration>
        <room>K.1.105 (La Fontaine)</room>
        <slug>precise_time</slug>
        <title>Precise time: from CPU clocks to hacking the Universe</title>
        <subtitle>Adventures of a time nut</subtitle>
        <track>Time</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;Time is the most precisely measured quantity we have, yet it is still the most mysterious. Precise time and frequency are the hidden ingredient in most technology used today, from computer synchronization, to satellite navigation, to data communications, to digital music and video. In this talk we explore the amazing world of precise time, a world that anyone with curiosity can explore on their own.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;It is not uncommon for ham radio operators, electrical engineers, or physicists to encounter the details about precision timing. But it turns out that playing with computer hardware and operating system software is also a wonderful entry into the obscure world of nanoseconds and parts per million accuracy.&lt;/p&gt;

&lt;p&gt;The talk is in three parts:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Examples of precise time and frequency in computing, from operating systems to microcontrollers.&lt;/li&gt;
&lt;li&gt;A "powers of ten" tour of clocks, timekeeping, and measurement; from the worst possible clock you can find at home to the best atomic clock you can buy.&lt;/li&gt;
&lt;li&gt;The results of Project GRE²AT, a DIY time experiment where Einstein's general theory of relativity was demonstrated by carrying atomic clocks from home up a mountain and the predicted time dilation actually measured. This puts keeping accurate time on a new level, and makes one wonder what time really is.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <persons>
          <person id="2950">Tom Van Baak</person>
        </persons>
        <links>
          <link href="http://LeapSecond.com/FOSDEM15">Time Hacking</link>
        </links>
      </event>
      <event id="2656">
        <start>13:00</start>
        <duration>00:50</duration>
        <room>K.1.105 (La Fontaine)</room>
        <slug>computers_clocks_and_network_time</slug>
        <title>Computers, Clocks and Network Time</title>
        <subtitle>Everything you never wanted to know about time.</subtitle>
        <track>Time</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;Most people who work with computers have no idea how the computers keep time.  All networked computer  systems require some form of temporal synchronization.  As networks have gotten faster the demands for accurate, distributed, timekeeping have increased, but most programmers have no idea about the quality of the clocks in their systems, nor how they might be kept in sync.  This talk will go over the basics of computer clocks, why they're inaccurate, and what can be expected from various strategies for getting systems into sync.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;All networked computer  systems require some form of temporal synchronization.  As networks have gotten faster the demands for accurate, distributed, timekeeping have increased, but most programmers have no idea about the quality of the clocks in their systems, nor how they might be kept in sync.  Most programmers have at least heard of NTP (The Network Time Protocol) which is used to synchronize computer clocks over a network, but fewer have heard about more recent work, such as the Precision Time Protocol which can keep computers accurate to within several hundred nanoseconds when working over a LAN.  Well synchronized clocks are used in financial applications such as High Frequency Trading as well as the electrical grid and cellular telephone networks.&lt;/p&gt;

&lt;p&gt;This talk will cover:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;How computers keep track of the time, and how they fail miserably at this.&lt;/li&gt;
&lt;li&gt;The fundamental ideas behind network based time keeping, why we do it, and how it works.&lt;/li&gt;
&lt;li&gt;Network Time Protocols (NTP and PTP) deployment, use and tuning.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <persons>
          <person id="2316">George Neville-Neil</person>
        </persons>
        <links>
          <link href="http://ptpd.sf.net">Open Source PTP Daemon</link>
        </links>
      </event>
      <event id="3448">
        <start>14:00</start>
        <duration>00:50</duration>
        <room>K.1.105 (La Fontaine)</room>
        <slug>technical_aspects_of_leap_second_propagation_and_evaluation</slug>
        <title>Technical Aspects of Leap Second Propagation and Evaluation</title>
        <subtitle/>
        <track>Time</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;Leap seconds are scheduled by the International Earth Rotation Service (IERS) whenever the difference between true earth rotation and the UTC time scale reaches a certain limit. Whenever a leap second has been scheduled by the IERS, a warning must be disseminated to time keeping devices so that clocks become aware of the scheduled leap second early enough to be able to handle the leap second properly.&lt;/p&gt;

&lt;p&gt;There are different ways to propagate leap second warnings using different timing signals, protocols, etc. For example, the GPS satellites transmit a specific point in time when a leap second is to be inserted or deleted, but other timing signals may just provide a leap second warning flag which is set during a certain interval before the leap event, where the warning interval depends on the specification of the protocol.&lt;/p&gt;

&lt;p&gt;Also, there are different implementations how leap seconds are handled, which especially affect the sequence of timestamps across the leap second event. The clock can be stepped at the beginning or end of the leap second, can be slowed down or even stopped during a leap second insertion, or time can be slewed across a leap second. This makes it difficult to compare time stamps which have been taken on different systems during a leap second.&lt;/p&gt;

&lt;p&gt;Last, but not least, there are implementations of time keeping code which don't always work correctly, e.g. invalid leap second warnings are generated, leap seconds are not handled at all, or severe bugs occur due to side effects of the leap second handling.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2924">Martin Burnicki</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3402">
        <start>15:00</start>
        <duration>00:50</duration>
        <room>K.1.105 (La Fontaine)</room>
        <slug>ntimed_ntpd_replacement</slug>
        <title>Ntimed an NTPD replacement</title>
        <subtitle/>
        <track>Time</track>
        <type>maintrack</type>
        <language/>
        <abstract></abstract>
        <description></description>
        <persons>
          <person id="2182">Poul-Henning Kamp</person>
        </persons>
        <links>
          <link href="http://phk.freebsd.dk/time/">Sort of a running log</link>
          <link href="https://github.com/bsdphk/Ntimed">GitHub project</link>
        </links>
      </event>
      <event id="3443">
        <start>16:00</start>
        <duration>00:50</duration>
        <room>K.1.105 (La Fontaine)</room>
        <slug>ntf_s_general_timestamp_api_and_library</slug>
        <title>NTF's General Timestamp API and Library</title>
        <subtitle>Current timestamps suck.  We can do much better.</subtitle>
        <track>Time</track>
        <type>maintrack</type>
        <language/>
        <abstract>&lt;p&gt;A good timestamp can be a very useful thing.  Unfortunately, most current timestamps don't have enough information in them to be very useful, and they don't "age well"' and are too often not useful outside of the context of where they were taken.  After decades of casual thought, Harlan started to document what information would be needed to have a useful timestamp, and what sort of underlying support would be necessary to produce and use them.  This turned in to a GSoC project in  2013 where a proof-of-concept user-level library was produced, and some work was done to implement the new timestamp format as a core kernel timekeeping structure in a Linux kernel.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2918">Harlan Stenn</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="H.2215 (Ferrer)">
      <event id="2717">
        <start>10:00</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>gerrit_hooks</slug>
        <title>Validate your gerrit patches automaticly using magic hooks</title>
        <subtitle>hook framework to test patches as part of gerrit system</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;Use a hook framework, written in python to create rules to validate and automate tasks in your git/gerrit environment.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Every r&amp;amp;d department has its own rules and version planning for their product. It might be you're working on a latest (master) branch and at some point (feature freeze), you'll branch into a stable branch for the current version and backport only specific fixes to it. That process can be problematic and not without misses when managing a large scale project such as a virtualization project as oVirt. You'll want to integrate some validation into the process and ensure developers are following the right procedure, like merging fixes in right order (master-&gt;stable branch), adding 'bug-url' to the bug to maintain info on the bug fix and so on. In this talk I'll show you a unique system we developed for oVirt that works on gerrit (code review system) and bugzilla api that will run set of verification rules on each patch sent and will ensure patches are treated correctly and with respect! :)&lt;/p&gt;</description>
        <persons>
          <person id="1835">Eyal Edri</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2623">
        <start>10:20</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>luarocks</slug>
        <title>LuaRocks - fostering an ecosystem of Lua modules</title>
        <subtitle>Creating the package manager for the Lua language</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;This talk will present LuaRocks, the package manager for modules for the Lua programming language. Lua has successful as a scripting language embedded into applications, especially in the gaming industry. However, its "no-batteries-included" design prevented it from getting traction as a stand-alone application language.
LuaRocks was created to target this problem. This talk will discuss the particular challenges of developing a package manager for Lua. With this project, we've been successfully fostering an ecosystem of extension modules, improving reuse of Lua code.&lt;/p&gt;</abstract>
        <description>&lt;h2&gt;Full Description&lt;/h2&gt;

&lt;p&gt;This talk will present LuaRocks, the package manager for modules for the Lua programming language.&lt;/p&gt;

&lt;p&gt;Lua has been used for many years as a scripting language embedded into applications. It has been especially successful in the gaming industry, being present in several AAA titles. Its ease of embeddability, good performance and small footprint have been major factors it this success.&lt;/p&gt;

&lt;p&gt;However, its minimalistic, "no-batteries-included" design has also prevented it from getting much traction as a stand-alone application development language. A major setback was the lack of an easy way to integrate extension libraries for various tasks (such as sockets, databases, UI, XML/JSON, etc.)&lt;/p&gt;

&lt;p&gt;LuaRocks was created to target this problem. It is a package manager designed for Lua modules (written in Lua or C). It serves both as a package manager in the style of RubyGems or npm, and also as a build system for compiling C code into Lua modules.&lt;/p&gt;

&lt;p&gt;This talk will discuss the particular challenges of developing a package manager for Lua. Some are technical challenges, related to portability; some are social challenges that reflect into technical issues, such as the lack of established practices.&lt;/p&gt;

&lt;p&gt;With the LuaRocks project, we've been successfully fostering an ecosystem of extension modules for Lua. The repositories keep growing, and the dependencies between modules show that reuse is increasing.&lt;/p&gt;

&lt;h2&gt;About the presenter&lt;/h2&gt;

&lt;p&gt;Hisham Muhammad (Rio de Janeiro, Brazil) — lead developer of &lt;a href="http://luarocks.org"&gt;LuaRocks&lt;/a&gt;. PhD student at PUC-Rio, the university where Lua is developed. Other projects include &lt;a href="http://hisham.hm/htop"&gt;htop&lt;/a&gt; and &lt;a href="http://gobolinux.org"&gt;GoboLinux&lt;/a&gt;. I've been involved with the Lua community since 2004 and I have given talks on Lua-related topics in a number of conferences.&lt;/p&gt;</description>
        <persons>
          <person id="2352">Hisham Muhammad</person>
        </persons>
        <links>
          <link href="http://luarocks.org">LuaRocks</link>
          <link href="http://rocks.moonscript.org">the LuaRocks repository</link>
          <link href="http://lua.org">The Lua programming language</link>
        </links>
      </event>
      <event id="2797">
        <start>10:40</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>openchange_rest_api</slug>
        <title>How to create your own Exchange compatible backend</title>
        <subtitle>Dive into the OpenChange REST API</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;At OpenChange, we work on offering a portable Open Source implementation of Microsoft Exchange Server and Exchange Protocols. During the past 10 years, we have seen the community growing but not the number of developers. The conclusions were clear. The price to pay to develop on OpenChange was too high: C language only, very complex, too much knowledge required, too much time before you get visible results. We have addressed all these obstacles and will teach you during this talk how to set up the development environment in no time, understand the basics of the OpenChange REST API and leverage its resources and samples to get first visible results in Outlook today.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2502">Julien Kerihuel</person>
        </persons>
        <links>
          <link href="http://www.openchange.org">OpenChange website</link>
          <link href="http://www.openchange.org/documentation/api/mapistore-http/index.html">OpenChange REST API Reference</link>
        </links>
      </event>
      <event id="2832">
        <start>11:00</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>jmap</slug>
        <title>JMAP</title>
        <subtitle>A better way to interface with email</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;For the past 4 years, FastMail has been working on a next generation email protocol for our web interface.  We have years of experience writing email clients and servers, and we know where the pain points are.  This protocol is in production right now, and a 30 second demo will show it in action.&lt;/p&gt;

&lt;p&gt;At the moment the email world is divided.  Every vendor is building their own proprietary JSON protocol, because IMAP+SMTP is a really poor fit for mobile apps and even the LEMONADE protocol changes haven't made the experience good enough.&lt;/p&gt;

&lt;p&gt;We want to change that by offering a completely unencumbered standard which is good enough that companies don't need to build their own, and gain an interoperability layer which is better for everybody.  Raise the baseline experience if you will.  We believe it's possible to have a protocol which is both open AND good.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2567">Bron Gondwana</person>
        </persons>
        <links>
          <link href="http://jmap.io/">website</link>
        </links>
      </event>
      <event id="2687">
        <start>11:20</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>mail2voice</slug>
        <title>Mail2Voice: an accessibility approach to mail</title>
        <subtitle/>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;Mail2voice is a mail management software dedicated to people with cognitive disabilities or illiteracy, to elder people or young children.
Mail2Voice uses a simplified graphical interface which permits to use a touch screen.
Outgoing messages are handled through audio recording, incoming messages are read by a speech synthesis, and address book contacts are reachable through a photo.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2411">Matthieu Hazon</person>
        </persons>
        <links>
          <link href="http://www.mail2voice.org">website</link>
        </links>
      </event>
      <event id="3049">
        <start>11:40</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>agora_voting</slug>
        <title>Agora Voting</title>
        <subtitle>An end to end verifiable system</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;Agora Voting is an open source voting software that allows any organization to carry out secure, flexible, transparent and  cost-effective electoral processes. It has been used in multiple high profile elections in Spain, first in Congreso Transparente in 2013 by a congressman, then by multiple political parties (including leading ones like Podemos) to do internal binding elections, counting more than 400k votes in 2014. This year we moved to work on it full time, and we're expanding world-wide. Our aim: to be the reference secure open source voting project worldwide.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2724">Eduardo Robles Elvira</person>
        </persons>
        <links>
          <link href="http://agoravoting.org">Agora Voting</link>
          <link href="https://github.com/agoravoting">source code (multiple repositories)</link>
          <link href="https://groups.google.com/forum/#!forum/agora-voting">Mailing list</link>
          <link href="http://blog.agoravoting.com/">Blog</link>
          <link href="http://www.theguardian.com/world/2013/sep/11/joan-baldovi-spain-transparency-bill">Congreso Transparente</link>
        </links>
      </event>
      <event id="2528">
        <start>12:00</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>hacking_ceof</slug>
        <title>Hacking ceof</title>
        <subtitle>Enhancing the decentralised anonymous chat tool</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;Can you imagine there is a chat program existing that allows you to easily chat anonymously and makes life for the intelligence hard while not even chatting? And can you imagine there are only tiny bits missing to have it reach global scale?&lt;/p&gt;</abstract>
        <description>&lt;p&gt;In this lightning talk I will give a short introduction to ceof, what it can do, why it gives intelligence headache and why a hacknight at fosdem can improve the world.&lt;/p&gt;</description>
        <persons>
          <person id="2269">Nico Schottelius</person>
        </persons>
        <links>
          <link href="http://www.nico.schottelius.org/software/ceof">ceof</link>
        </links>
      </event>
      <event id="2869">
        <start>12:20</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>improving_key_signing_parties</slug>
        <title>Improving Key Signing Parties</title>
        <subtitle>Tools to make them easier, more secure, and much faster</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;KSP Tools is a set of tools to simplify and automate the tasks that are needed to attend a key signing party. They will significantly reduce the amount of work needed, and reduce the amount of errors that can be made. My aim is to reduce the amount of work to be done before and after the meeting to just 5 minutes, even with the large amount of people that attend the event at FOSDEM (~100 people), without compromising security.&lt;/p&gt;

&lt;p&gt;I also hope to considerably shorten the amount of time that a key signing party takes through future work.&lt;/p&gt;

&lt;p&gt;The current tools are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ksp-makelist: Generates a better formatted key list for usage at a key signing party. It's better looking, more readable, more comfortable to use and can be processed automatically by scanning QR codes.&lt;/li&gt;
&lt;li&gt;ksp-scanlist: Makes a list of keys to sign by scanning QR codes from the above list.&lt;/li&gt;
&lt;li&gt;ksp-list: Performs operations on a list of selected keys like signing keys and mailing them.&lt;/li&gt;
&lt;li&gt;ksp-import-keys: Connects to a mail server and automatically imports signatures people emailed to you.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The tools automatically check fingerprints and use a file format that is easy to handle with standard tools like grep and awk.&lt;/p&gt;

&lt;p&gt;These tools were made after my experience with key signing parties at FOSDEM and I hope other people will find them useful.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;After attending several key signing parties at FOSDEM I found that with a large number of participants it's a process that can take hours to finish the meeting, and a large amount of time afterwards to deal with the results. It's easy to make mistakes that make people waste their time, or that compromise security.&lt;/p&gt;

&lt;p&gt;Since PGP signatures are widely used in Free Software development (for instance for signing packages), it's important to make the process as reliable as possible.&lt;/p&gt;

&lt;p&gt;Signatures are also important for end users. Important packages like GPG or Tor are signed. The easier it is to participate in a key signing party, the more people will attend and will be able to know they got a good copy.&lt;/p&gt;

&lt;p&gt;The tools are written in simple, clear code and follow the UNIX philosophy, making it easy to customize the process to your needs.&lt;/p&gt;</description>
        <persons>
          <person id="2558">Vadim Troshchinskiy</person>
        </persons>
        <links>
          <link href="https://github.com/vatral/KeySigningPartyTools">github page</link>
        </links>
      </event>
      <event id="2764">
        <start>12:40</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>next_generation_cloud_computing</slug>
        <title>Cloud Computing: The Next Generation</title>
        <subtitle>Federation of the Cloud</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;Looking at the evolution of the Cloud everything started with centralized services. Today everybody can set up his own Cloud with Free Software. What's next? This talk will discuss the idea to connect this decentralized clouds in a way that users can share seamlessly data across multiple instances.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Looking at the evolution of the cloud, as a file share and sync solution, everything started with centralized services and evolved to to the point where everybody can set up his own Cloud with Free
Software. Decentralizing the cloud was a important step but at the same time it created islands. Only user on the same instance can collaborate on the same files. The next step will be to connect this individual clouds to enable the users to collaborate seamlessly across multiple instances. The ownCloud project works actively on this idea, this talk will discuss the general idea behind it and how this is going to happen.&lt;/p&gt;</description>
        <persons>
          <person id="2448">Björn Schießle</person>
        </persons>
        <links>
          <link href="http://www.owncloud.org">The ownCloud project</link>
        </links>
      </event>
      <event id="2639">
        <start>13:00</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>volunteer_computing</slug>
        <title>All your cycles are belong to us</title>
        <subtitle>Volunteer computing in the age of the ubiquituous browser</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;We live in an age in which every person owns two or three devices that are powerful enough to render a few seconds of 3D movies in a while although they are used mainly to send messages via WhatsApp and create selfies for social network consumption. At the same time, all these devices have the closest thing to an universal virtual machine that has ever existed: the JavaScript virtual machined, paired to a (roughly) standard object model that allows anybody with a bit of programming prowess to create programs that can be run anywhere and everywhere.
There is great potential for massive distributed computing in this environment, but the ability to tap it a bit farther than sending basic computations is not there yet. In this presentation we will talk about the issues involved in doing so, from basic algorithmic issues to twisted legal issues that can arise when you are using devices you don't own to perform unwitting computations.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Volunteer computing was started thanks to lack of funds and surplus of computing power (and connectivity to go with it) on the hands of labs and companies. Stealth computing was proposed initially by Barabasi to take advantage of devices connected to the network that perform very basic computations. There's a very fine line between them, a line that includes a button that says "Click here" or the will to not use resources more than those dutifully allotted by the operating system. There are also usability differences between volunteer and stealth computing and maybe ethical and legal ones. However, from the point of view of the computing model and the techniques involved, there is no difference.
In this talk we will explore the possibilities of stealth/volunteer computing using mainly the browser and the issues involved with it. The main one is performance, either from the algorithmic point of view or CPU-cycles-wise. How many CPU cycles could be achievable using them? Is it predictable in a way? And there is an intriguing edge to the performance model: it includes the fact that there will be a big dependence on the web page that is used itself, from its content, to its search engine position, to the way it is announced in social networks and by whom.
Even as there is some predictability in the whole experiment, from the algorithmic point of view it is impossible to know, in advance, how long a particular user is going to stay contributing to the system and when he's going to come and go. This is an issue that has to be leveraged in the algorithm so that these cycles contributed actually add something to the whole experiment and do not detract from it. We will specially talk about population-based algorithms, which are the ones we do have a certain experience with, but any algorithm that has some dependencies (that is, anything that goes beyond brute-force approach) will experience similar issues.
Finally, there are some trust issues that must also be taken into account. There are purely legal issues, but stealthy volunteer (or voluntarily stealth) computing should follow open science best practices, since that is the only way of managing a healthy and sustainable meta-computing device where people or citizens have a huge role.&lt;/p&gt;</description>
        <persons>
          <person id="1263">Juan Julián Merelo</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2838">
        <start>13:20</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>datacenter_provisioning</slug>
        <title>Datacenter Provisioning and Orchestration</title>
        <subtitle/>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;Discovery and tracking of data center resources to enable highly accurate server provisioning and software deployments is a complex problem. The inability to make available resources for use in production in a timely and cost effective manner causes overruns across product and feature life-cycles. Automating discovery, provisioning and orchestration cuts down on delays. This talk presents Genesis, an open source ruby DSL developed at Tumblr. Genesis provides a DSL for resource discovery and is part of an open source stack from Tumblr, alongside Phil (Provisioning) and Collins (Orchestration).&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The theme of the talk will be the need for discovery, provisioning and orchestration of physical infrastructure, presenting a non-traditional use case for Ruby. We will cover the DSL developed in Ruby that is part of Genesis. The talk will cover Genesis, from initialization using PXE (PreBoot Execution Environment), to tasks written using the DSL to discover system information.&lt;/p&gt;

&lt;p&gt;The talk will cover the history of Tumblr, growth from using PaaS providers to migrating to self owned and operated data centers. The challenges faced in accomplishing the transition and lessons learned from it leading to the need for Genesis (Discovery), Phil (Provisioning) and Collins (Orchestration).&lt;/p&gt;

&lt;p&gt;Key takeaways for attendees is exposure to Tumblr's experience of applying Ruby in a non-traditional domain. It will include coverage of datacenter design and operations, attendees can expect to gain an understanding of infrastructure software.&lt;/p&gt;

&lt;p&gt;NOTE: Genesis and Phil are not currently open sourced. Genesis will be open-sourced prior to the conference date and Phil at a later time. Collins, on which Genesis relies heavily on is already open-sourced.&lt;/p&gt;</description>
        <persons>
          <person id="2944">Felix Aronsson</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2716">
        <start>13:40</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>automated_devops_environment</slug>
        <title>Fabricate your automated devops environment using python</title>
        <subtitle>fabric is your (devops) friend</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;Maintaining a devop environment isn't easy, this talk will explain how to use fabric to automate a lot of tasks you're doing and some you havn't thought of even.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;At some point in your job as devops lead, you'll come to a conclusion there are some tasks that has to be automated (enough is enough!). You'll start looking for the right tool to do it, and you'll have lots of options out there, we chose fabric, and we're doing some cool stuff with it! In this short talk we'll show you how to use fabric from simple tasks such as updating multiple hosts using yum, to provisioning a system to any operating system you'll need or even monitoring Jenkins master status for offline slaves or job load, while utilizing nagios along the way.&lt;/p&gt;</description>
        <persons>
          <person id="1835">Eyal Edri</person>
        </persons>
        <links>
          <link href="http://www.fabfile.org/">http://www.fabfile.org/</link>
        </links>
      </event>
      <event id="2657">
        <start>14:00</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>upgrade_ux</slug>
        <title>Upgrade-UX</title>
        <subtitle>Upgrade-UX is a software framework to update or patch Unix systems</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;Upgrade-UX is an open source framework developed to assist in patching and/or updating Unix Operating Systems in a consistent and repeatable way. Especially in the industry it is forbidden just to run yum update (on Linux) to update your Linux system, therefore, upgrade-ux may proof to be a handy tool to guide you through the patching and/or update process as it follows a track you control (evidence gathering, pre/post executing of scripts, logging, and so on).&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Upgrade-UX is a software framework to update or patch lots of Unix systems (Linux, HP-UX, AIX and Solaris).&lt;/p&gt;

&lt;p&gt;In professional environments it is not allowed to just blindly update an UNIX system without testing this first out on a development system, pre-production and so on. The upgrade-ux product allows you to repeat this process in a consistent way and as many times as you like on any system. Upgrade-ux understands two states:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;preview mode: will go through the whole process without actually doing the update&lt;/li&gt;
&lt;li&gt;upgrade mode: will do it for real (the update)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The upgrade-ux uses configuration files which describes what a particular Unix Operating System requires to be upgraded in the way you want it (or designed it). Doing it this way allows you to exactly define how a system should look like after the upgrade or patching. Nothing else can be installed, removed or configured.&lt;/p&gt;

&lt;p&gt;Furthermore, many checks can be build-in via adding simple scripts. We also keep of each run an unique log file, and furthermore, we keep evidence before and after patching in a special directory. Months later we can still inspect these logs and evidence directories to verify what happened or what has changed in the meantime.&lt;/p&gt;</description>
        <persons>
          <person id="8">Gratien D'haese</person>
        </persons>
        <links>
          <link href="http://www.it3.be/projects/upgrade-ux.html">Upgrade-UX project</link>
        </links>
      </event>
      <event id="2900">
        <start>14:20</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>elvish</slug>
        <title>Elvish</title>
        <subtitle>an experimental Unix shell</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;Elvish is a new Unix shell that seeks to combine the expressiveness of a programming language with the convenience of a shell interface. In the lightning talk I will showcase the linguistic and interactive features of Elvish.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2569">Qi Xiao</person>
        </persons>
        <links>
          <link href="https://github.com/elves/elvish">Code</link>
          <link href="https://news.ycombinator.com/item?id=8090534">Hacker News submission</link>
          <link href="http://go-talks.appspot.com/github.com/xiaq/elvish-fudcon2014/elvish.slide">Talk at FUDCON Beijing 2014</link>
        </links>
      </event>
      <event id="2562">
        <start>14:40</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>satnogs</slug>
        <title>SatNOGS - Global Network of Ground Stations</title>
        <subtitle>Creating a full stack of destributed ground station management.</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;SatNOGS project is a complete platform of an Open Source Networked Ground Station. The scope of the project is to create a full stack of open technologies based on open standards , and the construction of a full ground station as a showcase of the stack. In this lighting talk we will be introducing the software stack of the project, including a scheduling and observations management server, a data crowd-sourcing app and the client of the ground station.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2302">Pierros Papadeas</person>
        </persons>
        <links>
          <link href="http://hackaday.io/project/1340-SatNOGS">Detailed site for project</link>
          <link href="http://satnogs.org/">Project Website</link>
          <link href="https://github.com/satnogs/">Code repositories</link>
        </links>
      </event>
      <event id="2856">
        <start>15:00</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>openbazaar</slug>
        <title>OpenBazaar</title>
        <subtitle>Decentralized markets for online trade</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;We will have a half-dozen members of the OpenBazaar team at the conference, and we'd like to give an overview of how our decentralized marketplace for online trade works. Our goal is to give a slideshow (attached) that explains the basics around the history and evolution of the platform, a high-level explanation of the technical challenges and solutions to creating a decentralized marketplace, and then ask them to come visit our stand to give them a personal demonstration.&lt;/p&gt;

&lt;p&gt;Please contact me at sam@openbazaar.org if you have any questions.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2249">Dionysis Zindros</person>
          <person id="2535">Sam Patterson</person>
        </persons>
        <links>
          <link href="https://blog.openbazaar.org/what-is-openbazaar/">Explanation of OpenBazaar</link>
        </links>
      </event>
      <event id="2887">
        <start>15:20</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>health_sector</slug>
        <title>Open source is not only for geeks and idealists in the (danish) health sector</title>
        <subtitle>A presentation of the OpenTele project and other health related projects by the 4S organisation</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;A presentation of the telemedicine project OpenTele, and the 4S organization behind it.&lt;/p&gt;

&lt;p&gt;We will talk about the impact OpenTele has had for the many conical ill and pregnant who has used it in the pilot phase, and what the (open source) community can use OpenTele and the related 4S toolbox for.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;We would like to make a presentation of the open source OpenTele project and what it has done for people in Denmark, as well as shortly introduce the toolbox of open source modules that are under the wings of the 4S organization.&lt;/p&gt;

&lt;p&gt;We do this to increase the awareness of our project in the open source community, we want to extend our community beyond the limited reach it currently has, open for contributions on all levels, and for letting people with interest in the health sector know that there is a free alternative that they can promote and use in their own projects, but also in their local communities by cooperating with medical professionals.&lt;/p&gt;

&lt;h1&gt;4S&lt;/h1&gt;

&lt;p&gt;4S is an open source ecosystem for telemedicine providers and consumers. Members include the National eHealth Authority (who is responsible for setting the national standards for telemedicine in Denmark), three out of the five Danish regions (who operate all public hospitals and secondary care), municipalities (primary health care and social care), software providers, Aarhus University and the Alexandra Institute. The two latter are currently the operators of 4S.&lt;/p&gt;

&lt;h1&gt;Open Tele&lt;/h1&gt;

&lt;p&gt;OpenTele is an open source project that is governed by 4S and released under an Apache 2.0 license - it is in a transition phase from different pilot projects to production mode, and going from the company that originally developed it, into the 4S open source eco system.&lt;/p&gt;

&lt;p&gt;OpenTele is currently being used for people with diabetes, COPD and pregnancies with medical complications - allowing medical staff to monitor patients remotely, and empowering patients with respect to their own illness or pregnancy, giving them a better understanding of their issues and the ability to be proactive with respect to their own treatment.&lt;/p&gt;

&lt;h1&gt;The Toolbox&lt;/h1&gt;

&lt;p&gt;A number of separate components are being developed, either as spin-offs from OpenTele or as separate components.&lt;/p&gt;

&lt;p&gt;We are a couple of people that are currently working on making a device communication module written in C++ with ports to Ubuntu and Android for talking with Continua medical devices as well as devices using proprietary formats.&lt;/p&gt;

&lt;p&gt;It's possible to use our code either from html5 sites running in the app, or to build new apps from the code, this can be used in other projects that wishes to have integration with measurement devices, either as medical applications or health/fitness aware application and of course all the things we didn't even dream about yet.&lt;/p&gt;

&lt;p&gt;The devices that this component will provide easy communication with are things like weight scales, blood pressure monitors, puls-oxymeters, blood glucose monitors etc.&lt;/p&gt;</description>
        <persons>
          <person id="2596">Mike Kristoffersen</person>
        </persons>
        <links>
          <link href="http://4s-online.dk/wiki/doku.php">The 4S, Net4Care and OpenTele Wiki</link>
        </links>
      </event>
      <event id="2670">
        <start>15:40</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>medical_imaging</slug>
        <title>Free and open-source software for medical imaging</title>
        <subtitle>Bringing technological independence to hospitals</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;The amount of medical images that are generated, analyzed and exchanged by hospitals is dramatically increasing. Medical imaging is indeed the first step to the treatment of more and more illnesses, such as cancers or cardiovascular diseases.&lt;/p&gt;

&lt;p&gt;In turn, the data management of clinical images and the administration of the computer network of a medical imaging department imply continuously growing technological challenges. Tasks such as autorouting between imaging modalities, exchanging data between clinical departments or hospitals, or anonymizing images are still hard to achieve in practice. This is a direct consequence of the lack of interoperability software that could bring technological independence to hospitals by creating low-cost gateways between proprietary ecosystems.&lt;/p&gt;

&lt;p&gt;In this talk, I will explain the pains behind modern medical imaging, from the perspective of the hospitals. The DICOM standard will be introduced, together with free and open-source software supporting this standard.&lt;/p&gt;

&lt;p&gt;I will then put emphasis on the free software Orthanc, a lightweight, versatile DICOM server. Thanks to its REST API and to its Lua scripting engine, Orthanc is primarily conceived as a central, robust building block to bring technological independence to clinical departments by automating their very specific imaging flows. Orthanc was nominated at the Zénobe Award 2013 for social innovation.&lt;/p&gt;</abstract>
        <description>&lt;h1&gt;Table of Contents&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Introduction: Imaging flows for radiology and radiotherapy&lt;/li&gt;
&lt;li&gt;DICOM and the pains of medical imaging&lt;/li&gt;
&lt;li&gt;Free and open-source software for DICOM&lt;/li&gt;
&lt;li&gt;Orthanc:

&lt;ul&gt;
&lt;li&gt;Description and architecture&lt;/li&gt;
&lt;li&gt;Automating imaging flows with Orthanc&lt;/li&gt;
&lt;li&gt;The present and the future of Orthanc&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Conclusion&lt;/li&gt;
&lt;/ul&gt;
</description>
        <persons>
          <person id="2392">Sébastien Jodogne</person>
        </persons>
        <links>
          <link href="http://www.orthanc-server.com/">Homepage of Orthanc</link>
          <link href="https://fr.wikipedia.org/wiki/Orthanc_(logiciel)">Orthanc on Wikipedia (French)</link>
        </links>
      </event>
      <event id="2698">
        <start>16:00</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>leihs_booking_system</slug>
        <title>Leihs, the leading free equipment booking system</title>
        <subtitle>It took us eight years to get it right. What we learned about being a FOSS project.</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;leihs is probably the most widely used free inventory management and equipment booking system. Started at the Zürich University of the Arts (ZHdK) in order to manage their own sizeable pool of equipment, it quickly became clear that other organizations have exactly the same problems. It now made sense to release leihs under the GPL. In this talk, Ramón talks about mistakes made, challenges and things learned in the last 8 years of managing a free software project from within a government organization.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;leihs began as a small internal project, written when Ruby on Rails was still young and considered cutting-edge technology. Deployment was messy and unreliable, the code had to be changed significantly with every Rails upgrade and even Ruby itself had a few pretty bad bugs at the time. But we stuck with it and rewrote the core and most of the interface for version 2.0. This was the initial version of leihs released under the GPL. Later GitHub came along, and so leihs went there. With GitHub came some popularity, and the project really took off when we redesigned the user interface yet again, this time with real interaction designers.&lt;/p&gt;

&lt;p&gt;The main takeaways from eight years of free software development:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If you choose a technology that's immature, things get very exciting. But be prepared to rewrite your code again and again as the foundation you built on shifts.&lt;/li&gt;
&lt;li&gt;Don't add internationalization at a later time, do it from the start. One of my biggest regrets is not going with a complete German/English interface from the start.&lt;/li&gt;
&lt;li&gt;Make sure your management understands what it means to do free software, and that you can't just do your own thing. Be part of your own community. Comment on bug reports, write change logs, have a project blog -- if you treat the community as if it isn't there, it will soon not be there anymore.&lt;/li&gt;
&lt;li&gt;If you're doing something with a GUI and don't have interaction- or UX people, hire professionals to do it for you.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;leihs has now been installed at some very important universities and colleges in and outside Switzerland. I want to encourage anyone who is paid with taxpayer money to develop free software and to politely urge their management into letting them do it. But I don't want to create the illusion that it will be easy.&lt;/p&gt;</description>
        <persons>
          <person id="2424">Ramón Cahenzli</person>
        </persons>
        <links>
          <link href="https://github.com/zhdk/leihs">homepage</link>
        </links>
      </event>
      <event id="2873">
        <start>16:20</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>community_data</slug>
        <title>Data, data and data about your favourite community</title>
        <subtitle/>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;This talk aims at providing a quick overview of the GrimoireLib library. This python-based piece of code provides a list of classes that help to analyze open source communities. This talk is intended for those interested in open source analytics and want to have a better understanding of the community and processes around their favourite open source projects. The talk will use ipython notebook recipes to follow the code.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;GrimoireLib [1] is a python-based library that facilitates the analysis of open source communities. This is part of the Grimoire toolset, a set of tools that help to download, parse and analyze open source communities from several perspectives. Activity in the source code, mailing lists, ticketing systems are some of the data sources supported by this toolset.&lt;/p&gt;

&lt;p&gt;This talk assumes the existence of a previous CVSAnalY retrieved database and will play with the several metrics and analysis available at GrimoireLib. Examples driven on ipython notebook will help to follow the talk. And specific analysis of some communities will be carried out. Among other metrics, commits from several perspectives will be calculated: branches, message log, type of file, organizations, module, and others.&lt;/p&gt;

&lt;p&gt;[1] https://github.com/VizGrimoire/GrimoireLib&lt;/p&gt;</description>
        <persons>
          <person id="565">Daniel Izquierdo</person>
        </persons>
        <links>
          <link href="https://github.com/VizGrimoire/GrimoireLib">https://github.com/VizGrimoire/GrimoireLib</link>
        </links>
      </event>
      <event id="3349">
        <start>16:40</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>home_automation</slug>
        <title>Open source home automation</title>
        <subtitle>by OpenMotics</subtitle>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;There are 3 problems with close source home automations systems. i. These systems tend to be ridiculously expensive for the features that they offer, since most vendors target the high-end market segment with customized solutions. ii. Configuring and maintaining the system has to be done by a certified installer, giving the customer little control over their own house. iii. Theses systems use closed-source communication protocols and you -as a user- are not able to interface with the system or change anything in the system.&lt;/p&gt;

&lt;p&gt;OpenMotics is an open source home automation hardware and software system that offers features like switching lights and outputs, multi-zone heating and cooling, power measurements, and automated actions. The system encompases both open source software and hardware. For interoperability with other systems, the OpenMotics Gateway provides an API through which various actions can be executed. The project was open sourced 2 years ago and was started about 10 years. The choice to open source the project was very conscious: we want to offer a system where users are in full control over their home automation system.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;OpenMotics is an open source home automation hardware and software system that offers features like switching lights and outputs, multi-zone heating and cooling, power measurements, and automated actions. The system encompases both open source software and hardware. For interoperability with other systems, the OpenMotics Gateway provides an API through which various actions can be executed.&lt;/p&gt;

&lt;p&gt;Open source software: Download, adjust and recompile the source code of our Home Automation Modules; licensing as GPLv2.&lt;/p&gt;

&lt;p&gt;Open hardware: Download the PCB files (including BOM and schematics) to create, adjust and manufacture your own hardware; licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.&lt;/p&gt;

&lt;p&gt;The project first started 10 years ago with basic hardware modules for switches and outputs. Since then the number of modules has increased to create an extensible full-featured home automation system. The modules include a Gateway module that is the heart of the system which drives all other modules. An Input module for reading the status of the switches. An Output module that toggles lights, outlets or other devices. And others like a Dim Control module, a Sensor module and a Power module for measuring the power consumed by each appliance in your home.&lt;/p&gt;

&lt;p&gt;Two years ago we decided to open source the software running on the Gateway module, all firmware running on the other modules and the schematics and PCBs (printed circuit boards) for all modules. The choice to open source the project was very conscious—at OpenMotics we believe there are three fundamental problems with the existing commercial home automation offerings.&lt;/p&gt;

&lt;p&gt;The first problem concerns the price: home automation systems tend to be ridiculously expensive for the features that they offer. Most vendors target the high-end market with fully integrated custom solutions. The alternative is using open source software like OpenHAB to stitch together components from different vendors. With OpenMotics we offer a complete solution that is easy to install, configure and use, at a fair price.&lt;/p&gt;

&lt;p&gt;The second problem is that many home automation systems are not maintainable by the customer, and every change to the system requires an installer to come by at location to make the changes. We believe a home, and how it is used, changes over the years and the owner should be able to modify the configuration of his home automation system to reflect this. Compare this to a smartphone where you don't have to run to the shop every time you want to install a new app. So why should your home automation system be any different? Why shouldn't we be in full control of our own homes?&lt;/p&gt;

&lt;p&gt;For more tech-savvy users, the inability to configure your own system brings us to the third problem: most proprietary systems use closed communication protocols and you—as a user—are not able to interface or change anything. Everybody has ideas on how they could make their home better, a home automation system should enable the user to implement these improvements. We tackled this problem on three different levels.&lt;/p&gt;

&lt;p&gt;First, as described above, the user is in full control over the configuration of the system and can change it at any time. For techy users, we provide a plugin mechanism on the Gateway module: any self written or community developed plugin can be installed through the secure web interface. These plugins can communicate with the modules, catch events like lights turning on or off, expose a web interface and communicate with other services. The possibilities are up to your own imagination. And third, because the software and hardware are both open source, an electronics and/or software enthusiast can modify both hardware and software at will, or even create their own modules. Or you can just use the system as is, with lots of features readily available.&lt;/p&gt;</description>
        <persons>
          <person id="2862">Frederick Ryckbosch</person>
        </persons>
        <links>
          <link href="https://www.openmotics.com">OpenMotics</link>
          <link href="http://www.openhab.org/">OpenHAB</link>
        </links>
      </event>
      <event id="2713">
        <start>17:00</start>
        <duration>00:15</duration>
        <room>H.2215 (Ferrer)</room>
        <slug>kodi_mediacenter</slug>
        <title>Open source Kodi mediacenter (XBMC) past, present and future</title>
        <subtitle/>
        <track>Lightning talks</track>
        <type>lightningtalk</type>
        <language/>
        <abstract>&lt;p&gt;A brief overview of Kodi (XBMC) open source Media center. How one of the oldest and largest open source projects originated, the path walked to present day and what the future might hold. Talk will include a brief history overview, what steps were taking to come in current state and what our goals are for the future.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Title:
From XBMP to XBMC to Kodi: A Brief History of the Trials of a User-facing Media Center and it's future&lt;/p&gt;

&lt;p&gt;Brief description:
In this talk, we will review many of the issues, solutions, pitfalls, and near miracles that have occurred since Kodi started out as a simple media player for the original Xbox.&lt;/p&gt;

&lt;p&gt;Short abstract:
It's relatively rare and difficult to keep a large scale open source project going year after year without the firm financial backing of a larger organization. Since its inception in 2002, the software currently called Kodi has gone through numerous changes, both at the software level and at the organizational level, and has encountered numerous difficulties along the way, from simple communications problems both internally and with the userbase to larger organizational snafus. In this talk, we'll briefly go through the history and what we have planned for the future&lt;/p&gt;</description>
        <persons>
          <person id="2447">Martijn Kaijser</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="UD2.120 (Chavanne)">
      <event id="3031">
        <start>09:00</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>underhoodcontainers</slug>
        <title>Under the hood of Docker Containers</title>
        <subtitle>In flight and at rest</subtitle>
        <track>Virtualisation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Docker containers are generating excitement because of relatable and recognizable use cases and unique facilitation of solutions. One example of this is easy distribution of the container environment.  Docker does this with a particular design of images.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;In this talk, we will discuss:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Storage of Docker images: the drivers available as well as some of best practices and recommended performance tunings.&lt;/li&gt;
&lt;li&gt;Notes on the format: how a Docker image is at rest on a daemon versus a registry, and how the image is transferred.&lt;/li&gt;
&lt;li&gt;Verification of images: mechanics of validation and how to return reproducible sums&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The goal of this talk is to provide greater awareness of options available for daemon setup, knowledge around the bits in-flight daemon-to-registry, and assurance of this data.&lt;/p&gt;</description>
        <persons>
          <person id="2344">Vincent Batts</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3048">
        <start>09:40</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>dockerovirt</slug>
        <title>Docker Integration in oVirt and IaaS</title>
        <subtitle/>
        <track>Virtualisation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This session will present the current status of integration between oVirt, Docker containers and Kubernetes. It will cover the motivations, some of the low level details and ideas for the future. The second part of the presentation will be dedicated to possible future work within oVirt, ideas for the new concept of multi-purpose data-center and an overview of other projects related to Docker and IaaS.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Deploying an Application (Old-Fashion and Docker)&lt;/li&gt;
&lt;li&gt;Ecosystem: Kubernetes and Project Atomic&lt;/li&gt;
&lt;li&gt;Current Status of Integration in oVirt&lt;/li&gt;
&lt;li&gt;oVirt Docker User-Interface Plugin&lt;/li&gt;
&lt;li&gt;Dockerized oVirt Engine&lt;/li&gt;
&lt;li&gt;Docker on Virtualization&lt;/li&gt;
&lt;li&gt;Possible Future Integration&lt;/li&gt;
&lt;li&gt;Managing Containers as VMs&lt;/li&gt;
&lt;li&gt;Future Multi-Purpose Data Centers&lt;/li&gt;
&lt;li&gt;Other Projects Related to Docker and IaaS&lt;/li&gt;
&lt;/ul&gt;
</abstract>
        <description></description>
        <persons>
          <person id="620">Federico Simoncelli</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2929">
        <start>10:20</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>livemigration</slug>
        <title>Live migration for containers is around the corner</title>
        <subtitle/>
        <track>Virtualisation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;CRIU (checkpoint/restore in userspace) is a project, which allows to dump a group of processes on a disk and restore them back later on the same or another host. Another significant use case is online (iterative) migration of Linux Containers.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;CRIU (checkpoint/restore in userspace) is a project, which allows to dump a group of processes on a disk and restore them back later on the same or another host. Another significant use case is online (iterative) migration of Linux Containers. CRIU project was born in OpenVZ team to replace their in-kernel realization.&lt;/p&gt;

&lt;p&gt;There was a talk here about CRIU two years ago. In that time CRIU was a young project and we needed to do a lot of things to be ready for real use. Now CRIU is mature enough, the main functionality is completed. People are getting more and more interested in the project. They are integrating CRIU into their own projects.  Our community becomes bigger. There are more than thirty people from Parallels, Canonical, Google, Docker, etc.&lt;/p&gt;

&lt;p&gt;The talk will cover following questions:
* How does this work?
* How to integrate CRIU in another project?
* What are the most interesting use cases?
* What are the current state and future plans?
* How are we caring about quality?&lt;/p&gt;</description>
        <persons>
          <person id="2445">Andrew Vagin</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2697">
        <start>11:00</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>provisiondocker</slug>
        <title>Provision and manage Docker containers with Foreman</title>
        <subtitle>Roll out your applications in containers with ease</subtitle>
        <track>Virtualisation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Deploying containers, images with Docker is becoming a big trend. However, large installations of containerized applications are still few and far between, and solutions are either proprietary or they force you to use their own cloud.&lt;/p&gt;

&lt;p&gt;We believe Foreman can fill this space by providing a central space to provision and manage your containers and your network, as we already do with your data center. This provides a great framework for mixed environments where physical machines, vms, and containers are all used in conjunction. Orchestration through Kubernetes is being implemented at the moment.&lt;/p&gt;

&lt;p&gt;Monitoring, deploying, and everything else is possible to do through the web UI or an API, and it's open source, so if you miss any feature, feel free to add it!&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Deploying containers, images with Docker is becoming a big trend. However, large installations of containerized applications are still few and far between, and solutions are either proprietary or they force you to use their own cloud.&lt;/p&gt;

&lt;p&gt;We believe Foreman can fill this space by providing a central space to provision and manage your containers and your network, as we already do with your data center. This provides a great framework for mixed environments where physical machines, vms, and containers are all used in conjunction. Orchestration through Kubernetes is being implemented at the moment.&lt;/p&gt;

&lt;p&gt;Monitoring, deploying, and everything else is possible to do through the web UI or an API, and it's open source, so if you miss any feature, feel free to add it!&lt;/p&gt;</description>
        <persons>
          <person id="2413">Daniel Lobato</person>
        </persons>
        <links>
          <link href="http://github.com/katello/katello">Katello, for docker registries content management</link>
          <link href="http://github.com/theforeman/foreman-docker">Foreman Docker, the plugin for container management and orchestration</link>
          <link href="http://theforeman.org">Provision, monitoring, management of baremetal, virtual, and now containers all in one</link>
        </links>
      </event>
      <event id="3377">
        <start>11:40</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>rocketspec</slug>
        <title>Rocket and the App Container Spec</title>
        <subtitle/>
        <track>Virtualisation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Rocket is a simple daemon-free tool that enables users to run containerized apps on their systems free of host dependencies. Containers running under rocket execute like regular processes and can be managed using existing process management tools like upstart, systemd, runit, and etc.&lt;/p&gt;

&lt;p&gt;Rocket is also an implementation of the "App Container Spec" which defines how to define and build containerized applications based on tooling like tar and pgp. And then host these files easily using standard protocols like HTTP. The goal of the spec is to enable independent and creative implementations of container runtimes and build tools.&lt;/p&gt;

&lt;p&gt;Both of these projects are open source and part of a young growing community. Come learn how they work and how you can get involved.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2880">Kelsey Hightower</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3148">
        <start>12:20</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>zombieapocalypse</slug>
        <title>Surviving the Zombie Apocalypse</title>
        <subtitle>Containers, KVM, Xen, and Security</subtitle>
        <track>Virtualisation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In our interconnected world of mobile and cloud computing, particularly with the rise of governmental spying, corporate espionage, and theft of data by organized crime syndicates, security is more important than ever.  Many claims are being made about the security of open-source cloud technologies: How can administrators, users, and developers separate fact from fiction?&lt;/p&gt;

&lt;p&gt;This talk will equip the audience with the principles needed to evaluate security claims.  We will talk the nature of risk, of vulnerabilities and exploits; the various factors that reduce the risk of vulnerabilities in software;  and about TCB, threat models, and defense-in-depth.  And we will introduce a colorful and (hopefully) helpful analogy to help make these concepts more clear.&lt;/p&gt;

&lt;p&gt;We will then apply these principles to three open-source cloud technologies: containers, KVM, and Xen, to see how they stack up.  These will be backed up with numbers: lines of code, security advisories, entry points, and so on.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Audience&lt;/p&gt;

&lt;p&gt;This is particularly aimed at system administrators or system architects wishing to make decisions about which cloud technologies to use or deploy.  It should also be of interest to those who want an introduction to thinking about security analysis in general.&lt;/p&gt;

&lt;p&gt;Benefits to the ecosystem&lt;/p&gt;

&lt;p&gt;First, it will help those making decisions about which technology to used to make an informed decision.  Secondly, by giving the  audience a framework for thinking about security analysis, and show how to apply it to some concrete examples, it will help anyone thinking about security in almost any area of development or configuration.&lt;/p&gt;</description>
        <persons>
          <person id="2772">George Dunlap</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3363">
        <start>13:00</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>lxd</slug>
        <title>LXD: The Container Hypervisor</title>
        <subtitle/>
        <track>Virtualisation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;LXC is a production-ready container management toolset focused on flexible container management.  Its container management API has language bindings for many languages including C, python, Go, lua, and more.&lt;/p&gt;

&lt;p&gt;LXD is a new project by the LXC community. It provides a REST API for LXC, an improved command line interface and OpenStack integration plugin.  The command line interface lets you control both local and remote LXD in a perfectly transparent way including live migration.  LXD is also strongly focused on security, uses user namespaces by default, integrates with apparmor, selinux, seccomp and any other security mechanism available.&lt;/p&gt;

&lt;p&gt;This talk will present the most exciting features of LXD, including a walk-through of the new command line tool.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2868">Serge Hallyn</person>
        </persons>
        <links>
          <link href="http://lxd.linuxcontainers.org">lxd homepage</link>
        </links>
      </event>
      <event id="3259">
        <start>13:40</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>observability</slug>
        <title>Observability in KVM</title>
        <subtitle>How to troubleshoot virtual machines</subtitle>
        <track>Virtualisation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;KVM is the most popular hypervisor deployed with OpenStack and is also often used with libvirt in non-cloud scenarios.  With multiple layers of software between the user and the virtual machine, how does one troubleshoot failures and performance issues?&lt;/p&gt;

&lt;p&gt;This presentation covers tools and techniques for observing virtual machines with the KVM hypervisor.  It gives you a mental model of KVM's architecture so you'll know how to get to the bottom of questions about virtual machine behavior and performance.&lt;/p&gt;

&lt;p&gt;Areas covered include guest CPU activity, RAM, disk I/O, network traffic, and the QEMU monitor.  Examples are based on real-life scenarios often encountered by KVM users.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The KVM hypervisor is part of the Linux kernel, making it an easy and popular way to run virtual machines on Linux hosts.  KVM is also the most well supported and popular hypervisor deployed with OpenStack, typically through the libvirt library.&lt;/p&gt;

&lt;p&gt;When something goes wrong with a virtual machine there are often questions like "how do I see the network packets that the host is receiving for this virtual machine?" or "can I find out which virtual machine is causing excessive disk I/O?".&lt;/p&gt;

&lt;p&gt;Luckily KVM is not a black box, it's an open source hypervisor that runs together with the userspace QEMU emulator.  There are a wealth of tools for observing virtual machine activity and they can be used to troubleshoot failures and performance issues.  From packet sniffing to CPU profilers, tracing to debuggers, this talk covers the arsenal of tools and how to apply them.&lt;/p&gt;

&lt;p&gt;This presentation arms you with knowledge of KVM's architecture and how to observe virtual machine activity.  Monitoring and debugging virtual machines is actually much like (and sometimes even easier than) on physical machines so you can reuse many familiar tools.&lt;/p&gt;

&lt;p&gt;Once you understand how virtual machines interact with the outside world, how CPU, RAM, disk I/O, and network resources are connected, investigating issues with virtual machines becomes a systematic process.  This presentation includes examples of common questions you can ask with the help of performance monitoring and debugging tools.&lt;/p&gt;

&lt;p&gt;This talk is suitable for both users of KVM virtual machines and developers of management software like libvirt, OpenStack, or oVirt.  The aim is share knowledge gained from real-world cases so that virtual machines are not just a joy to use, but also a powerful vehicle for observability.&lt;/p&gt;</description>
        <persons>
          <person id="2816">Stefan Hajnoczi</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2893">
        <start>14:20</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>transplantation</slug>
        <title>Transplantation of VirtualBox to the NOVA microhypervisor</title>
        <subtitle/>
        <track>Virtualisation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;NOVA is both a microkernel and a hypervisor. With only 10,000 lines of code, it is able to host virtual machines and applications securely side by side. In contrast to mature virtualization solutions like VirtualBox, however, the range of supported virtual machines used to be limited to a few fine-tuned guest OSes. The talk explains and demonstrates how VirtualBox became able to run on top of Genode/NOVA, and presents the benefits of combining NOVA with VirtualBox.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Commodity open-source virtualization solutions like Qemu/KVM and VirtualBox have received tremendous work and hand-crafted heuristics to enable a wide range of unmodified guest operating systems to run flawlessly inside virtual machines. On the other hand, those commodity virtualization solutions rely on a highly complex trusted computing base. Speaking of VirtualBox, the user has to ultimately trust the VirtualBox application in addition to the host OS kernel because VirtualBox exercises all-encompassing control over the host system. This high complexity comes with a high likelihood for bugs and thereby represents a large attack surface that puts the security and privacy of the user at risk.&lt;/p&gt;

&lt;p&gt;With the NOVA virtualization architecture, there exists an alternative approach where the complex parts of the virtualization platform are executed in the form of unprivileged components on top of a low-complexity hybrid microkernel/hypervisor. The hypervisor solely provides mechanisms to segregate platform resources, to enable secure inter-component communication, and to reflect virtualization events to user-level virtual-machine monitors. This way, the effective isolation between virtual machines as well as components that run beside virtual machines depends on a trusted computing base of less than one percent compared to commodity virtualization solutions. On the downside, the beauty of the architecture has not gained much attention because NOVA's existing user-level virtual machine monitor lacked the feature set and out-of-the box experience of mature virtualization products.&lt;/p&gt;

&lt;p&gt;The talk will present how the feature-rich VirtualBox virtual machine monitor was brought to the NOVA microhypervisor using the Genode OS framework as user-level infrastructure. It will start with an overview of the VirtualBox architecture on the traditional platforms, followed by a brief introduction into the world of NOVA and Genode. The main part of the talk will explain the methodology of the transplantation work and the challenges that had to be overcome. Finally, it will outline the benefits and possible future directions of combining both technologies.&lt;/p&gt;

&lt;p&gt;The presentation will be held using a Genode/NOVA system, which will also be used for a live demonstration.&lt;/p&gt;</description>
        <persons>
          <person id="607">Norman Feske</person>
        </persons>
        <links>
          <link href="http://genode.org">Genode OS Framework</link>
        </links>
      </event>
      <event id="3068">
        <start>15:00</start>
        <duration>00:40</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>xorchestra</slug>
        <title>Xen Orchestra: a web UI for Xen and XenServer</title>
        <subtitle>Handle modern IaaS needs from the web</subtitle>
        <track>Virtualisation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;XenServer exposes a fully featured management API called XAPI. Xen Orchestra was originally designed as web interface for Xen in 2009, and is now a complete re-write to leverage all those new possibilities.&lt;/p&gt;

&lt;p&gt;This is the story of a tool evolving from "simple hypervisor management" to a "Infrastructure as a Service" interface, with all the challenges involved.&lt;/p&gt;

&lt;p&gt;First, we will examine architecture choices of Xen Orchestra (to reduce connections, bandwidth waste, storing of structured data, allowing persistence and so on...), then and how we decide to address common problems, like user permissions and ACLs in a virtualized infrastructure. Finally, we'll see the roadmap of this fully open source project (aGPLv3)&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2730">Olivier Lambert</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3196">
        <start>16:20</start>
        <duration>00:20</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>numaovirt</slug>
        <title>Utilizing NUMA architecture in oVirt</title>
        <subtitle/>
        <track>Virtualisation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;For several years now, the oVirt project is leveraging KVM and relevant technologies (ksm, etc) in data center virtualizations. Being a mature
and feature reach, oVirt takes another step forward with introducing NUMA architecture support which will allow better utilization of hypervisors
in advanced virtual data centres. Different NUMA implementations and insights on use cases will allow participants to gain more knowledge on how
to optimize their existing hypervisors in the virt world.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Starting the latest release of the oVirt project, NUMA architecture is
supported. This presentation will cover general NUMA architecture concepts,
as well as review recent oVirt improvements to support NUMA.&lt;/p&gt;

&lt;p&gt;The first part will provide an introduction to Non Uniform Memory Access
and its importance for better utilization of current hardware. The differences
between NUMA implementations in various Linux kernels (numad VS autonuma)
should provide insights on how NUMA is implemented to participants of this
presentation.&lt;/p&gt;

&lt;p&gt;The second part of this session we will present support of various NUMA modes
with insights for various flows and use cases. participants will hear about
virtual NUMA options available today, which are quite advanced in the virt
world.&lt;/p&gt;</description>
        <persons>
          <person id="1417">Doron Fediuck</person>
        </persons>
        <links>
          <link href="http://www.ovirt.org/Features/NUMA_and_Virtual_NUMA">oVirt NUMA feature page</link>
        </links>
      </event>
      <event id="3154">
        <start>16:40</start>
        <duration>00:20</duration>
        <room>UD2.120 (Chavanne)</room>
        <slug>immutable</slug>
        <title>CentOS Virt SIG</title>
        <subtitle>Community virtualization packages on an immutable core</subtitle>
        <track>Virtualisation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;CentOS is a "distribution" with a rather unique description: it is a free (gratis) clone of a commercially-supported "distribution" with all the branding removed.  Being enterprise-grade distribution means solid and well-tested; but it also means not having the latest functionality.  It also means having a small enough feature set to provide commercial support in a viable manner: and that typically means choosing one technology and sticking with it.&lt;/p&gt;

&lt;p&gt;But what if you wanted your entire system to be solid, and well-tested, but want the latest features for one particular package or program?  Or what if you really wanted an enterprise system, but wanted to use one of the alternate technoligies that were not selected?&lt;/p&gt;

&lt;p&gt;This is where CentOS SIGs come in.  The new CentOS is still at its core a clone of an upstream enterprise distribution.  But having had success with the Xen4CentOS project, which provided a version of Xen to run on CentOS 6, they have now generalized the process.&lt;/p&gt;

&lt;p&gt;This talk will talk about CentOS SIGs: the vision, the structure, what SIGs are available. We will compare and contrast them to other community distro development models like Fedora, OpenSuSE, Debian, Ubuntu, and so forth.  We will also share lessons from the CentOS Virt SIG, in which a number of virtualisation and related technologies such as Xen, oVirt, Docker and others collaborate.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2772">George Dunlap</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="UB2.252A (Lameere)">
      <event id="2689">
        <start>09:00</start>
        <duration>00:45</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>starting_yocto</slug>
        <title>Starting with the Yocto Project</title>
        <subtitle/>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Yocto has an alleged steep learning curve. It can be a challenge for modules and evaluation board manufacturers to add support for their devices in Yocto as they don't necessarily have a software background. This talk will highlight the steps required, techniques and good practices to create a well integrated machine configuration allowing to build images using the Yocto Linux build system. The Crystalfontz support from meta-fsl-arm-extra will be used to illustrate the talk.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2412">Alexandre Belloni</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2749">
        <start>10:00</start>
        <duration>00:45</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>tizen_iot_security</slug>
        <title>Adding advance Connectivity and Security to an embedded project</title>
        <subtitle>Tizen-meta as a security and Connectivity layers for Yocto</subtitle>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;More and more embedded projects require support for advance connectivity. With it, comes the requirement to enforce a better security as well as private data protection.
Using the layer model of Yocto, we show how we can extract from a complex project such as Tizen, advance connectivity and security and apply it to any embedded project.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The Internet of Things (IoT) is growing fast and opens large opportunities to embedded Linux. Unfortunately traditional embedded Linux has been weak when it comes to security and complex connectivity enabling. Tizen which has been developed as a Linux base OS for connected object (phone, TV, car) is on the other side very well equipped in that area. We will start by explaining what is Tizen architecture and how it provides Security and Connectivity facilities on top of a base Linux. We will then show how Yocto and Tizen-meta can be used to create embedded devices which benefit from several years of work done by the Tizen community. In particular we will review : - the mandatory access control enabling in an embedded device - the enforcement of good behavior by applications - resource access control - connectivity layers - HTML5 App enabling. - multi user mode enabling.&lt;/p&gt;</description>
        <persons>
          <person id="1783">Dominig ar Foll</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3052">
        <start>11:00</start>
        <duration>00:25</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>8bit_compiler</slug>
        <title>Small Device C Compiler</title>
        <subtitle>An optimizing standard C compiler for 8-bit architectures</subtitle>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;SDCC is a standard (ANSI C89, ISO C90, ISO C99, ISO C11) C compiler targeting 8-bit architectures (MCS51, DS80C390, Z80, Z180, Rabbit 2000, Rabbit 3000A, GBZ80, TLCS-90, HC08, S08, STM8, PIC).
It works on many host systems (Linux, Windows, Mac OS, Solaris, NetBSD, FreeBSD, ...).
The talk starts with a view on SDCC from a user perspective - standard compliance, targets.
There is a short interlude on how the SDCC project is set up.
The second part is about some of SDCC's unusual optimizations currently not found in any other compiler, in particular an optimal register allocator and bytewise register allocation.&lt;/p&gt;

&lt;p&gt;The presentation will be held jointly with sdcc developer Maarten Brock.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2698">Philipp Klaus Krause</person>
        </persons>
        <links>
          <link href="http://sdcc.sourceforge.net/">SDCC website</link>
        </links>
      </event>
      <event id="3119">
        <start>11:30</start>
        <duration>00:25</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>mediamanage</slug>
        <title>The connected playlist of everything</title>
        <subtitle>How to get your music in your car</subtitle>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;You want your music in the car with you but its stuck in the "cloud" or on some removable medium. This talk will describe what the process of creating a playlist from open source components and removable media looks like in detail. It will show the gory details of how you connect your USB device to a car's embedded system and how that can be played in a media player in the car.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;You want your music in the car with you but its stuck in the "cloud" or on some removable medium. This talk will describe what the process of creating a playlist from open source components and removable media looks like in detail. It will show the gory details of how you connect your USB device to a car's embedded system and how that can be played in a media player in the car.&lt;/p&gt;</description>
        <persons>
          <person id="2189">Jonatan Palsson</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3103">
        <start>12:00</start>
        <duration>00:25</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>backporting_drivers</slug>
        <title>Backporting Linux mainline drivers</title>
        <subtitle/>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk will give an overview over the Linux backports project and how to use it.
The Linux backports project makes it possible to use a driver from a recent Linux mainline kernel with an older kernel version.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;When you have a vendor board support package which does not use a bleeding edge mainline kernel, like it is the case most times, but you want to use some driver from a bleeding edge Linux kernel you can use backports.
Backports "automatically" generates a tar with many drivers from a specific Linux mainline kernel which can be used with older kernel versions.&lt;/p&gt;

&lt;p&gt;In this talk I will describe how the backports project, with its compatibility layer, the spatches and the normal patches.
For practical usage I will show how to use backports with your own kernel in addition I will give a brief overview on how to add a new driver to backports.&lt;/p&gt;</description>
        <persons>
          <person id="2740">Hauke Mehrtens</person>
        </persons>
        <links>
          <link href="https://backports.wiki.kernel.org/index.php/Main_Page">Project Page</link>
        </links>
      </event>
      <event id="2745">
        <start>12:30</start>
        <duration>00:25</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>embedded_multiuser</slug>
        <title>Multi User support in an embedded secured environment</title>
        <subtitle>Pratical return of experience from Tizen 3 in Automotive</subtitle>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The multi-user support is a new feature of Tizen 3 which aims to enable multiple profile in connected devices while enabling a strict application containment.
This new feature responds to a secured multi-seat context as Tizen IVI (In-Vehicle Infotainment) project.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The multi-user mode is a new feature of Tizen 3 that mainly impacts the application framework, resources management and security framework.
The aim of multi-user Tizen 3 support is to enable multiple profile in connected devices while enabling a strict application containment.&lt;/p&gt;

&lt;p&gt;We will see how this new feature allows a new way to manage applications, services and HW resources in a secured multi-seat context, thus meeting Tizen In-Vehicle Infotainment (IVI) project needs;
We will discover the concepts of a default user before connecting, of separated connected users and privilege user and how users can exchange seats without lost their applications context.&lt;/p&gt;</description>
        <persons>
          <person id="2474">Sabera Djelti</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2681">
        <start>13:00</start>
        <duration>00:25</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>curl_device</slug>
        <title>Internet all the things - using curl in your device</title>
        <subtitle>everyone uses curl - how did this happen and how do you use it?</subtitle>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;libcurl is the world's most used and most popular internet transfer library, already used in every imaginable sort of embedded device out there. How did this happen and how do you use libcurl to transfer data to or from your device?&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Embedded devices are very often network connected these days. Network connected embedded devices often need to transfer data to and from them as clients, using one or more of the popular internet protocols.&lt;/p&gt;

&lt;p&gt;libcurl is the world's most used and most popular internet transfer library, already used in every imaginable sort of embedded device out there. How did this happen and how do you use libcurl to transfer data to or from your device?&lt;/p&gt;

&lt;p&gt;Daniel once founded the project and is still lead developer and maintainer of the curl project, making curl and libcurl. He is also active within IETF and maintain several other open source projects. Daniel is employed by Mozilla.&lt;/p&gt;</description>
        <persons>
          <person id="362">Daniel Stenberg</person>
        </persons>
        <links>
          <link href="http://curl.haxx.se/">The cURL project</link>
        </links>
      </event>
      <event id="2766">
        <start>13:30</start>
        <duration>00:25</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>open_hw_tizen</slug>
        <title>Porting Tizen to open source hardware devices</title>
        <subtitle>DIY open source hardware devices with open source software</subtitle>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This presentation will reveal the process of porting Tizen:Common to open source hardware developer boards with SoC manufactured by Allwinner, Rockchip or Intel such as OLinuXino, Radxa Rock, Minnowboard. The following topics will be covered:
- Building Tizen ARMv7 and x86 images from scratch,
- Adapting the Linux kernel, bootloader and Tizen:Common to popular single board computers,
- Do it yourself (DIY) open-source hardware Tizen tablet or laptop,
- Sharing knowledge and experience of the community.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The presentation will discuss the Tizen project and the efforts for porting it to open source hardware devices with ARM or Intel processors. Guidelines for making your own DIY device to be part of an Internet of Things (IoT) based on Tizen:Common.&lt;/p&gt;

&lt;p&gt;The following show cases will be demonstrated:
- Tizen:Common for A20-OLinuXino-MICRO with Allwinner A20 SoC (Dual-Core ARM Cortex-A7 CPU and Mali400-mp2 GPU)
- Tizen:Common for Radxa Rock with Rockchip RK3188 SoC (Quad-core ARM Cortex-A9 CPU and Mali400-mp4 GPU)
- Tizen:Common for Minnowboard Max (64-bit Intel Atom CPU)&lt;/p&gt;

&lt;p&gt;The presentation will also provide information about U-Boot, Yocto project, the Linux-Sunxi and Linux-Rockchip, Minnowboard communities.&lt;/p&gt;

&lt;p&gt;This presentation should help and encourage more developers to experiment with Tizen and to port it to new devices. A comparison between different single board computers as well as hints how to select hardware devices that fit your needs best will be also shared.&lt;/p&gt;

&lt;p&gt;No previous experience with the Tizen platform is required. Attendees should expect to learn what is open-source hardware, how to build the Linux kernel and Tizen platform images from scratch.&lt;/p&gt;</description>
        <persons>
          <person id="1773">Phil Coval (rzr)</person>
        </persons>
        <links>
          <link href="https://wiki.tizen.org/wiki/ARM">https://wiki.tizen.org/wiki/ARM</link>
          <link href="https://wiki.tizen.org/wiki/Linux">https://wiki.tizen.org/wiki/Linux</link>
          <link href="https://dockr.eurogiciel.fr/blogs/embedded/tds14sh/">https://dockr.eurogiciel.fr/blogs/embedded/tds14sh/</link>
          <link href="https://github.com/leon-anavi/tizen-sunxi">https://github.com/leon-anavi/tizen-sunxi</link>
        </links>
      </event>
      <event id="3066">
        <start>14:00</start>
        <duration>00:45</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>replicant_embedded_freedom</slug>
        <title>Reached milestones and ongoing development on Replicant</title>
        <subtitle/>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Replicant was started as a pragmatic way to achieve software freedom on mobile devices, as a fully free version of Android. Over the years, support was added for a dozen of different mainstream devices. However, most of these are severely flawed when it comes to software freedom and privacy/security. Thus, it was decided to focus the development effort on a few specific devices that perform better than others from those perspectives, instead of trying to catch up with the latest mainstream devices.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;This talk will first cover what was accomplished by the Replicant project over the last few years and what milestones have been reached. This includes an overview of the work that was completed to support various devices, especially when it comes to writing free software replacements for proprietary components. Some of the most challenging examples will be highlighted and put in perspective as milestones for the project. In addition, some of the work on making the system better regarding privacy and security will be mentioned.
Once the improvement of the situation is acknowledged, this talk will show how most of these devices are still fundamentally flawed, hence opening up two possible ways for the future of the project: adding support for more and more new devices and recent Android versions or focusing on a handful of devices that show real potential for being liberated.
Hence, the second part of this presentation will introduce the recent efforts that were started to support devices that can take freedom to the next step. Some of these exciting devices will be presented in details, with a description of the journey to freeing them from the ground up!&lt;/p&gt;</description>
        <persons>
          <person id="1526">Paul Kocialkowski</person>
        </persons>
        <links>
          <link href="http://www.replicant.us/">Replicant website</link>
        </links>
      </event>
      <event id="3213">
        <start>15:00</start>
        <duration>00:45</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>oss_driving</slug>
        <title>Vision for a qualifiable Open-Source Software Platform for Automated Driving</title>
        <subtitle>OSS automated driving</subtitle>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk will describe the motivations and the vision for an Open Source software platform for automated driving and how it might get safety-critical certification.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;It describes the steps taken so far in the autonomous driving direction. It discusses                                                                                                                                                                                          &lt;br/&gt;
the challenges, especially regarding liability and safety-standard                                                                                                                                                                                          &lt;br/&gt;
compliance, and explains why we consider cross-industry                                                                                                                                                                                                    &lt;br/&gt;
collaboration and open-source as mandatory for that effort.&lt;/p&gt;</description>
        <persons>
          <person id="2894">Tillman Ochs</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2803">
        <start>16:00</start>
        <duration>00:45</duration>
        <room>UB2.252A (Lameere)</room>
        <slug>bitbox_game_console</slug>
        <title>the bitbox console</title>
        <subtitle>making of a small, open &amp; DIY ARM game machine</subtitle>
        <track>Embedded</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The bitbox console is a small open hardware &amp;amp; open source game console.
I will present the rationale behind it and the current status of the project, detail the hardware conception and particularly video signal generation from a cortex-m4 chip with no video subsystem. I will then proceed to show the different elements of the software stack : kernel, video engines, the boot loader and, finally, current programs and games, including a Gameboy emulator and a full motion video player.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The bitbox console is a current open hardware / software project.&lt;/p&gt;

&lt;p&gt;Its current abilities are  :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- Based on the STM32F4 chip including 1MB Flash and 192kB SRAM
- 15 bit (32768 colors) color VGA with a resistive DAC.
- Software based signal generation, DMA based. Resolution : Variable, standard resolution of 640x480 @ 60 Hertz
- Stereo 12bit Audio DAC, variable sampling frequency
- microSD driven by 4wire SDIO (6 MB/s transfers tested)
- 1 user button / user LED
- 2 USB 2.0 host 
- 1 microUSB for power (may be used for loading firmware by soldering 2 solder jumpers)
- UEXT extension port 
- SWD port to debug programs on chip
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A description of the console is available on &lt;a href="http://bitboxconsole.blogspot.fr/p/blog-page.html"&gt;its main blog&lt;/a&gt;&lt;/p&gt;</description>
        <persons>
          <person id="2542">Xavier Moulet</person>
        </persons>
        <links>
          <link href="http://bitboxconsole.blogspot.com">main website of the console</link>
          <link href="https://github.com/makapuf/bitbox">sources</link>
        </links>
      </event>
    </room>
    <room name="H.1301 (Cornil)">
      <event id="3339">
        <start>09:00</start>
        <duration>00:50</duration>
        <room>H.1301 (Cornil)</room>
        <slug>newwavephp</slug>
        <title>New Wave PHP</title>
        <subtitle/>
        <track>PHP and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;With new PHP versions being released more often, and projects including Drupal increasing their minimum requirements for PHP versions, it's clear that things are changing rapidly. This session is all about the changes introduced in newer versions of PHP (5.3 onwards), and what that means for PHP projects everywhere. There will be practical examples of the shiny new features, advice on finding hosting and safely upgrading existing projects, and news about the performance improvements you can expect as you move between the versions. The way PHP is evolving is truly exciting so come and join in on the fun!&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1086">Lorna Mitchell</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3341">
        <start>10:00</start>
        <duration>00:50</duration>
        <room>H.1301 (Cornil)</room>
        <slug>phppackagedesign</slug>
        <title>PHP package design</title>
        <subtitle/>
        <track>PHP and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;With many great tools available for sharing packages of PHP code, it is now up to you as a developer to design these packages well. You have to decide what to put in a package, when to split a package and on what other packages you can safely depend.&lt;/p&gt;

&lt;p&gt;You will learn how to make good decisions about your package design and release reliable, highly usable and therefore highly esteemed packages of PHP code.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2858">Matthias Noback</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3342">
        <start>11:00</start>
        <duration>00:50</duration>
        <room>H.1301 (Cornil)</room>
        <slug>profilingphpapplications</slug>
        <title>Profiling PHP applications</title>
        <subtitle/>
        <track>PHP and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;It's nothing new that speed is important for the success of any web application. Only a few hundred milliseconds may lie between a user leaving your site or staying. Unfortunately performance problems are oftentimes hard to fix and even harder to pinpoint. In this talk I will show you how we at ResearchGate measure web application performance, which means not only timing how long the PHP backend took to deliver a page, but also tracking the speed the users actually perceives in the browser. After that you will see how you can track down and analyze any problems you found through measuring with the help of tools like Xdebug, XHProf and the Symfony Debug Toolbar. And if you still need to get faster after optimizing and fixing all these issues, I'll introduce you to some tricks, techniques and patterns to even further decrease load times.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2859">Bastian Hofmann</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3340">
        <start>12:00</start>
        <duration>00:50</duration>
        <room>H.1301 (Cornil)</room>
        <slug>beyondphp</slug>
        <title>Beyond PHP - it's not (just) about the code</title>
        <subtitle/>
        <track>PHP and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Most web developers focus on writing code. But creating web applications is about much more than just writing code. Take a step outside the code cocoon and into the big web ecosphere to find out how small code changes can make a world of difference on servers and network. This talk is an eye-opener for developers who spend over 80% of their time coding, debugging and testing.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="411">Wim Godden</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3343">
        <start>13:00</start>
        <duration>00:50</duration>
        <room>H.1301 (Cornil)</room>
        <slug>thestateofphpunit</slug>
        <title>The State of PHPUnit</title>
        <subtitle/>
        <track>PHP and friends</track>
        <type>devroom</type>
        <language/>
        <abstract></abstract>
        <description>&lt;p&gt;Every eight weeks a new version of PHPUnit is released. In this session we discuss features that were added recently to help with writing and running tests. The development of new features is not limited to the PHPUnit core anymore, though. Thanks to Composer there is a thriving ecosystem of plugins available that can be used with ease to make your testing effort more effective. We will have a look at the most commonly used plugins and close with an outlook on the future of PHPUnit.&lt;/p&gt;</description>
        <persons>
          <person id="1880">Sebastian Bergmann</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3344">
        <start>14:00</start>
        <duration>00:50</duration>
        <room>H.1301 (Cornil)</room>
        <slug>php7</slug>
        <title>PHP 7</title>
        <subtitle/>
        <track>PHP and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;It's been over ten years since PHP5 arrived on the scene and a lot has happened in that time. Namespaces, Closures, Generators, Traits, and performance improvements every step of the way. Next year, the runtime we all know and love will be experiencing another major milestone: PHP 7. Find out what new functionality is around the corner, what's likely to break, how it'll impact your application and your development strategies, and most importantly: What the heck happened to PHP6?!&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="999">Sara Golemon</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3345">
        <start>15:00</start>
        <duration>00:50</duration>
        <room>H.1301 (Cornil)</room>
        <slug>depencymanagementwithcomposerphpreinvented</slug>
        <title>Dependency Management with Composer: PHP Reinvented</title>
        <subtitle/>
        <track>PHP and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Over the last 3 years Composer helped reshape the way PHP programs are written. It was key in transforming a language ecosystem from bad-mouthed procedural mess to an environment in which engineers focus on best practices, refined architecture and code re-use. This talk covers best practices of Composer usage and some tips &amp;amp; tricks even regular Composer users might not be aware of yet!&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2860">Nils Adermann</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3346">
        <start>16:00</start>
        <duration>00:50</duration>
        <room>H.1301 (Cornil)</room>
        <slug>rediscoveringspl</slug>
        <title>(Re)discovering SPL</title>
        <subtitle/>
        <track>PHP and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The Standard PHP Library (SPL) might be one of the most powerful, yet the most unused part of PHP, but you are one of those lucky developers who have discovered it! But now what? The lack of documentation about SPL makes it that a lot users don't really harvest the power that SPL brings. During this presentation I will dive into the numerous iterators, data-structures and interfaces that SPL defines and when &amp;amp; how to implement them in your own projects, but we will talk about the edge-cases as well, as in SPL land things don't always are what they seem..&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="410">Joshua Thijssen</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="H.1302 (Depage)">
      <event id="2875">
        <start>09:00</start>
        <duration>00:55</duration>
        <room>H.1302 (Depage)</room>
        <slug>supporting_accessibility_in_your_distribution</slug>
        <title>Supporting accessibility in your distribution</title>
        <subtitle/>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This will discuss the few important details that distribution hackers should know to make sure that their distribution is accessible to everybody.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Freedom #0 of free software is to be able to execute the software. But that is useless if one is unable to actually use the software. Distributions should thus take particular care of their accessibility, which means shipping accessibility tools of course, but also making sure that some accessible software alternatives are packaged, that accessibility can easily be enabled on an installed system, and even that the distribution installer itself is accessible!&lt;/p&gt;

&lt;p&gt;Thanks to the experience we have had in Debian in the past years, I will guide the audience through the few important details to know for distribution hackers in order to make sure that their distribution is accessible.&lt;/p&gt;</description>
        <persons>
          <person id="1133">Samuel Thibault</person>
        </persons>
        <links>
          <link href="http://brl.thefreecat.org/">Accessibility projects</link>
          <link href="http://wiki.debian.org/accessibility">Debian accessibility user wiki</link>
          <link href="http://wiki.debian.org/accessibility-devel">Debian accessibility developer wiki</link>
          <link href="http://wiki.debian.org/DebianInstaller/Accessibility">Debian installer accessibility wiki</link>
        </links>
      </event>
      <event id="3261">
        <start>10:00</start>
        <duration>00:30</duration>
        <room>H.1302 (Depage)</room>
        <slug>scl_for_bleeding_edge_stacks_on_enterprise</slug>
        <title>SCL for bleeding edge stacks on enterprise</title>
        <subtitle>Find out how to deliver bleeding edge, flexible development stacks on stable enterprise platform using Software Collections</subtitle>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Learn how to provide bleeding edge features on stable platform using Software Collections that allow you to enjoy different versions of a package or whole application stack on one machine, separately for every process and without influencing the rest of the system. The Software Collections technology is more open than ever before and developed in cooperation with CentOS now. Learn how to use it in practice, what projects use them already and what are the recent changes in the concept.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;For last two years Red Hat delivers two major products using Software Collection. Goal is to provide development environments, newer packages like dynamic languages, modules for them, databases to satisfy customer demand on more up to date contant on stable enterprise platform.
The lecture will introduce concept of Software Collections, while listeners will learn how to build and use application stack delivered using this technology. Practical examples will demonstrate this unusual combination of stable enterprise platform with latest versions of frameworks like latest NodeJS, Django or Ruby on Rails.
Also, tips how to get involved or extend existing collections will be given.
The lecture is intended for developers that need to develop applications for enterprise Linux platform but are not satisfied with old versions that are usually delivered on such platforms.
Also admins or devops engineers will benefit from being able to install any software without influence the rest of the system.&lt;/p&gt;</description>
        <persons>
          <person id="2818">Honza Horak</person>
        </persons>
        <links>
          <link href="http://softwarecollections.org/">Main site of Software Collections</link>
          <link href="http://developerblog.redhat.com/tag/software-collections/">Blog posts about Software Collections</link>
        </links>
      </event>
      <event id="2955">
        <start>10:35</start>
        <duration>00:50</duration>
        <room>H.1302 (Depage)</room>
        <slug>the_tumbleweed_factory</slug>
        <title>The Tumbleweed Factory</title>
        <subtitle>from an unstable development branch to a fully rolling binary distro </subtitle>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;openSUSE Factory is the head development branch for the openSUSE
distribution releases. As such the explosive mixture of changes and
new versions throughout the whole stack from kernel to the desktops
made openSUSE Factory a challenging distribution to use even for
hard core distribution hackers. To make Factory usable for a wider
audience of distribution developers it had to be made more stable
while retaining the short turnaround times needed for a bleeding
edge distribution. openSUSE therefore introduced a number of automated
and semi-automated tools for review and QA into the development
workflow to reach that goal. The result is now called openSUSE
Tumbleweed, a fully rolling binary distribution based on openSUSE
Factory. This talk explains the development process and the tools
used to turn openSUSE Factory into Tumbleweed.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Target audience are distribution integrators in general. All of them
have problems like "does this new dracut submission break the
installer or render the system unbootable?". With the process used
by openSUSE many such questions can be answered by the machine,
automatically. The process outlined in this talk is not only useful
for rolling distributions like Tumbleweed but also for stable
releases. It helped significantly to increase the quality resp avoid
regressions between beta and RC versions during the release process.&lt;/p&gt;</description>
        <persons>
          <person id="2978">Stephan Kulow</person>
        </persons>
        <links>
          <link href="https://openqa.opensuse.org/tests/">openQA</link>
          <link href="https://build.opensuse.org/project/dashboard/openSUSE:Factory">openSUSE Factory dashboard</link>
        </links>
      </event>
      <event id="3299">
        <start>11:30</start>
        <duration>00:55</duration>
        <room>H.1302 (Depage)</room>
        <slug>whats_new_in_systemd,_2015_edition</slug>
        <title>What's new in systemd, 2015 Edition</title>
        <subtitle>What's new in the systemd world, and what's coming next</subtitle>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;systemd is now a core component of most major distributions. In this talk I want to give an overview over everything new in the systemd project over the last year, and what to expect over the next year.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="945">Lennart Poettering</person>
        </persons>
        <links>
          <link href="http://freedesktop.org/wiki/Software/systemd/">systemd homepage</link>
        </links>
      </event>
      <event id="2688">
        <start>12:30</start>
        <duration>00:50</duration>
        <room>H.1302 (Depage)</room>
        <slug>retooling_fedora</slug>
        <title>Retooling Fedora</title>
        <subtitle>A Retrospective on Fedora 21</subtitle>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Fedora 21 marked the first phase of the Fedora.next Initiative, an umbrella concept for a reimagining of how Fedora will operate in its second decade. This talk will focus on the switch to a Product-based model, the reasons behind it and the challenges (both technical and social) that we faced in shipping Fedora 21.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The session will be broken into approximately 25-30 minutes of lecture lightly covering a variety of topics including release-engineering, new feature development and socialization of ideas.&lt;/p&gt;

&lt;p&gt;After the talk, the session will be opened up to a Q&amp;amp;A session with the audience.&lt;/p&gt;</description>
        <persons>
          <person id="1549">Stephen Gallagher</person>
          <person id="2931">Matthew Miller</person>
        </persons>
        <links>
          <link href="http://fedoraproject.org/get-fedora">Fedora Download Page</link>
        </links>
      </event>
      <event id="3290">
        <start>13:25</start>
        <duration>00:30</duration>
        <room>H.1302 (Depage)</room>
        <slug>openstack_on_fedora_&amp;_centos</slug>
        <title>Openstack on Fedora &amp; CentOS</title>
        <subtitle/>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk will describe the state of OpenStack packaging on Fedora &amp;amp; CentOS through the project RDO.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Openstack is a big player in the FOSS IaaS field, yet, it's still a challenge to package it and integrate it into major GNU/Linux Distros.
Here, we'll see how it is packaged and maintained in Fedora/CentOS and what are the plans in the near future.&lt;/p&gt;</description>
        <persons>
          <person id="2810">Haïkel Guémar</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3239">
        <start>14:00</start>
        <duration>00:45</duration>
        <room>H.1302 (Depage)</room>
        <slug>can_distros_make_the_link?_lets_package_the_customizable,_free_software_web_of_the_future!_</slug>
        <title>Can Distros Make the Link? Let's Package the Customizable, Free Software Web of the Future! </title>
        <subtitle/>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Without buy-in from non-technical users, decentralized web services are destined to fail. It's time for the folks who are building the distros of the future and the folks who are building the web of the future to see what we can offer each other. Come hear what we've done so far at MediaGoblin, where we think the tricky bits will be and then join us in building the computing, sharing, connecting environment of the future!&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Let's be honest. Most of the people who currently run a node of a decentralized web service are pretty technical. The rest of the world uses massive centralized services. These large centralized service providers are prone to easy surveillance, hard for users to customize and rife with arbitrary censorship. But people want to connect and share, so if we aren't building free web services for everyone, then we may as well not be building them at all.&lt;/p&gt;

&lt;p&gt;GNU/Linux distributions could well be the missing link. If users could install the software to host their own node of MediaGoblin, Diaspora or Pump.io as easily as they choose an application like VLC or Audacity then we might start to see the multi-node network that federated services need to succeed. Of course, there are a few hurdles we'll have to overcome before we can expect easily deployable federation in every distro. Some of the great new innovations from the world of devops (prepare for all the failure) and the magic of containerization (assemble once, deploy everywhere) could help us bridge the gap.&lt;/p&gt;

&lt;p&gt;It's time for the folks who are building the distros of the future and the folks who are building the web of the future to see what we can offer each other. The folks at MediaGoblin have been thinking about this for quite a while. Come hear what we've done so far, where we think the tricky bits will be and then join us in building the computing, sharing, connecting environment of the future!&lt;/p&gt;</description>
        <persons>
          <person id="698">Deb Nicholson</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3234">
        <start>14:50</start>
        <duration>00:45</duration>
        <room>H.1302 (Depage)</room>
        <slug>centos_community_infra_revealed</slug>
        <title>CentOS (community) Infra revealed</title>
        <subtitle>aka the joy of running on donated machines</subtitle>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;CentOS.org Infra explained&lt;/p&gt;</abstract>
        <description>&lt;p&gt;CentOS Project exists now for more than 10 years now, and some people are wondering how the CentOS.org Infra is managed. We'll explain all the tools we use to maintain that infra, but also the constraints we have due to the fact that our infra is spread around the world on community/donated machines, without SLA and disappearing without notification. We'd like to also not only present how we run the infra, from a community perspective, but a real discussion with other distributions (round-table discussion ? ) about those common issues, and how to solve those&lt;/p&gt;</description>
        <persons>
          <person id="2801">Fabian Arrotin</person>
        </persons>
        <links>
          <link href="http://www.centos.org">CentOS website</link>
        </links>
      </event>
      <event id="3033">
        <start>15:40</start>
        <duration>00:30</duration>
        <room>H.1302 (Depage)</room>
        <slug>live_atomic_updates</slug>
        <title>Live atomic updates</title>
        <subtitle>Installing new software without the need for packages or a reboot</subtitle>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;If you install packages on a running system you need to be careful to not break running software, or leave the filesystem in an invalid state. This is why Android, Baserock, CoreOS and Project atomic do atomic updates for system software. Currently this requires a reboot, so it's an offline atomic update, but if we can solve online atomic updates, there's no need for packages any more.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;I work for Codethink on a project called Baserock, the goal of which is to solve problems in embedded systems development.&lt;/p&gt;

&lt;p&gt;With package-based upgrades you need to be careful to not remove anything that a running program is using, and you need to avoid moving the file-system through invalid states.
Distributions generally get this right, but it's a lot of work, and the complicated dance required to make this work, also makes it slow.&lt;/p&gt;

&lt;p&gt;We decided to do away with packages to simplify things, so we do image-based updates by applying a binary delta to a snapshot and atomically flip to the new version.
Currently the way to do this is reboot or kexec, but requires a service outage, so for Baserock I've been looking at a better way to do this.&lt;/p&gt;

&lt;p&gt;In this talk I'm going to explain the various alternative approaches, why I settled on my current approach, the limitations of this approach, and future work to make this more reliable.&lt;/p&gt;</description>
        <persons>
          <person id="2717">Richard Maw</person>
        </persons>
        <links>
          <link href="http://wiki.baserock.org/">The Baserock Project</link>
        </links>
      </event>
      <event id="3014">
        <start>16:15</start>
        <duration>00:45</duration>
        <room>H.1302 (Depage)</room>
        <slug>the_centos_storage_sig_and_glusterfs</slug>
        <title>The CentOS Storage SIG and GlusterFS</title>
        <subtitle>Challenges, solutions and how GlusterFS is fitting in Storage SIG</subtitle>
        <track>Distributions</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;GlusterFS is a scale out storage solution which has wide range of uses cases.&lt;/p&gt;

&lt;p&gt;GlusterFS is one of the founding members of Storage SIG. We have been able to successfully bootstrap GlusterFS in the Storage SIG. Relevant RPMs have been build for the SIG using the new CentOS build system. During the last couple of months of bootstrapping GlusterFS in the storage SIG we have faced some technical challenges which will be applicable to other SIGs (current and Future). During this talk we will share our experiences and discuss the technical challenges GlusterFS faced, how we solved it and the thought process around it. In this talk we will also talk about how Storage SIG is trying to give best upstream experience to community/users.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Open source storage projects (e.g. Ceph and GlusterFS) were the first to jump on the SIG bandwagon. For GlusterFS it is a perfect match as most of the users in Gluster community preferred CentOS over RHEL to deploy GlusterFS. Our goal was to create a seamless experience for community to consume GlusterFS and related technologies. GlusterFS is also deeply integrated with other technologies too e.g. Samba,NFS, nfs-ganesha, OpenStack, QEMU-KVM, Hadoop, OpenStack Swift, and OVirt. One of the goals of the Storage SIG to ensure users can consume GlusterFS and related technologies easily through storage SIGs and other SIGs( e.g virtualization SIG ) etc.&lt;/p&gt;

&lt;p&gt;We have been working on GlusterFS in the storage SIG for some time now. In the presentation we will share our experiences, challenges, and some insights to SIG.&lt;/p&gt;

&lt;p&gt;The talk will be beneficial to wide variety of people e.g. System admins who want to deploy GlusterFS, and developers who are working with technologies which consume GlusterFS. It would also give fair idea what kind of challenges SIGs face, and to those who want to know more about storage SIG&lt;/p&gt;</description>
        <persons>
          <person id="2389">Kaleb Keithley</person>
          <person id="2702">Lalatendu Mohanty</person>
        </persons>
        <links>
          <link href="http://wiki.centos.org/SpecialInterestGroup/Storage">Storage SIG</link>
          <link href="http://wiki.centos.org/SpecialInterestGroup/Storage/Proposal">Storage SIG Proposal</link>
          <link href="http://www.centos.org/variants/">CentOS Variants</link>
        </links>
      </event>
    </room>
    <room name="H.1308 (Rolin)">
      <event id="3390">
        <start>09:00</start>
        <duration>00:05</duration>
        <room>H.1308 (Rolin)</room>
        <slug>opening_desktops_devroom_2015</slug>
        <title>Opening of the Desktops DevRoom 2015</title>
        <subtitle/>
        <track>Desktops</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Welcome to the Desktops DevRoom at FOSDEM 2015&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="157">Christophe Fergeau</person>
          <person id="666">Pau Garcia i Quiles</person>
          <person id="668">Philippe Caseiro</person>
          <person id="2019">Jerome Leclanche</person>
          <person id="2078">Didier Roche</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2674">
        <start>09:05</start>
        <duration>00:30</duration>
        <room>H.1308 (Rolin)</room>
        <slug>wapt_apt_get_for_windows</slug>
        <title>WAPT, apt-get for Windows</title>
        <subtitle>A package manager for Windows</subtitle>
        <track>Desktops</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;With WAPT, IT teams can manage simply and effectively the lifecycle of an installed base of Windows applications. WAPT can (1) install, (2) update, (3) configure, (4) uninstall and (5) inventory your Windows based applications, be they business, office, utilities or even system drivers.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2398">Vincent Cardon</person>
        </persons>
        <links>
          <link href="http://dev.tranquil.it/wiki/WAPT_-_apt-get_pour_Windows">Main community website (in French as of 2014/10)</link>
        </links>
      </event>
      <event id="2892">
        <start>09:35</start>
        <duration>00:30</duration>
        <room>H.1308 (Rolin)</room>
        <slug>lessons_learned_with_time_based_releases_for_efl</slug>
        <title>Lessons Learned with Time Based Releases for EFL</title>
        <subtitle/>
        <track>Desktops</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The Enlightenment window manager and its libraries have for a long time been seen as one of the
pieces of software that might never be released. With E17 taking 12 years for its first release
there was some truth in this story. Since we have released E18 and E19 and adopted a time based
release schedule for our library releases. Enlightenment still runs on its own schedule.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The Enlightenment window manager and its libraries have for a long time been seen as one of the
pieces of software that might never be released. With E17 taking 12 years for its first release
there was some truth in this story. Since we have released E18 and E19 and adopted a time based
release schedule for our library releases. Enlightenment still runs on its own schedule.&lt;/p&gt;

&lt;p&gt;The EFL gets a new release roughly every 3 month. Over a year into my role as release manager of
EFL and 4 time based releases later it seems to be a good time to look back and let others know
about the lessons I learned to get this working.&lt;/p&gt;

&lt;p&gt;The talk will touch topics like setting a release schedule within the community, keep track of the
status of git master while progressing, motivate people to invest time in stabilization and tools
and automation to keep time effort small. It will touch technical as well social topics involved
with release management.&lt;/p&gt;</description>
        <persons>
          <person id="1814">Stefan Schmidt</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3286">
        <start>10:05</start>
        <duration>00:30</duration>
        <room>H.1308 (Rolin)</room>
        <slug>ubuntu_on_phones_and_beyond</slug>
        <title>Ubuntu on phones and beyond</title>
        <subtitle>How we built Ubuntu for the phone and plan to build out to all the other devices out there</subtitle>
        <track>Desktops</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;I would like to talk about the next generation of Ubuntu, currently working on phones and, mostly, on tablets.&lt;/p&gt;

&lt;p&gt;We're building it out for traditional windowed use cases now, ultimately enabling convergence, i.e. using one device to drive all your computing (mobile or otherwise) needs. I'll talk about how we want to get there&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2829">Michał Sawicz</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3225">
        <start>10:40</start>
        <duration>00:30</duration>
        <room>H.1308 (Rolin)</room>
        <slug>gcompris_goes_qt_quick_with_the_help_of_kde</slug>
        <title>GCompris goes Qt Quick with the help of KDE</title>
        <subtitle>GCompris is an educational software for children 2 to 10</subtitle>
        <track>Desktops</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;GCompris is a high quality educational software suite comprising of numerous activities for children aged 2 to 10. It was created in 2000 using the GTK+ graphical toolkit. It is available on different platforms, GNU/Linux, and the proprietary platforms MacOSX and Windows.&lt;/p&gt;

&lt;p&gt;Willing to address the large number of tablet users and to enhance the user experience the choice was made in January 2014 to rewrite GCompris in Qt Quick.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The presentation will address the following topic:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Project goal and history&lt;/li&gt;
&lt;li&gt;Community and commercial. Starting in 2003 a Windows version was created and is distributed under a commercial model while being still Free Software. We will see how and why we decided to do so&lt;/li&gt;
&lt;li&gt;Why we selected Qt Quick. This development toolkit is based on Qt and let the developer create dynamic user interface that can run on desktop and mobile platforms&lt;/li&gt;
&lt;li&gt;Why we became a KDE project. GCompris has always been a community project, leaving the GTK+ toolkit it does not make sense to develop the new version under the Gnome umbrella&lt;/li&gt;
&lt;li&gt;State of the Qt Quick port&lt;/li&gt;
&lt;li&gt;A short Qt Quick presentation&lt;/li&gt;
&lt;li&gt;A live coding session where showing how easy it is to create a new educational activity for GCompris&lt;/li&gt;
&lt;/ul&gt;
</description>
        <persons>
          <person id="2261">Bruno Coudoin</person>
        </persons>
        <links>
          <link href="http://gcompris.net">GCompris main site</link>
        </links>
      </event>
      <event id="2630">
        <start>11:15</start>
        <duration>00:45</duration>
        <room>H.1308 (Rolin)</room>
        <slug>mobile_web</slug>
        <title>Mobile == Web</title>
        <subtitle>the best mobile "apps" are on the web</subtitle>
        <track>Desktops</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The next billion people to come online will do so through their phone. If they don't have access to awesome mobile web content, their experience will be controlled by the app ecosystem of the phone they purchase.&lt;/p&gt;

&lt;p&gt;Help them - and all your friends - by making sure that all the websites and apps you create are great mobile experiences. Increase your reach to mobile and make sure that everyone has access to your content by creating a discoverable, responsive, awesome mobile experience on the web.&lt;/p&gt;

&lt;p&gt;Why?
1) All mobile users have access to the web. Not all mobile users will download an app.
2) Web pages are more accessible through search.
3) All users, regardless of their platform, have access to mobile websites.
4) Nobody is censoring content, nor taking part of the profits, on the web.
5) Everyone can create mobile web content without needing third party approval.
6) Your mobile website can easily become an app for mobile platforms.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The next billion people to come online will do so through their phone. If they don't have access to awesome mobile web content, their experience will be controlled by the app ecosystem of the phone they purchase.&lt;/p&gt;

&lt;p&gt;Help them - and all your friends - by making sure that all the websites and apps you create are great mobile experiences.  Increase your reach to mobile and make sure that everyone has access to your content by creating a discoverable, responsive, awesome mobile experience on the web.&lt;/p&gt;

&lt;p&gt;Why?
1) All mobile users have access to the web. Not all mobile users will download an app, especially for things they do once or places they visit infrequently.
2) Web pages are more accessible through search.
3) All users, regardless of their platform, have access to mobile websites.
4) Nobody is censoring content, nor taking part of the profits, on the web.
5) Everyone can create mobile web content without needing third party approval.
6) Your mobile website can easily become an app for mobile platforms.&lt;/p&gt;</description>
        <persons>
          <person id="2355">Stormy Peters</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2582">
        <start>12:05</start>
        <duration>00:45</duration>
        <room>H.1308 (Rolin)</room>
        <slug>wikimedia_adopts_phabricator</slug>
        <title>Wikimedia adopts Phabricator, deprecates seven infrastructure tools</title>
        <subtitle>First hand experiences from a big free software project on a complex migration</subtitle>
        <track>Desktops</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Phabricator is an open source software development platform used for project management, bug reporting, and code review in an integrated fashion. Wikimedia has about 500 regular contributors developing MediaWiki plus hundreds of extensions and related tools. We are deploying https://phabricator.wikimedia.org to replace Bugzilla, RT, Trello, Mingle, Gerrit, gitblit, and Jenkins. This is the biggest and most complex Phabricator migration we are aware of, and we want to share our first-hand experiences with other free software projects.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Why such a big change? All the tools we are/were using kind of work/ed. However, we felt that the cocktail of tools was slowing us down, becoming also an obstacle for new contributors. In more detail:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The volume and complexity of our software projects keeps increasing; MediaWiki and Bugzilla fall short for project management.&lt;/li&gt;
&lt;li&gt;Wikimedia Foundation teams were increasingly using Mingle and Trello, 3rd party commercial services that are alien to the Wikimedia community and principles. This was creating a divide. Wikimedia Germany was trying Scrumbugz, a one-man OSS project barely maintained.&lt;/li&gt;
&lt;li&gt;Overlap, duplication, and actions falling between the cracks increased.&lt;/li&gt;
&lt;li&gt;To mitigate this problem, we created more tools to synchronize information between services (like "Bingle", "Bugello" or Gerrit notifications in Bugzilla). They needed to be maintained (i.e. when one service is upgraded and its API interface has changed).&lt;/li&gt;
&lt;li&gt;Contributing to Bugzilla (Perl) and Gerrit (Java) is complex for us (PHP, and Phabricator is written in PHP), while there is no way to contribute code to proprietary Mingle and Trello.&lt;/li&gt;
&lt;li&gt;The current setup brings overhead and annoyance to key developers:
&lt;strong&gt; Senior developers having to use heavily Gerrit, Bugzilla, and Mingle/Trello.
&lt;/strong&gt; New contributors, most of them arriving with GitHub-like expectations.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;As we write these lines, this is an ongoing work. Learn more about the Wikimedia Phabricator timeline and other project details at https://www.mediawiki.org/wiki/Phabricator&lt;/p&gt;</description>
        <persons>
          <person id="2328">Quim Gil</person>
          <person id="2902">Andre Klapper</person>
        </persons>
        <links>
          <link href="https://www.mediawiki.org/wiki/Phabricator">Wikimedia Phabricator project page</link>
          <link href="https://phabricator.wikimedia.org/">Wikimedia Phabricator site</link>
          <link href="http://phabricator.org/">phabricator.org</link>
        </links>
      </event>
      <event id="2995">
        <start>12:50</start>
        <duration>00:30</duration>
        <room>H.1308 (Rolin)</room>
        <slug>application_sandboxing_with_systemd</slug>
        <title>Application Sandboxing with systemd</title>
        <subtitle>Containers and wayland and kdbus, oh my!</subtitle>
        <track>Desktops</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;I will talk about the experimental work I've been doing to securely sandbox graphical applications in a Wayland based desktop. I will also talk about the next steps and how this work relates to the GNOME Safety project and systemd.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2689">Rob Taylor</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3064">
        <start>13:20</start>
        <duration>00:30</duration>
        <room>H.1308 (Rolin)</room>
        <slug>qtquick_in_complex_applications</slug>
        <title>QtQuick in Complex Applications</title>
        <subtitle/>
        <track>Desktops</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;It is well known that QtQuick is cool, trendy, and empowers you to make your applications looking awesome. Various tutorials and talks discuss that and how to do this, but seldom reach the point where they talk about QtQuick usage for more complex use cases than a simple game/a small example text editor. In this talk, I will discuss how the mechanisms in "hybrid" C++ (logic, models, data) and QtQuick (the fancy looking stuff) applications work and what are best practices there. This includes a very brief recap of QtQuick and QML, but mainly focuses on how to access and communicate data from the QtQuick engine that is provided by the C++ models, and the other way around. The talk will conclude with a walk through different pitfalls and best practices when working with QtQuick UIs of significant size.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2021">Andreas Cord-Landwehr</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3273">
        <start>13:50</start>
        <duration>00:30</duration>
        <room>H.1308 (Rolin)</room>
        <slug>desktop_software_on_the_web</slug>
        <title>Desktop Software on the Web</title>
        <subtitle>Bringing FOSS Desktop Software to the Browser</subtitle>
        <track>Desktops</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Until recently, Free and Open Source Software designed for the Desktop, particularly development tools, has been unavailable on the Web. Now, using a technology called Native Client, some 240+ packages including editors, compilers, interpreters, and utilities can be made available in the Chrome web browser, online or offline, without sacrificing portability or security. Come learn how the the Desktop of the future will meld the security and flexibility of the Web with the performance and rich application set of today’s Desktop.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Native Client (NaCl), is an open-source technology that allows native machine code to run securely sandboxed in the browser, with privileges mirroring Javascript. Two layers of sandboxing, a static verification inner sandbox combined with Chrome’s outer process sandbox, ensure users can safely run applications they may not trust. Modified GCC and LLVM based toolchains allow applications to target NaCl using the PPAPI I/O interface.&lt;/p&gt;

&lt;p&gt;This talk will explore key challenges including: packaging, testing, emulating process management using a JavaScript “microkernel”, and building POSIX support—pthreads, files, processes, sockets, terminal I/O—on top of Web-centric APIs.&lt;/p&gt;

&lt;p&gt;See a full-featured development environment comprised of FOSS applications including editors (Vim, Emacs, Nano), scripting languages (Python, Lua, Ruby, Tcl/Tk, Bash), utilities (tar, zip, curl, grep), version control (git, svn), compilers (GCC, Clang/LLVM), GDB, GNUMake, window managers, and an X11 server, all running in concert, sandboxed in the browser. Discover how the Desktop can now become one with the Web and help put Free and Open Source Software in the hands of developers and users everywhere.&lt;/p&gt;</description>
        <persons>
          <person id="2253">Brad Nelson</person>
        </persons>
        <links>
          <link href="http://gonacl.com/fire">NaCl Dev Environment Codelab</link>
          <link href="http://gonacl.com/">NaCl Overview</link>
        </links>
      </event>
      <event id="3251">
        <start>14:25</start>
        <duration>00:30</duration>
        <room>H.1308 (Rolin)</room>
        <slug>application_gui_design</slug>
        <title>Application GUI Design - Notes From a Toolkit Developer</title>
        <subtitle/>
        <track>Desktops</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Designing an application with a good user interface and user experience is hard. Many people get it wrong which results in a degraded user experience, satisfaction and retention.
In this talk, Tom will demonstrate some good design patterns, review the current design landscape in the desktop and touch friendly worlds and will give his notes and ideas as a developer of the EFL graphical toolkit and applications.
Tom will also offer some easy tips for making your applications better.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="875">Tom Hacohen</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2823">
        <start>14:55</start>
        <duration>00:30</duration>
        <room>H.1308 (Rolin)</room>
        <slug>gnome_creating_ripples_in_the_linux_ecosystem</slug>
        <title>GNOME - creating ripples in the Linux eco-system</title>
        <subtitle/>
        <track>Desktops</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Sri Ramkrishna makes the argument that GNOME's off the beaten style of development are ripples that create opportunities for interesting problems for the eco-system to solve.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;GNOME tends to be a controversial project, their design and technical decisions create ripples that affect the Linux eco-system.  Whether good or for ill, GNOME's decisions creates opportunities to solve interesting problems by pushing a 'just works'.  The talk will involve a retrospective of GNOME's initial path and how they changed the Linux eco-system today and contrast today's design and how things will go further with integration with systemd.&lt;/p&gt;</description>
        <persons>
          <person id="2560">Sri Ramkrishna</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3252">
        <start>15:30</start>
        <duration>00:30</duration>
        <room>H.1308 (Rolin)</room>
        <slug>reinventing_the_enlightenment_object_system</slug>
        <title>Reinventing the Enlightenment Object System</title>
        <subtitle/>
        <track>Desktops</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The Enlightenment project started over 15 years ago, and while it has evolved a lot over the years, its object system has not; this is quite surprising given that almost everything in Enlightenment is represented by objects. Tom, later joined by other Enlightenment developers, has taken upon himself to redesign it, and called the new system Eo. In this talk Tom will describe the main goals they had for Eo, what (and how) they have achieved, how it was received by fellow developers and how it impacted the Enlightenment project as a whole. Tom will also briefly review other C object systems, some of Eo's unique features, and several related projects that were either created to support Eo, had undergone major improvements enabled by it, or owe they existence to Eo.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="875">Tom Hacohen</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2587">
        <start>16:00</start>
        <duration>00:30</duration>
        <room>H.1308 (Rolin)</room>
        <slug>the_haxe_language_as_a_transmedia_toolkit</slug>
        <title>The Haxe language as a transmedia toolkit</title>
        <subtitle>One codebase, one app, many runtimes, millions of devices.</subtitle>
        <track>Desktops</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;We will present the Haxe Language (haxe.org), what is is, and what it is not. We will explain why Motion Twin (motion-twin.com) originally had the need to use Haxe, and why it still does.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;title : The Haxe language as a transmedia toolkit
sub : One codebase, one App, many runtimes, millions of devices.&lt;/p&gt;

&lt;p&gt;We will present the Haxe Language (haxe.org), what is is, and what it is not. We will explain why Motion Twin (motion-twin.com) originally had the need to use Haxe, and why it still does.&lt;/p&gt;

&lt;p&gt;part 1 : Developing games using open source technology
- Who are Motion Twin and why do they have 15 million users?
- A Motion Twin showreel of games created using open source tools
- An overview of the open source tools available for writing games&lt;/p&gt;

&lt;p&gt;part 2 : What is Haxe ?
- Why did we need Haxe, a comparison with alternative languages (compilers are too slow, or languages are too broken)
- A one man (army) Swiss army knife
- People using Haxe to fuel their creativity
- The Haxe Foundation mission&lt;/p&gt;

&lt;p&gt;part 3 : A case study : Dead Cells, a zombie survival game (dead-cells.com)
- Server technologies : going back from the servers to the users with the best tool available
- Client technologies : driving GPU, FPU, resolving screen resizing with simple yet efficient methods.
- Paying hommage : Breakdown of all technologies involved
- A Transmedia experience : start at work on a desktop, continue on the metro with a phone, and end at home on a micro console&lt;/p&gt;

&lt;p&gt;part 4 : Questions&lt;/p&gt;

&lt;p&gt;ps : The game used as case study might change&lt;/p&gt;</description>
        <persons>
          <person id="2244">David "Blackmagic" Elahee</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2782">
        <start>16:30</start>
        <duration>00:30</duration>
        <room>H.1308 (Rolin)</room>
        <slug>microraptor_gui</slug>
        <title>MicroRaptor Gui</title>
        <subtitle>An immediate mode UI framework on top of cairo</subtitle>
        <track>Desktops</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Traditional UI toolkits like motif, GTK, qt, Clutter, QML, HTML DOM and more are retained. MicroRaptor Gui is immediate mode - like cairo itself and augments the cairo drawing API with keyboard and pointer event handling, as well as styling and positioning using CSS. The API of MicroRaptor Gui makes it easy to implement your own scene-graph, or directly
render from in memory data structures or using iteration APIs.&lt;/p&gt;

&lt;p&gt;MicroRaptor Gui has backends for /dev/fb, SDL, embedding in GTK+ applications, running as a composited client of another MicroRaptor Gui process and for some uses even vt100 terminal emulators.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2526">Øyvind Kolås</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="H.1309 (Van Rijn)">
      <event id="3000">
        <start>10:00</start>
        <duration>00:45</duration>
        <room>H.1309 (Van Rijn)</room>
        <slug>openstack_infra_tools_to_borrow</slug>
        <title>OpenStack Infrastructure tools you will want to borrow</title>
        <subtitle/>
        <track>Testing and automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;A presentation of original open source tools created for (and used by) the OpenStack project infrastructure.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Last year at FOSDEM I gave an overview of the OpenStack project infrastructure, a Puppet-driven collection of free software tools which ensure continuous integration at the crazy pace of the OpenStack projects.&lt;/p&gt;

&lt;p&gt;While a number of these tools are well-known (Puppet, Jenkins, Gerrit), we also created our own free software tooling to support our unique needs, and those are potentially useful for any software project development infrastructure.&lt;/p&gt;

&lt;p&gt;Come one, come all. Step right up and prepare to be amazed! Learn more about Zuul, our fearless pipeline-oriented gatekeeper. Be surprised by jenkins-job-builder, our YAML-driven err... Jenkins job builder. Make Gerrit saner with git-review, JeepyB or gertty. And don't leave without discovering StoryBoard, our amazing future task tracker.&lt;/p&gt;</description>
        <persons>
          <person id="427">Thierry Carrez</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2949">
        <start>10:55</start>
        <duration>00:45</duration>
        <room>H.1309 (Van Rijn)</room>
        <slug>mongooseim_testing_massively_concurrent_system</slug>
        <title>MongooseIM: Testing Massively Concurrent System</title>
        <subtitle/>
        <track>Testing and automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Distribution to multiple virtual machines in the cloud or servers is the way to scale horizontally when there is no more room or resources to grow vertically. In this talk we will discuss how to load test an XMPP server and distribute load generation using Erlang/OTP as a platform. Experiences from testing production ready MongooseIM systems will be presented.&lt;/p&gt;

&lt;p&gt;Talk objectives: show from the ground up how to plan and execute load tests of a distributed service and distribute load generation.&lt;/p&gt;

&lt;p&gt;Talk audience: DevOps people wanting to load test their XMPP or other message oriented services. People evaluating XMPP solutions in terms of capacity and scalability.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2652">Michal Slaski</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3082">
        <start>11:50</start>
        <duration>00:45</duration>
        <room>H.1309 (Van Rijn)</room>
        <slug>ci_as_infrastructure</slug>
        <title>CI as an infrastructure: components, patterns and problems</title>
        <subtitle/>
        <track>Testing and automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Usually we talk about CI as a process. We can start from very simple "checkout, build, test and deploy" idea and we might come to some complex scheme of interconnected tasks or jobs with different pipelines fulfilling certain requirements, but we mostly remain within the process scope dealing with problems like what to automate, how to automate and in which order to run those automated tasks.&lt;/p&gt;

&lt;p&gt;However in this talk we are going to step back a bit and look at CI as an infrastructure, i.e. the system of services, which is constantly evolving to catch up with changes happening in the base project. We will go through number of examples trying to figure out basic principles and common patterns of CI infrastructure, and discuss the ways to solve common problems arising from them.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;To organize the discussion we will structure it in groups:&lt;/p&gt;

&lt;p&gt;Services group includes topics like:
- setup and update system,
- message bus and status reports,
- artifacts storage and distribution.&lt;/p&gt;

&lt;p&gt;In Master group we put questions related to build system configuration, such as:
- difference between interactive and non-interactive build systems,
- proper use of templates for jobs configuration,
- version control.&lt;/p&gt;

&lt;p&gt;There are also Workflow questions like:
- should people get access to debug failures in place and how to organize it?
- how to test test?&lt;/p&gt;

&lt;p&gt;As an extension for setup and update system topic we'll go through questions which deal with test environment, such as:
- How to add new worker?
- How to check it?
- Will Docker containers solve all of our problems?&lt;/p&gt;

&lt;p&gt;While this talk doesn't provide you with the recipe of the perfect CI, it could help you to prepare for the challenge which designing CI infrastructure definitely is.&lt;/p&gt;</description>
        <persons>
          <person id="2738">Aleksandra Fedorova</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2973">
        <start>12:45</start>
        <duration>00:45</duration>
        <room>H.1309 (Van Rijn)</room>
        <slug>its_not_a_bug_its_an_environment_problem</slug>
        <title>It’s not a bug, it’s an environment problem. </title>
        <subtitle/>
        <track>Testing and automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;It’s not a bug, it’s an environment problem.
Environments are costly and data refreshes tedious. As a result, QA analysts have to make compromises and work in environments that have a different makeup than the production environment, which can create false positives and missed bugs. This presentation will help QA engineers learn how to mitigate the lack of data refreshes by creating modular test cases and use parameters to dissociate the data from the test cases and automation and therefore be able to work with data that you do have in each environment. Additionally, it will dive into how to maximize the environments QA professionals currently have and align them to their testing process to do feature testing and regression efficiently.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2636">Helene Astier</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2966">
        <start>13:40</start>
        <duration>00:45</duration>
        <room>H.1309 (Van Rijn)</room>
        <slug>appium_module_automation_made_awesome</slug>
        <title>Appium</title>
        <subtitle>Mobile Automation Made Awesome</subtitle>
        <track>Testing and automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Appium (http://appium.io) is a world-class, award-winning open source test automation framework for use with native, hybrid and mobile web apps.  It drives iOS and Android apps using the WebDriver protocol and uses APIs similar to Selenium.  In doing so, it allows developers to run the same tests across multiple mobile devices.&lt;/p&gt;

&lt;p&gt;This talk will explain how Appium works, the advantages it offers, and provide implementation examples for Android and iOS.  I am a core contributor to Appium development and work for Sauce Labs.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2667">Eric Millin</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3144">
        <start>14:35</start>
        <duration>00:45</duration>
        <room>H.1309 (Van Rijn)</room>
        <slug>property_based_testing</slug>
        <title>Property-based testing an open-source compiler, pflua</title>
        <subtitle>A fast and easy way to find bugs</subtitle>
        <track>Testing and automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Discover property-based testing, and see how it works on a real project, the pflua compiler.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;How do you find a lot of non-obvious bugs in an afternoon? Write a property that should always be true (like "this code should have the same result before and after it's optimized"), generate random valid expressions, and study the counter-examples!&lt;/p&gt;

&lt;p&gt;Property-based testing is a powerful technique for finding bugs quickly. It can partly replace unit tests, leading to a more flexible test suite that generates more cases and finds more bugs in less time.&lt;/p&gt;

&lt;p&gt;It's really quick and easy to get started with property-based testing. You can use existing tools like QuickCheck, or write your own: Andy Windo and I wrote pflua-quickcheck and found a half-dozen bugs with it in one afternoon, using pure Lua and no external libraries.&lt;/p&gt;

&lt;p&gt;In this talk, I will introduce property-based testing, demonstrate a tool for using it in Lua - and how to write your own property-based testing tool from scratch, and explain how simple properties found bugs in pflua.&lt;/p&gt;</description>
        <persons>
          <person id="2770">Katerina Barone-Adesi</person>
        </persons>
        <links>
          <link href="https://github.com/igalia/pflua-test">Lua quickcheck implementation for pflua.</link>
        </links>
      </event>
      <event id="2537">
        <start>15:30</start>
        <duration>00:45</duration>
        <room>H.1309 (Van Rijn)</room>
        <slug>make_your_tests_fail</slug>
        <title>Make your tests fail</title>
        <subtitle>How randomisation adds a whole new dimension to finding bugs in your code</subtitle>
        <track>Testing and automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;It's easy as pie: before checking in, your test suite should always be green. Or should it? What if your tests are all green but you forgot to check one important edge case? What if your underlying system environment lets you down, but only under rare conditions that you didn't cover in your tests?&lt;/p&gt;

&lt;p&gt;This talk introduces randomised testing as used by projects like Apache Lucene and Elasticsearch based on the Carrotsearch Randomised Testing framework. It has helped uncover (and ultimately fix) a huge number of bugs not only in these project’s source code, but also in the JVM itself which those projects rely on.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Writing unit and integration tests can be tricky: assumptions about your code may not always be true as any number of "this should never happen" log entries in production systems show. When implementing a system that will be integrated in all sorts of expected, unexpected, and outright weird ways by downstream users, testing all possible code paths, configurations and deployment environments gets complicated.&lt;/p&gt;

&lt;p&gt;With the Carrotsearch Randomised Testing framework, projects like Apache Lucene and Elasticsearch have introduced a new level to their unit and integration tests. Input values are no longer statically pre-defined but are generated based on developer defined constraints, meaning The test suite is no longer re-run with a static set of input data each time. Instead, every continuous integration run adds to the search space covered. Though generated at random, tests are still reproducible as all configurations are based on specific test seeds that can be used to re-run the test with the exact same configuration.&lt;/p&gt;

&lt;p&gt;Add to this randomising the runtime environment by executing tests with various JVM versions and configurations,and you are bound to find cases where your application runs into limitations and bugs in the JVM.&lt;/p&gt;

&lt;p&gt;This talk introduces randomised testing as a concept, shows examples of how the Carrotsearch Randomised Testing framework helps with making your test cases more interesting, and provides some insight into how randomising your execution environment can help save downstream users from surprises. All without putting too much strain on your continuous integration resources.&lt;/p&gt;</description>
        <persons>
          <person id="2234">Isabel Drost-Fromm</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3057">
        <start>16:25</start>
        <duration>00:35</duration>
        <room>H.1309 (Van Rijn)</room>
        <slug>it_doesnt_do_what_you_think_it_does</slug>
        <title>It Doesn't Do What You Think It Does</title>
        <subtitle>A Survey of Strategies for Gaining Confidence in (Testing) Applications/Systems</subtitle>
        <track>Testing and automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;How do we have confidence that our applications and systems do what they say on the tin? This will be a brief survey of how people gain confidence that their systems work as intended, finding links between everything from type systems to operational monitoring and how each layer of a system can help improve our confidence in the other.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;We will start with the emphasis of modern type systems on the compile time correctness of a program as well as language level strategies for run time assertions. We will transition from having confidence in our systems via language level features to external tests as we compare and contrast how tests are written using xUnit style and BDD style testing as well as introduce generative testing from functional languages. Going farther up the layers of abstraction, we will look at full system level testing of emergent behaviors via simulation testing. Finally we will compare similarities with simulation testing and staging environments, and how this level of insight is extended into production via monitoring.&lt;/p&gt;

&lt;p&gt;This talk will discuss high level concepts with brief examples using FLOSS tools and many links for further examples and reading. Its target audience is intermediate Developers, Testers, and Leads that want to understand the big picture of how testing fits into many other disciplines.&lt;/p&gt;</description>
        <persons>
          <person id="2728">Justin Stoller</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="H.2213">
      <event id="2637">
        <start>09:45</start>
        <duration>00:10</duration>
        <room>H.2213</room>
        <slug>deviot01</slug>
        <title>Welcome to the IoT Devroom</title>
        <subtitle>Welcome to participants and explanation of the day</subtitle>
        <track>Internet of things</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Welcome to participants and explanation of the day.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="522">Pieter Hintjens</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2502">
        <start>10:00</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>deviot02</slug>
        <title>Orchestrating computer systems, a new protocol</title>
        <subtitle>Introducing ZOCP an orchestration protocol for live performances, rapid prototyping and the IoT</subtitle>
        <track>Internet of things</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Trying to control multiple computers in live performances is a challenging task. Often computers intercommunicate using fixed or manually configured parameters. However when projects expand across many devices this is hard to maintain, especially in situations where parameters are prone to change. ZOCP is a new protocol which solves this problem by facilitating flexibility and autonomous configurations in an orchestrated environment.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;In this presentation we present the ZOCP protocol which overcomes the situations mentioned below. The ZOCP protocol is designed with the following in mind:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;KISS (Keep it simple and stupid): We want this protocol not be in our way and we want to be able to understand it easily.&lt;/li&gt;
&lt;li&gt;Zero Configuration: The protocol should be able to handle most, if not all configuration by itself. There is no need for setting up specific parameters unless requested, aka convention over configuration.&lt;/li&gt;
&lt;li&gt;Runs on anything TCP/IP: Since TCP/IP is the de facto standard for devices to communicate the technology should be able to run on any device that is able to talk TCP/IP&lt;/li&gt;
&lt;li&gt;Open Standards: All used technologies, software, protocols should be freely and openly available.&lt;/li&gt;
&lt;li&gt;Low latency, when needed&lt;/li&gt;
&lt;li&gt;Reliability, when needed&lt;/li&gt;
&lt;li&gt;Unintrusive debugging and monitoring&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;As artists embrace new technologies as an artistic medium, these technologies often provide artists with new methods for cooperation. Networking technologies are used frequently for these purposes. Internet has been a driving force behind the development of networking hardware and open standards for connecting any to device to any device. These technologies are now a commodity and thus available for anybody to use. However we see a rising need to be able to implement these technologies in a flexible adaptive manner without the explicit fixed configurations requiring manual configuration.&lt;/p&gt;

&lt;p&gt;Open Sound Control (OSC) is a protocol developed for exchanging music performance data. OSC is often used as an alternative to MIDI, however, it has found its way to many use cases besides musical performances. We have found OSC to be an ideal de facto standard for connecting applications to each other in order to orchestrate them. However the flexibility of OSC tends to decrease exponentially when used in large configurations because of its hard-coded nature. This implies that many applications need to be instructed to use specific manual settings and agreements in order for applications to communicate. In large configurations containing multiple systems and multiple applications, this manual work is inflexible and error prone.&lt;/p&gt;

&lt;p&gt;The current prototype is developed using the ZeroMQ framework. We will demonstrate the protocol in a setup with Blender, a game engine, an Urwid console monitor and a RaspberryPi.&lt;/p&gt;</description>
        <persons>
          <person id="2256">Arnaud Loonstra</person>
        </persons>
        <links>
          <link href="http://www.z25.org/static/_rd_/zocp_init_plab/index.html">Initial research paper</link>
          <link href="http://github.com/z25/pyZOCP">Python implementation </link>
        </links>
      </event>
      <event id="2940">
        <start>10:30</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>deviot03</slug>
        <title>Creating an IoT device with ease.</title>
        <subtitle>With Tizen you are almost there !</subtitle>
        <track>Internet of things</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk will focus on how to adapt an existing distro like Tizen to the IoT world and try to answer some questions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;how 'small' is an IoT device ?&lt;/li&gt;
&lt;li&gt;why starting with Tizen ?&lt;/li&gt;
&lt;li&gt;what are the consequences on the software architecture ?&lt;/li&gt;
&lt;li&gt;which adjustments for which components ?&lt;/li&gt;
&lt;/ul&gt;
</abstract>
        <description>&lt;p&gt;Topics:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;How 'small' is an IoT device ?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;memory size, CPU power&lt;/li&gt;
&lt;li&gt;headless or not ?&lt;/li&gt;
&lt;li&gt;wireless or not ? (which connectivity)&lt;/li&gt;
&lt;li&gt;power consumption&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Why Tizen ?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;OS for everything !&lt;/li&gt;
&lt;li&gt;connected&lt;/li&gt;
&lt;li&gt;secure&lt;/li&gt;
&lt;li&gt;Yocto-enabled&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Tizen architecture revisited&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Tizen APIs&lt;/li&gt;
&lt;li&gt;&lt;ul&gt;
&lt;li&gt;Wearable APIs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;ul&gt;
&lt;li&gt;OIC APIs (or AllJoyn APIs)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Tizen components to adjust:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;linux kernel&lt;/li&gt;
&lt;li&gt;display system: framebuffer (no GPU)&lt;/li&gt;
&lt;li&gt;no graphics server (no weston, no X11)&lt;/li&gt;
&lt;li&gt;embedded crosswalk on framebuffer&lt;/li&gt;
&lt;li&gt;systemd -&gt; uselessd&lt;/li&gt;
&lt;li&gt;others ...&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        <persons>
          <person id="1782">Stéphane Desneux</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3079">
        <start>11:00</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>deviot04</slug>
        <title>IoT through Matrix</title>
        <subtitle>Matrix.org is a new open standard for distributed, real-time communication</subtitle>
        <track>Internet of things</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Matrix is a new, pragmatic HTTP-based clean-room alternative to XMPP, SIP, IRC and other messaging/VoIP technologies. It consists of an open standard defining RESTful HTTP APIs and open source, Apache-licensed reference implementations for creating and running your own real-time communication infrastructure for VoIP/IM or any other service that includes sending binary data around - including IoT services.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Matrix is a set of pragmatic RESTful HTTP JSON APIs presented as an open standard, intended to be implemented on a wide range of servers, services and clients, letting developers build functionality on top of the Matrix ecosystem for messaging, VoIP and a multitude of other services.&lt;/p&gt;

&lt;p&gt;In Matrix, every user runs one or more Matrix clients, which connect through to a Matrix "homeserver" which stores all their personal communication history and user account information - much as a mail client connects through to an IMAP/SMTP server. Just like email, you can either run your own Matrix homeserver, which means you own and control your own communications and history - or you can use one hosted by someone else (e.g. matrix.org) - there is no single point of control or mandatory service provider in Matrix.  In fact, there is no single point of control over conversations in Matrix at all - conversation history is a first class citizen, with room state replicated over all participating servers, avoiding single-points of failure or control as you get in XMPP MUCs.&lt;/p&gt;

&lt;p&gt;With the continously increasing number of devices connected to the internet, we need ways to gather and unify all the status and instruction data going back and forth - and Matrix is a perfect fit for these kind of services.&lt;/p&gt;</description>
        <persons>
          <person id="2951">Matthew Hodgson</person>
        </persons>
        <links>
          <link href="http://matrix.org">Matrix</link>
        </links>
      </event>
      <event id="2998">
        <start>11:30</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>deviot05</slug>
        <title>Using GSM network for IoT</title>
        <subtitle>AT commands are not dead</subtitle>
        <track>Internet of things</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Connectivity is crucial for Internet of Things concept. For moving devices like position data loggers is typical solution GSM network. I will show you how you can use different types of GSM network for your IoT projects.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;GSM network is easy way how to connect almost any device to internet. There are lot of GSM modules on market from different vendors but all devices has one thing in common - AT commands. There is standardized AT commands set for GSM networks. Using AT command you can send text messages, read phone number from list on SIM card, connect to internet and much more. I will show you basic command set for HTTP communication using basic GSM module SIM900 and Arduino.&lt;/p&gt;</description>
        <persons>
          <person id="2687">Stepan Bechynsky</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3003">
        <start>12:00</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>deviot06</slug>
        <title>Working with I/O using libmraa on Linux</title>
        <subtitle/>
        <track>Internet of things</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;libmraa is a low level IO library for GNU/Linux platforms in the IoT sector. It tries to abstract platform 'crazyness' such as level shifters, i2c gpio expanders and other hardware features that software engineers don't want to deal with. It supports C/C++/python &amp;amp; nodejs and a number of hardware platforms.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;I plan to run the talk in this order:
- Small demo showing how to use IO on a MIPS based vocore &amp;amp; an intel based edison both using libmraa, a few sensors &amp;amp; actuators on various buses to show the flexibility and the same code running on both platforms
- Example of why current APIs are too complicated and not portable
- Quick walkthrough of the board configuration API to add new platforms to the build system
- Q&amp;amp;A&lt;/p&gt;

&lt;p&gt;The aim is to show people how we can interact with IO as seemlessly as possible between platforms and that adding new platforms to the framework is relatively easy.&lt;/p&gt;</description>
        <persons>
          <person id="2308">Brendan Le Foll</person>
        </persons>
        <links>
          <link href="https://github.com/intel-iot-devkit/mraa">libmraa git repository</link>
        </links>
      </event>
      <event id="3080">
        <start>12:30</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>deviot07</slug>
        <title>Patchwork Toolkit</title>
        <subtitle>Lightweight Platform for the Network of Things</subtitle>
        <track>Internet of things</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Patchwork is a toolkit for connecting various devices into a network of things or, in a more broad case - Internet of Things (IoT). The main goal of creating this toolkit is to have a lightweight set of components that can help to quickly integrate different devices (i.e. Arduinos, RaspberryPI's, Plugwise, etc) into a smart environment and expose specific devices' capabilities as RESTful/SOAP/CoAP/MQTT/etc services and data streams.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The key features of patchwork include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Lightweight (no RAM-consuming sliced pie of Java and OSGi, only bare necessities)&lt;/li&gt;
&lt;li&gt;Cross-platform (can be deployed on OSX/Linux/Windows, tested on RaspberryPI and BeagleBone Black boards)&lt;/li&gt;
&lt;li&gt;Language-agnostic (device agents can be written in any programming language, APIs can be consumed by app written in any programming language)&lt;/li&gt;
&lt;li&gt;Easily deployable (no JARs, no Eggs or Wheels for the core components, just a single native binary with statically linked dependencies)&lt;/li&gt;
&lt;li&gt;Easily extendable (integrate new devices without modification of the core components, drop in solution)&lt;/li&gt;
&lt;li&gt;Interchangeable (not happy with current existing Device Gateway or Catalog? replace it with another implementation without breaking the infrastructure)&lt;/li&gt;
&lt;li&gt;Not re-inventing the wheel (we re-use as many existing technologies and components as possible)&lt;/li&gt;
&lt;/ul&gt;
</description>
        <persons>
          <person id="2739">Alexandr Krylovskiy</person>
        </persons>
        <links>
          <link href="http://patchwork-toolkit.github.io/">web site</link>
          <link href="https://github.com/patchwork-toolkit/patchwork">source code</link>
        </links>
      </event>
      <event id="3015">
        <start>13:00</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>deviot08</slug>
        <title>picoTCP for Linux Kernel tinification</title>
        <subtitle>Replacing the kernel's stack with picoTCP</subtitle>
        <track>Internet of things</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;By replacing the Linux Kernel's TCP/IP stack with picoTCP, we aim to lower the threshold to use Linux on small embedded systems and bring it to the IoT world. In this case we ran it on a Cortex-M microcontroller with a few MBs of RAM and flash.
Using picoTCP inside the kernel results in a reduction of the kernel's size by over 300 kb, while still having all of the TCP/IP functionality an embedded system might need, and more.
The talk will start with a demo, then a motivition why we did this, and finally explaining how we did this.&lt;/p&gt;</abstract>
        <description>&lt;h1&gt;picoTCP for Linux Kernel tinification&lt;/h1&gt;

&lt;p&gt;"Linux runs on everything from cellphones to supercomputers"; While this is true, in 2014 an average cellphone has around 2GB of memory, 16GB of flash and a quad-core CPU. The embedded systems we have in mind for the Internet of Things might be more in the region of a few megabytes of flash and ram.&lt;/p&gt;

&lt;p&gt;The Linux kernel has been growing in size over the years; growing in features also. But a lot of the development has been focused on supporting more CPU’s, more memory, more high-end stuff to support supercomputer-like systems. The minimum possible kernel size has increased with almost every release.&lt;/p&gt;

&lt;p&gt;An ongoing effort exists to try and tinify the Linux kernel, with these embedded systems in mind. There is the Tiny wiki1, LWN article on Kernel tinification2 and the LWN article on Networking on tiny machines3.&lt;/p&gt;

&lt;p&gt;Being embedded system developers, getting inspired by these articles, and being the creators of picoTCP, we thought of pushing the tinification a step further: Replace the Kernel’s TCP/IP stack with picoTCP. picoTCP is a free TCP/IP stack designed for embedded systems.
In a typical ucLinux kernel the network functionality is over 500 kb; that can be 1/4th of the kernel!&lt;/p&gt;

&lt;p&gt;The talk will start with a demo of picoTCP inside the Linux kernel, running on an STM32F4 Cortex-M4 microcontroller. Then, we’ll show some figures on why this is important, and explain the steps taken to strip the default TCP/IP stack from the kernel and replace it with picoTCP; reducing the kernel size by over 300 kb.&lt;/p&gt;

&lt;p&gt;References:
https://tiny.wiki.kernel.org/
http://lwn.net/Articles/608945/
http://lwn.net/Articles/597529/&lt;/p&gt;

&lt;p&gt;uC Linux kernel size - nominal - = 2.1 MB
uC Linux kernel size - No Network Support - = 1.5 MB
uC Linux kernel size - No TCP, but drivers - = 1.67 MB (1,749,216 b)
uC Linux kernel size - PicoTCP (ipv4, dns client, arp, tcp, udp, icmp) - = 1,790,912 b (+ 41696 bytes = 40.7 kB)&lt;/p&gt;</description>
        <persons>
          <person id="1866">Maxime Vincent</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3041">
        <start>13:30</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>deviot09</slug>
        <title>What's new inside the Linux IEEE 802.15.4 subsystem?</title>
        <subtitle/>
        <track>Internet of things</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Many patches found their way into the mainline Linux kernel since the last talk about the state of IEEE 802.15.4 and 6LoWPAN at FOSDEM 2014.&lt;/p&gt;

&lt;p&gt;This presentation will outline what changes were done, with a focus on the 802.15.4 subsystem.
The architecture of the subsystem has been reworked to be more similar to the 802.11 wifi stack; in addition, this lecture will explain new internal kernel frameworks and the new "wpan" userspace tool which is based on "iw" and give an outlook towards upper layer protocol such as 6LoWPAN.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;This talk will begin with a demo to show the fixed changes according the last FOSDEM talk.
Mainly these are the fragmentation and UDP fixes.
Demo for fragmentation will be a simple "ping6" example with high payload between two Linux nodes.
Another demo for UDP fixes will be a simple "netcat" example between Linux and contiki nodes.
During the demo applications wireshark is running for confirm the working connection.
Additional the demo will show the new userspace tool.&lt;/p&gt;

&lt;p&gt;After that the presentation will start with information about general project information like project name change and new mailinglist address.
Moreover the talk explain new internal kernel frameworks for introducing new userspace interfaces.
At last future work will be show.&lt;/p&gt;

&lt;p&gt;Rest of time is to start a Q&amp;amp;A with the audience.&lt;/p&gt;</description>
        <persons>
          <person id="1745">Alexander Aring</person>
        </persons>
        <links>
          <link href="http://wpan.cakelab.org/">project website</link>
        </links>
      </event>
      <event id="3211">
        <start>14:00</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>deviot10</slug>
        <title>Put an "Actor Model" in your House</title>
        <subtitle/>
        <track>Internet of things</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The Internet of Things with the explosion of sensor adds a lot of challenges in how to deal with all of these simultaneously connected devices producing lots of data to be retrieved, actors have delivery guarantees and isolation properties that are perfect for the IoT world. The session will show how to implement an actor base home automation system.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The actor model with the characteristics of elastic and decentralized by design, is the perfect solution for IOT environment. With actor is possible to create a simple concurrency and distributed system that react  on the events. The talk will give an overview on the existing technologies and implementation, it will show also the experience of build an home automation system with an actor model with the description of the challenges and the solution adopted.&lt;/p&gt;</description>
        <persons>
          <person id="1929">Fabrizio Manfredi</person>
        </persons>
        <links>
          <link href="http://en.wikipedia.org/wiki/Actor_model">Actor Model</link>
          <link href="http://www.reactivemanifesto.org/">Reactive Manifest</link>
          <link href="http://readwrite.com/2014/07/10/akka-jonas-boner-concurrency-distributed-computing-internet-of-things">How One Developer Set Out To Make The Internet Of Things Manageable</link>
          <link href="http://scalacamp.pl/data/Grzegorz-Kossakowski-Actors-Play-backend-role-for-internet-of-things.pdf">Actors Play backend role for Internet of Things</link>
          <link href="http://www.openhab.org/">OpenHab</link>
        </links>
      </event>
      <event id="2666">
        <start>14:30</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>deviot11</slug>
        <title>MCUIO/LININOIO - Virtualizing MCU peripherals</title>
        <subtitle/>
        <track>Internet of things</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;MCUIO/LININOIO - Virtualizing MCU peripherals&lt;/p&gt;

&lt;p&gt;The MCUIO/LININOIO subsystem allows a Microprocessor Unit (MPU), somehow
connected to a Microcontroller Unit (MCU), to see the MCU's peripherals as
standard Linux peripherals (i.e. gpios, i2c adapters, pwms, ...).
The basic communication protocol is completely generic, it just defines ways
to read/write a (virtualized) memory space on the MCU. Standard, vendor
independent memory maps are then defined for each kind of MCU peripheral, so
that MCU specific implementation details can be ignored by the MPU.
Interrupt events can be spontaneously sent by the MCU to the MPU as write
requests.
The protocol is transport independent, only a bidirectional channel is required
(for instance rs232 or even a network connection).&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Coming soon...&lt;/p&gt;</description>
        <persons>
          <person id="2390">Aurelio Colosimo</person>
          <person id="2976">Davide Ciminaghi</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2761">
        <start>15:00</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>deviot12</slug>
        <title>XMPP-IoT an open solution for things</title>
        <subtitle>A demo and talk around using XMPP to create open scalable and secure IoT systems between peers in different domains</subtitle>
        <track>Internet of things</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The XMPP community has since 2013 been working to enable the federated XMPP network to support Internet of Things (IoT).
In this Demo/Talk, we will go through the initiative, showing how individual devices, and larger systems can interact cross domains in a secure interoperable environment.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The XMPP-IoT initiative is an Internet of Things solution from the XMPP standards foundation XSF. It consists of several extensions to the common known XMPP instant messaging standard.&lt;/p&gt;

&lt;p&gt;One of the core values of the technology is that XMPP already has a large federated server to server infrastructure for messaging. Using this will create an open interoperable middleware for IoT. Where any device in a domain freeley can choose to interact with anybody else through the federation and friendship mechanisms, just as the chat network is used today.
Using standard XML creates good interoperability possibilities and during 2014 the xmpp network also upgraded to demand participants in the network to enforce encryption both server to server and client to server to increase security.&lt;/p&gt;

&lt;p&gt;Agenda:
Demo of live devices locally and on the web.
 -The audience is invited to interact with them during the talk through phones and laptops
An intro to the core concepts, reading and writing values in devices.
A discussion on the security, scalability and interoperability, distributed vs. centralized solutions.
If interest and time exist we will touch on EXI to create XML compression.&lt;/p&gt;</description>
        <persons>
          <person id="1660">Joachim Lindborg</person>
        </persons>
        <links>
          <link href="http://xmpp.org/extensions">the XMPP extension library</link>
          <link href="http://xmpp-iot.github.io/">Live open github web with explanations and how-to</link>
          <link href="http://wiki.xmpp.org/web/Tech_pages/IoT_systems">XMPP wikipages</link>
          <link href="http://wiki.xmpp.org/web/Securing_XMPP">Securing the federated XMPP network</link>
          <link href="http://xmpp-iot.github.io/basics/read-a-value/">Intro to the XEP 323 reading fields</link>
          <link href="http://xmpp-iot.github.io/basics/write-a-value/">Intro to the XEP 325 writing fields</link>
          <link href="http://www.w3.org/XML/EXI/">EXI XML compression</link>
        </links>
      </event>
      <event id="3106">
        <start>15:30</start>
        <duration>00:25</duration>
        <room>H.2213</room>
        <slug>deviot13</slug>
        <title>Manage all the things, small and big, with open source LwM2M implementations</title>
        <subtitle/>
        <track>Internet of things</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;LwM2M is a standard for device management that solves many of the issues M2M and IoT solutions makers have faced in the past (or, let's be realistic, are still facing), with custom protocols or even standards like OMA-DM: complex workflows, high bandwidth usage, lack of open-source implementations...
Join this talk to get an overview of the LwM2M protocol, and to learn how you can start managing an embedded device with Eclipse Wakaama (yes, it fits in an Arduino, and yes, there will be a live demo!), or build your own device management server with Eclipse Leshan.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2694">Benjamin Cabé</person>
        </persons>
        <links>
          <link href="https://github.com/jvermillard/leshan">Leshan</link>
          <link href="https://github.com/eclipse/wakaama">Wakaama</link>
          <link href="http://iot.eclipse.org">Eclipse IoT projects</link>
        </links>
      </event>
      <event id="3409">
        <start>16:00</start>
        <duration>01:00</duration>
        <room>H.2213</room>
        <slug>deviot14</slug>
        <title>Open space</title>
        <subtitle/>
        <track>Internet of things</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Open space for participant-driven talks, Q&amp;amp;A, demos, and other short pieces.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Speakers welcome on a FIFO basis, 5-minute time slots allocated by the room moderators at their discretion and according to feedback from the audience.&lt;/p&gt;</description>
        <persons>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="H.2214">
      <event id="3510">
        <start>09:30</start>
        <duration>00:30</duration>
        <room>H.2214</room>
        <slug>vidi</slug>
        <title>ViDI - The Visual Design Inspector</title>
        <subtitle/>
        <track>Smalltalk</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;We present ViDI, a platform to provide interactive 2D and 3D visualizations of Design Problems in Smalltalk systems. The user can inspect and correct issues in the source code, as well as compare different versions of the same system in terms of design quality. ViDI is built on top of Moose, CodeCity, Roassal, and CodeCritics.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2974">Yuriy Tymchuk</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3471">
        <start>10:00</start>
        <duration>00:30</duration>
        <room>H.2214</room>
        <slug>gt</slug>
        <title>GT</title>
        <subtitle>A new generation of development tools</subtitle>
        <track>Smalltalk</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Mold your development environment. Your system is too special to leave it in the hands of generic tools. The &lt;a href="http://gt.moosetechnology.org/"&gt;Glamorous Toolkit (GT)&lt;/a&gt; brings a new generation of easily customizable development tools.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2930">Andrei Chis</person>
          <person id="2945">Aliaksei Syrel</person>
        </persons>
        <links>
          <link href="http://gt.moosetechnology.org/">The Glamorous Toolkit</link>
          <link href="http://">http://</link>
        </links>
      </event>
      <event id="3462">
        <start>10:30</start>
        <duration>00:30</duration>
        <room>H.2214</room>
        <slug>ddc</slug>
        <title>Dynamic Distributed Computation with Smalltalk</title>
        <subtitle/>
        <track>Smalltalk</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Context is a Smalltalk distribution with a minimal object memory
and a distributed module system. I will demonstrate distributed
operation on a small local network of machines, focusing on use cases
for remote team development.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2384">Craig Latta</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3445">
        <start>11:00</start>
        <duration>00:30</duration>
        <room>H.2214</room>
        <slug>embeddedpharo</slug>
        <title>Embedded pharo</title>
        <subtitle/>
        <track>Smalltalk</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Pharo can be used on much more than just a Linux, Mac or Windows pc. The vm is rather easy to port as most of the code is written in Slang, a Smalltalk subset that easily compiles to c.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2846">Max Mattone</person>
          <person id="2863">Jean-Baptiste Arnaud</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2658">
        <start>11:30</start>
        <duration>00:30</duration>
        <room>H.2214</room>
        <slug>zerooverhead</slug>
        <title>Zero-Overhead Metaprogramming</title>
        <subtitle>Using Self-optimizing Interpreters to make Runtime Metaprogramming Fast</subtitle>
        <track>Smalltalk</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Runtime metaprogramming enables many useful applications and is widely used in frameworks, middleware, and domain-specific languages to simplify the task of application developers. However, today’s language implementations rarely optimize even common concepts such as reflective method invocation or dynamic proxies, despite the fact that solutions for efficient implementations have been advocated since decades.&lt;/p&gt;

&lt;p&gt;In this presentation, we demonstrate how self-optimizing interpreters can be used to implement runtime metaprogramming efficiently.
For the implementation, we use SOM Smalltalk, a little Smalltalk implemented in RPython (think PyPy) as well as Truffle (with Graal on top of the JVM).
We show that both platforms can remove the runtime overhead of reflection and thus open up new opportunities for metaprogramming in performance critical scenarios.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2295">Stefan Marr</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3469">
        <start>12:00</start>
        <duration>00:45</duration>
        <room>H.2214</room>
        <slug>showsmalltalk</slug>
        <title>Show us your projects</title>
        <subtitle>Short demos</subtitle>
        <track>Smalltalk</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Short presentations and demonstrations of interesting tools &amp;amp; projects. Let us know if you want to see or present something.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
        </persons>
        <links>
        </links>
      </event>
      <event id="3467">
        <start>12:45</start>
        <duration>01:00</duration>
        <room>H.2214</room>
        <slug>amber</slug>
        <title>Amber Smalltalk - Get Started &amp; More</title>
        <subtitle>Jump into the modern web with Amber</subtitle>
        <track>Smalltalk</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;SPAs are the new way to do web apps.
Javascript is the de facto assembly language of the web,&lt;/p&gt;

&lt;p&gt;But Javascript is ugly and debugging it is nightmarish (despite Developer Tools).
Node is cool, but Javascript is not as much.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2934">Philippe Back</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3137">
        <start>13:45</start>
        <duration>00:30</duration>
        <room>H.2214</room>
        <slug>cirela</slug>
        <title>Cirela, open source solutions to manage, monitor and prevent natural and environment disasters; an initial work</title>
        <subtitle/>
        <track>Smalltalk</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;CIRELA (Communication and Information technology for REsiLience to disAsters) is a non profit NGO aiming at providing open source solutions to manage, monitor and prevent natural and environmental disasters. Currently we are focusing on wireless sensor network (WSN) based monitoring and warning systems.&lt;/p&gt;

&lt;p&gt;We are working on WSN applications where people in a disaster-prone area can actively participate, to have access to information, to be warned on time, and to have their own sensor if they want. Jakarta with frequent flood events is currently a case we are working on.&lt;/p&gt;

&lt;p&gt;A 'simple' WSN based flood monitoring application will measure water levels on different locations using sensors, put this information on a server and make it available to users, warn people when the water level in an area is higher than an acceptable limit, ... So we have to manage a geographically distributed and concurrent system where sensor modules represent concurrent processes.&lt;/p&gt;

&lt;p&gt;We want to have a pleasant and user friendly environment for end-users as well as for programmers. We started to develop our applications with Pharo. We'll show Pharo with OpenStreetMap and Roassal2:
- to visualize geographic data and information
- to present and to simulate wireless sensor networks&lt;/p&gt;</abstract>
        <description>&lt;p&gt;CIRELA (Communication and Information technology for REsiLience to disAsters) is a non profit NGO aiming at providing open source solutions to manage, monitor and prevent natural and environmental disasters. Currently we are focusing on wireless sensor network (WSN) based monitoring and warning systems.&lt;/p&gt;

&lt;p&gt;We are working on WSN applications where people in a disaster-prone area can actively participate, to have access to information, to be warned on time, and to have their own sensor if they want. Jakarta with frequent flood events is currently a case we are working on.&lt;/p&gt;

&lt;p&gt;A 'simple' WSN based flood monitoring application will measure water levels on different locations using sensors, put this information on a server and make it available to users, warn people when the water level in an area is higher than an acceptable limit, ... So we have to manage a geographically distributed and concurrent system where sensor modules represent concurrent processes.&lt;/p&gt;

&lt;p&gt;We want to have a pleasant and user friendly environment for end-users as well as for programmers. We started to develop our applications with Pharo. We'll show Pharo with OpenStreetMap and Roassal2:
- to visualize geographic data and information
- to present and to simulate wireless sensor networks&lt;/p&gt;</description>
        <persons>
          <person id="2759">Onil Goubier</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3152">
        <start>14:15</start>
        <duration>00:45</duration>
        <room>H.2214</room>
        <slug>pharo</slug>
        <title>Pharo: Status and Plans</title>
        <subtitle>Another year, another release</subtitle>
        <track>Smalltalk</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Pharo3 was released in March 2014. Not even a year later, we are close to the release of Pharo4.&lt;/p&gt;

&lt;p&gt;This talk will give an overview of the changes and improvements done and show some demos of new functionality.
Again, Pharo4 is just a small step: after the release in the Spring of 2015, we will start to iteratet on Pharo5.
I will present the roadmap of what we will work on in Pharo5.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Pharo3 was released in March 2014. Not even a year later, we are close to the release of Pharo4.&lt;/p&gt;

&lt;p&gt;This talk will give an overview of the changes and improvements done and show some demos of new functionality.
Again, Pharo4 is just a small step: after the release in the Spring of 2015, we will start to iteratet on Pharo5.
I will present the roadmap of what we will work on in Pharo5.&lt;/p&gt;

&lt;p&gt;Bio
Marcus Denker is a permanent researcher (CR1, with tenure) at INRIA Lille - Nord Europe. Before, he was a postdoc at the PLEIAD lab/DCC University of Chile and the Software Composition Group, University of Bern. His research focuses on reflection and meta-programming for dynamic languages. He is an active participant in the Squeak and Pharo open source communities for many years. Marcus Denker received a PhD in Computer Science from the University of Bern/Switzerland in 2008 and a Dipl.-Inform. (MSc) from the University of Karlsruhe/Germany in 2004. He is a member of ACM, GI, and IEEE and a board-member of ESUG.&lt;/p&gt;</description>
        <persons>
          <person id="2774">Marcus Denker</person>
        </persons>
        <links>
          <link href="http://pharo.org">Pharo Website</link>
        </links>
      </event>
      <event id="3468">
        <start>15:00</start>
        <duration>00:50</duration>
        <room>H.2214</room>
        <slug>backtothefuture</slug>
        <title>Back to the Future</title>
        <subtitle>(Re)learn smalltalk</subtitle>
        <track>Smalltalk</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Always wanted to see what the origin of object orientation and the IDE looks like 40 years later?
This is your chance to try the environment for yourself, and see the future of live development&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="107">Stephan Eggermont</person>
          <person id="2941">Nicole de Graaf</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="H.3227">
    </room>
    <room name="AW1.120">
      <event id="2890">
        <start>09:00</start>
        <duration>00:25</duration>
        <room>AW1.120</room>
        <slug>openconnect_vpn</slug>
        <title>Software isolation issues</title>
        <subtitle>faced on the development of openconnect VPN server</subtitle>
        <track>Security devroom</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;For the development of openconnect VPN server a decision to compartmentalize the server was taken, in order to protect any sensitive values exchanged, ranging from the user transferred data, to the data used during the authentication process.
This talk will summarize the issues faced during that development that relate to software isolation. That would cover issues with protecting the server's keys via TLS, the client-side authentication of TLS, and PAM authentication, and how they were solved (or not).&lt;/p&gt;</abstract>
        <description>&lt;p&gt;For the development of openconnect VPN server a decision to compartmentalize the server was taken, in order to protect any sensitive values exchanged, ranging from the user transferred data, to the data used during the authentication process.
This talk will summarize the issues faced during that development that relate to software isolation. That would cover issues with protecting the server's keys via TLS, the client-side authentication of TLS, and PAM authentication, and how they were solved (or not).&lt;/p&gt;</description>
        <persons>
          <person id="2362">Nikos Mavrogiannopoulos</person>
        </persons>
        <links>
          <link href="http://www.infradead.org/ocserv/technical.html">openconnect vpn server design</link>
        </links>
      </event>
      <event id="3212">
        <start>09:30</start>
        <duration>00:25</duration>
        <room>AW1.120</room>
        <slug>pixelvault</slug>
        <title>PixelVault</title>
        <subtitle>Using GPUs for Securing Cryptographic Operations</subtitle>
        <track>Security devroom</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Protecting the confidentiality of cryptographic keys in the event of partial or full system compromise is crucial for containing the impact of attacks. The Heartbleed vulnerability of April 2014, which allowed the remote leakage of secret keys from HTTPS web servers, is an indicative example. PixelVault is a system for keeping cryptographic keys and carrying out cryptographic operations exclusively on the GPU, which allows it to protect secret keys from leakage even in the event of full system compromise. This is possible by exposing secret keys only in GPU registers, keeping PixelVault’s critical code in the GPU instruction cache, preventing this way even privileged host code from accessing any sensitive code or data.&lt;/p&gt;

&lt;p&gt;Due to the non-preemptive execution mode of the GPU, an adversary that has full control of the host cannot tamper with PixelVault’s GPU code, but only terminate it, in which case all sensitive data is lost. We have implemented a PixelVault-enabled version of the OpenSSL library that allows the protection of existing applications with minimal modifications. Based on the results of our evaluation, PixelVault not only provides secure key storage using commodity hardware, but also significantly speeds up the processing throughput of cryptographic operations for server applications.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2800">Giorgos Vasiliadis</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3123">
        <start>10:00</start>
        <duration>00:25</duration>
        <room>AW1.120</room>
        <slug>caml_crush</slug>
        <title>Thou shalt not leak your keys</title>
        <subtitle>Practical key privilege separation using Caml Crush</subtitle>
        <track>Security devroom</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The Heartbleed vulnerability made one thing very clear, current TLS stacks lack
an efficient way to isolate the cryptographic material from the application
layer. Hence, this vulnerability required the massive renewal of private keys
and certificates. This sure was a costly and painful process for IT
departments. The most efficient approach consists of using Hardware Security
Modules or smartcards to store the cryptographic material. Keys remain
confidential while being usable through an API to perform cryptographic
operations.
PKCS#11 is a standardized security API that is widely adopted by
device vendors. However, deployment of such hardware can be costly and
inconvenient in many scenarios. We propose using Caml Crush, a PKCS#11
filtering proxy, in combination with software PKCS#11 tokens. This architecture
leverages process isolation between the TLS stack and the cryptographic
material. This low-cost alternative is immediately applicable to PKCS#11
compliant software. We demonstrate that this architecture has a low performance
overhead by benchmarking the impact on web hosting scenarios.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2517">Thomas Calderon</person>
        </persons>
        <links>
          <link href="https://github.com/ANSSI-FR/caml-crush">Caml Crush github</link>
        </links>
      </event>
      <event id="2825">
        <start>10:30</start>
        <duration>00:40</duration>
        <room>AW1.120</room>
        <slug>second_factor_auth</slug>
        <title>Universal 2nd Factor Authentication</title>
        <subtitle>Strengthening username/password authentication with "driverless" USB hardware</subtitle>
        <track>Security devroom</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Universal 2nd Factor is the next step in hardware-assisted authentication for cloud services and more.  U2F specify a USB-based protocol for offloading the private-key handling for strengthening username/password logins, and is supported by Chrome and Google (for gmail.com users) since October 2014.  By using dedicated hardware that require physical presence, issues with common solutions (one-time-password or certs) are improved on.  This talk will be about the U2F protocol, and the free software implementations that we are writing.  There will be hands-on demo of the user-experience and also details about the implementation.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2563">Simon Josefsson</person>
        </persons>
        <links>
          <link href="http://fidoalliance.org/">FIDO Alliance</link>
          <link href="http://yubico.com">Yubico</link>
          <link href="https://developers.yubico.com/U2F/">Yubico U2F Developer's resources</link>
        </links>
      </event>
      <event id="3287">
        <start>11:15</start>
        <duration>00:40</duration>
        <room>AW1.120</room>
        <slug>javacards</slug>
        <title>Quickstart JavaCard development.</title>
        <subtitle>Isolate keys and code into secure hardware!</subtitle>
        <track>Security devroom</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Tutorial on how to start developing useful smart card applications for real life smart cards in less than a day.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Overview of smart cards and specifically JavaCard platform and a description of what is needed for development and testing and how everything can be accomplished with minimal money and mostly open source tools. Dedicated smart card applications allow to isolate critical keys or even generic code into small, secure devices that can be kept in a safe.&lt;/p&gt;</description>
        <persons>
          <person id="167">Martin Paljak</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2883">
        <start>12:00</start>
        <duration>00:25</duration>
        <room>AW1.120</room>
        <slug>genode_os_security_by_design</slug>
        <title>Genode - OS security by design</title>
        <subtitle/>
        <track>Security devroom</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Most provisions against the steadily growing threats imposed by malware, viruses, and directed attacks are fighting symptoms rather than addressing the root of the problem, which lies in the operating system. Genode is an open-source OS technology that promises to give an answer to those threats. By organizing the system as nested sandboxes and consequently applying the principle of least privilege, it protects the privacy of the user and renders most classes of malware ineffective. The talk will be presented on a Genode-based system, which allows the demonstration of the concepts live during the talk.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The effects of malware and client-side attacks seem to have become a prevalent part of our inter-connected world and increasingly affect individuals, businesses, and governmental institutions alike. The topic has even managed to capture the attention of main-stream media, prompting vocal calls for counter-measures. Governments invest large sums in forming cyber-defense departments. Computer users are urged to invest money in anti-virus software and install a steady stream of security updates. However, those actions are just reactive, fighting symptoms, and merely relieve the problem rather than solving it. For example, none of those measures is effective against zero-day exploits.&lt;/p&gt;

&lt;p&gt;The root of the problem is not the "dumb user", or "outdated anti-virus software", or "cyber terrorists" but the antiquated way of how today's operating systems are structured, how they implement security, and the chaotic way of how software components are allowed to interact with each other.&lt;/p&gt;

&lt;p&gt;Genode is an operating-system architecture that promises to prevent most classes of security problems by design. Genode-based systems are created out of surprisingly simple primitives: Each program runs in a dedicated sandbox and gets granted only those rights and resources that are needed for its actual task. Programs can create and manage sub-sandboxes out of their own resources, thereby forming hierarchies where policies can be enforced at each level. Furthermore, programs are able to communicate and trade their resources, but only in a well-defined manner. Thanks to this rigid regime, the attack surface of security-critical functions can be reduced by orders of magnitude compared to contemporary operating systems.&lt;/p&gt;

&lt;p&gt;This sounds pretty academic but there exists an Open-Source implementation in the form of the Genode OS Framework showing that those ideas translate to a general-purpose OS. In line with Unix philosophy, this framework is a collection of small building blocks, out of which complex systems can be composed. But unlike Unix, those building blocks include not only applications but all classical OS functionalities including kernels, device drivers, file systems, and protocol stacks.&lt;/p&gt;

&lt;p&gt;During the talk, we will see several of those compositions demonstrated, hinting at the vast flexibility the architecture provides. At present, this makes Genode a rich playground for OS enthusiasts. The ultimate goal, however, is a fully-fledged operating system that protects the user's privacy and data, and relieves us from worrying about malware, virus infections, and directed attacks. The talk will show how Genode renders various classes of malware pointless and how the Genode developers envision their migration path from current-generation OSes to Genode.&lt;/p&gt;</description>
        <persons>
          <person id="607">Norman Feske</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3238">
        <start>12:30</start>
        <duration>00:25</duration>
        <room>AW1.120</room>
        <slug>mandos</slug>
        <title>Mandos</title>
        <subtitle>Disk encryption without passwords</subtitle>
        <track>Security devroom</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Disk encryption is essential for physical computer security, but seldom used due to the trouble of remembering and typing a password at every restart.  We describe Mandos, a program which solves this problem, its security model, and the underlying concepts of its design.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Any security system must have a clear view of its intended threat model – i.e. what threats it is actually intended to protect against; the specific choices and tradeoffs made for Mandos will be explained.  Another danger of security system design is the risk of its non-use; i.e. that the system will not be used for some real or perceived drawbacks, such as complexity.  The deliberate design choices of Mandos, involving low-interaction, “invisible” and automatic features, will be covered.&lt;/p&gt;</description>
        <persons>
          <person id="2811">Teddy Hogeborn</person>
        </persons>
        <links>
          <link href="http://www.recompile.se/mandos">Mandos Home Page</link>
        </links>
      </event>
      <event id="3083">
        <start>13:00</start>
        <duration>00:25</duration>
        <room>AW1.120</room>
        <slug>hybrid_crypto</slug>
        <title>Hybrid Cryptography</title>
        <subtitle>Applying Hybrid Cryptography to Restful Systems</subtitle>
        <track>Security devroom</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This will show what is Hybrid Cryptography and how we can use Hybrid Cryptography in Restful environments.&lt;/p&gt;

&lt;p&gt;I will show with example code in Ruby how this flexible system can be applied in Text, HTTP, and maybe other places to show how it is applicable to Restful systems without changing any current protocols.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Firstly, I will give an explanation of what Hybrid Cryptography is in theory, how it can work as an alternative cryptosystem or work with other cryptography.
My aim is to show that the users of this method allow them to control which cryptographic algorithms are used and when key rollover is performed.&lt;/p&gt;

&lt;p&gt;I will then highlight that as this is non-invasive, it can be used anywhere in the Internet protocols, maybe showing an example of working with another Internet protocol to show this.&lt;/p&gt;

&lt;p&gt;Then, I will show simple examples.
I show how it can be used in text, encrypting a text file.
Then, I show an alternative to HTTPS using this to encrypt a web page.
I then show that it can work with HTTPS pages too.&lt;/p&gt;

&lt;p&gt;If given time, I will show where this came from in encrypting DNS NAPTRs.&lt;/p&gt;

&lt;p&gt;Example code in Ruby will be shown throughout to allow others to use.&lt;/p&gt;

&lt;p&gt;I do not believe this applies directly to the main themes.
I am estimating that this talk is 30 mins, although I am busy coding, so have not drawn up the presentation slides.&lt;/p&gt;</description>
        <persons>
          <person id="2741">Romek Szczesniak</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3024">
        <start>14:00</start>
        <duration>00:25</duration>
        <room>AW1.120</room>
        <slug>sec_webcrypto</slug>
        <title>Web Security</title>
        <subtitle>WebCrypto and CSP </subtitle>
        <track>Security devroom</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk is about how CSP and WebCrypto provides security in a web browser. It will present how security is implemented in browser. CSP provides many advantages and providing content security provide many advantages. It will also include where it is lacking and what more need to be addressed. Also includes WebCrypto provides a nice interface for interacting with the native platform security infrastructure.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;This talk is about how CSP and WebCrypto provides security in a web browser. CSP is about securing content from external attacks. It provides explanation about CSP (Content Security Policy) and how it is involving from providing static content security to more dynamic content security via script-hash nonce, SubResource integrity and Per-page suborigins. Via examples it will be shown what cases how these security mechanism secure dynamic content and why these are needed.&lt;/p&gt;

&lt;p&gt;WebCrypto is method through which user data can be used. WebCrypto API allows access to key located on the device and perform operation such as signature generation, hashing, encryption and decryption. WebCrypto provide whole set of new possibility of how information is secured. It will include the use cases for the WebCrypto, algorithm it current supports and examples on how to use WebCrypto in a device.&lt;/p&gt;

&lt;p&gt;The CSP topic is bit of a deviation from the main topic, but WebCrypto is related as it provide layer in software to access key stored in different storage. It is an important abstraction which is vital for web developer to make use of hardware tokens.&lt;/p&gt;

&lt;p&gt;About Me: I am a open source developer, contributing mainly to Chromium in rendering and security areas. I have worked previosuly on EU open source project, Webinos, which used PKI model to store keys and enable communication between the devices.&lt;/p&gt;</description>
        <persons>
          <person id="2710">Habib Virji</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3214">
        <start>14:45</start>
        <duration>00:25</duration>
        <room>AW1.120</room>
        <slug>fuzz_project</slug>
        <title>The Fuzzing Project</title>
        <subtitle>Improving the state of free software security with fuzzing tools</subtitle>
        <track>Security devroom</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;It is surprisingly easy to find memory access violation bugs in all kinds of common Linux tools via very simple fuzzing.
The Fuzzing Project is trying to fix that by systematically fuzzing applications and providing helpful pointers for developers to fuzz their own code.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Fuzzing is an easy strategy to find bugs in software. It works by creating a large number of malformed inputs and see what happens. Crashes usually point to bugs in the memory handling of an application which can often be a sign of potential security bugs.&lt;/p&gt;

&lt;p&gt;Lately a large number of bugs and security issues have been found with fuzzing, many of them in basic and important tools like less, strings, unzip, gnupg, bash and many more. This highlights a pretty dismal state of the security of many key free software projects.&lt;/p&gt;

&lt;p&gt;The talk will give a short introduction to fuzzing with tools like zzuf, american fuzzy lop and Address Sanitizer.&lt;/p&gt;</description>
        <persons>
          <person id="2701">Hanno Böck</person>
        </persons>
        <links>
          <link href="https://fuzzing-project.org/">The Fuzzing Project</link>
          <link href="http://lcamtuf.coredump.cx/afl/">american fuzzy lop</link>
        </links>
      </event>
      <event id="3284">
        <start>15:15</start>
        <duration>00:25</duration>
        <room>AW1.120</room>
        <slug>keysigning</slug>
        <title>Two decades later - Signing OpenPGP keys in the 2000s</title>
        <subtitle>Presenting GNOME Keysign</subtitle>
        <track>Security devroom</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This presentation shows a novel approach to signing keys which makes it easy to sign a person's key.
It enables very small groups of people to casually hold very small key signing parties.
The key idea is to automatically authenticate the key material
before the transfer via a secure audible or visual channel.
A Free Software implementation of the protocol will be shown and people are invited to sign their keys :-)&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The Web of Trust is the decentralised PKI in the OpenPGP world.
It depends on people participating by signing other people's keys.
However, when following best practises, the act of signing a key involves secure transfer of the OpenPGP key which contemporary casual key signing protocols for small groups address by exchanging the fingerprint of the key to be signed.
The key will then be downloaded over an untrusted channel and the key obtained needs to be manually verified.&lt;/p&gt;

&lt;p&gt;The presented solution was designed with Ellison's Law in mind,
which states that ``the userbase for strong cryptography declines by half with every additional keystroke or mouseclick required to make it work''.
It tries to make it as easy as possible to sign another person's key while not compromising security.
Contemporary key signing protocols were designed in the late 90s with big key signing party gatherings in mind.
The setup cost of such an event are prohibitively high for a small group of people.
Because we have arrived in the new millennium, mobile computing devices, link-local networks, cameras, and QR codes exist.
It is time for us to leverage these technologies to strengthen the Web of Trust without having to mumble hexadecimal strings.&lt;/p&gt;</description>
        <persons>
          <person id="2029">Tobias Mueller</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3242">
        <start>15:45</start>
        <duration>00:25</duration>
        <room>AW1.120</room>
        <slug>bifuz</slug>
        <title>BIFUZ</title>
        <subtitle>Broadcast Intent Fuzzing Framework for Android</subtitle>
        <track>Security devroom</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;We have designed and implemented an Intent Fuzzing Framework for Android.
Intents are one of the most important ways used by applications to communicate. They benefit also for a very high level of trust inside the Android OS, so if they are not validated appropriate, they might create an unwanted damage, or might even compromise a mobile device, from Security perspective.
As a term, fuzzing implies manipulating input data, in order to validate it through the mechanism or device under test. It is usually a black-box, negative testing technique, but we have used it as a grey-box method, also.
Knowing how Intents are built, and which type of parameters they accept and expect, we have been able to craft fuzzed Intents, in order to find Security vulnerabilities in the Inter Process Communication protocol.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2684">Razvan-Costin Ionescu</person>
          <person id="2921">Andreea Brindusa Proca</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2741">
        <start>16:15</start>
        <duration>00:25</duration>
        <room>AW1.120</room>
        <slug>sec_enforcement</slug>
        <title>Security enforcement by privilege aware launcher</title>
        <subtitle>Interesting research trial in Tizen security</subtitle>
        <track>Security devroom</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Adding a launcher to a binary allows to control some aspects of its execution environment of the target application.
This is used to change the namespace (view of the filesystem) of the target application at launch time.
An other mechanism is also setup: the process receives (or not) keys that can be checked by other applications for the purpose of controlling authorisations.
When implementing this mechanism, lakes appeared on the extendibility of the /proc kernel's filesystem that we will expose here.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The mainstream user is now accustomed to install applications that declare needing privileges (GPS position, reading contacts, ...).&lt;/p&gt;

&lt;p&gt;This kind of API privileges is hard to guaranty for native applications without a framework that linux does not provide by itself.&lt;/p&gt;

&lt;p&gt;The described framework is made of 3 parts:
 - the installer
 - the launcher
 - the key manager&lt;/p&gt;

&lt;p&gt;The installer is setting the launching mechanic. This is mecanic uses links, security extended attribute, and groups.&lt;/p&gt;

&lt;p&gt;The launcher setups the namespace environment using namespaces and the authorised keys and launches the target application.&lt;/p&gt;

&lt;p&gt;The key manager is a high efficient server that allows any service to ask if a process has a given key.&lt;/p&gt;

&lt;p&gt;The mecanism of the authorisation keys allow privileges to be given once, never or to be asked by some popup daemon.&lt;/p&gt;

&lt;p&gt;The key manager is made using a virtual filesystem implemented using FUSE for prototyping. But the study of this mechanism shown limitations of the /proc kernel filesystem and its link to the LSM. It does not allow to extend the subdirectories /proc/pid with security by process items. The question will be debated.&lt;/p&gt;</description>
        <persons>
          <person id="1784">José Bollo</person>
        </persons>
        <links>
          <link href="https://github.com/jobol/smaunch">secure launcher</link>
          <link href="https://github.com/jobol/keyzen">key manager</link>
        </links>
      </event>
    </room>
    <room name="AW1.121">
      <event id="3302">
        <start>09:00</start>
        <duration>00:05</duration>
        <room>AW1.121</room>
        <slug>intro_geospatial</slug>
        <title>Intro geospatial devroom</title>
        <subtitle/>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;A very short intro from the devroom organisers - who is doing this and what organisations support the initiative.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2381">Johan Van de Wauw</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2807">
        <start>09:05</start>
        <duration>00:10</duration>
        <room>AW1.121</room>
        <slug>lifewatch</slug>
        <title>Use of OSS in the Lifewatch biodiversity research project</title>
        <subtitle/>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract></abstract>
        <description></description>
        <persons>
          <person id="2548">Julien Radoux</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3109">
        <start>09:15</start>
        <duration>00:10</duration>
        <room>AW1.121</room>
        <slug>qgis_landslide</slug>
        <title>QGIS Tool for Landslide Hazard Assessment</title>
        <subtitle/>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In Southern Kyrgyzstan, large areas are affected by high landslide activity, which regularly results in casualties and economic losses. There have been many efforts in the past and the present to analyze landslide activity in this large data-scarce region. Yet there is a need for creating a system capable of integrating all of the existing information and include the possibility for future updates. Due to the limited funds and multiple end users, minimization of costs and flexible accessibility are requirements for such a system opting for the use of open source software.&lt;/p&gt;

&lt;p&gt;The presented tool has been developed as a QGIS plugin. That way, it is possible to take advantage of the core QGIS functionality and other plugins, e.g. the OpenLayers plugin. The plugin allows the user to access the data on landslides, their triggering and predisposing factors in an easy-to-use way. A typical workflow includes querying landslide and factor data for a certain time period and then assigning them to mapping units for further analysis. Besides data queries, the plugin offers tools for spatial analysis, e.g. finding the highest point of the landslide polygon as an approximation of the landslide main scarp, extension of the standard zonal statistics functionality for the derivation of landslide attributes, pixel- or polygon-based calculation of earthquake influence, etc.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2705">Darya Golovko</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2705">
        <start>09:25</start>
        <duration>00:10</duration>
        <room>AW1.121</room>
        <slug>qgis_geopunt</slug>
        <title>Opensource Desktop GIS at Regional and Local goverments in Flanders</title>
        <subtitle>Integrating Govermental webservices into QGIS</subtitle>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;A lightning talk about a plugin for QGIS, open source desktop GIS, that enable users at local governments in Flanders to view, save, analyse and create maps with webservices from the Flemish government. This allows them to use live data instead of downloading files from a webpage.
This includes Geocoding, Points of interest search, Traffic Obstruction data, Elevation Profile and Data search.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2421">Kay Warrie</person>
        </persons>
        <links>
          <link href="http://www.geopunt.be/nl/voor-experts/geopunt-plug-ins">The project description on the site of the Flemish government</link>
          <link href="https://github.com/warrieka/geopunt4Qgis">on github</link>
        </links>
      </event>
      <event id="3155">
        <start>09:40</start>
        <duration>00:25</duration>
        <room>AW1.121</room>
        <slug>bridging_simulation_gis</slug>
        <title>Bridging the gap between simulation and GIS</title>
        <subtitle/>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Polygonal meshes are the most common way of representing 2D geometries for simulation purposes. Integrating simulation to a GIS requires  storing georeferenced meshes in a databases (or using standard SIG file formats), and being able to use simulation values interpolated over the elements as a map layer.&lt;/p&gt;

&lt;p&gt;This presentation reviews what is the closest you can get with existing FOSS GIS solutions and what is needed to bridge the gap, both on the simulation side and on the GIS side.&lt;/p&gt;

&lt;p&gt;We show the few lines that need to be added to the simulation code to read a mesh from the GIS and write the results to the GIS. We also present a prototype mesh layer for QGIS that has been implemented as a PluginLayer.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2775">Vincent Mora</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3016">
        <start>10:10</start>
        <duration>00:20</duration>
        <room>AW1.121</room>
        <slug>grass_7</slug>
        <title>GRASS GIS 7: Efficiently processing big geospatial data</title>
        <subtitle/>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;You see beautiful maps every day, you use geospatial data every day but do you know what's behind processing all the big geospatial data? With the advent of open geospatial data in Europe new opportunities arise. In our presentation we show GRASS GIS (Geographic Resources Analysis Support System, http://grass.osgeo.org), a software suite for geospatial data management and analysis, image processing, graphics and map production, spatial modeling, and visualization. The software has been developed as FOSS for more than 30 years by a large community of developers and users.
After six years of development and a long beta release cycle the new stable GRASS GIS 7.0 release is imminent. GRASS GIS 7 is rich in functionality, it offers e.g. enhanced vector network analysis, voxel processing, support for massive time series data management, an animation tool for raster and vector map time series, a graphical image classification tool, and a "map swiper" for interactive maps comparison. The software is portable among most operating systems including GNU/Linux, Mac OSX, FreeBSD, AIX, SUN Solaris, other Unix based, and MS-Windows.&lt;/p&gt;

&lt;p&gt;GRASS GIS 7 offers a new Python API (PyGRASS) for rapid development of workflows. For working teams, it supports shared data management on networks. It can be used as a geoprocessing backend for Web Processing Service (OGC WPS). For statistics, it comes with an interface to R statistics.&lt;/p&gt;

&lt;p&gt;In our research context, we use GRASS GIS extensively for massive geospatial data analysis on a high-performance computing system (HPC). In our presentation, we illustrate workflows and results using "EuroLST" temperature dataset (http://gis.cri.fmach.it/eurolst/) as an example of data in the multi-terabyte range.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2686">Markus Neteler</person>
        </persons>
        <links>
          <link href="http://grass.osgeo.org">GRASS GIS Website</link>
        </links>
      </event>
      <event id="3019">
        <start>10:30</start>
        <duration>00:15</duration>
        <room>AW1.121</room>
        <slug>grass_api</slug>
        <title>GRASS Development APIs</title>
        <subtitle>Lifting the fog on the different ways to develop for GRASS</subtitle>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;GRASS offers different APIs that allows interested developers to contribute. From the core C-API to the very lightweight Python scripting library, each plays a different role and their coexistence can cause some confusion. This lightning talk aims at clarifying the role of each of these APIs.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;GRASS is originally a C project. However, there has always been command line scripting and some of these scripts have been integrated into the core distribution. With the upcoming GRASS 7, Python has been chosen to replace bash as the main scripting environnement, based on a lightweight scripting library leveraging the modular character of GRASS. At the same time, the need was felt by some to dispose of a more low-level access to GRASS functionality in Python. This has led to the development of pygrass, based on ctypes, which provides as more complete, more pythonic, object-oriented approach to GRASS script programming.&lt;/p&gt;

&lt;p&gt;This talk will briefly introduce the different APIs and explain different use-cases and user-types for each of them.&lt;/p&gt;</description>
        <persons>
          <person id="2704">Moritz Lennert</person>
        </persons>
        <links>
          <link href="http://grass.osgeo.org/">GRASS project homepage</link>
          <link href="http://grass.osgeo.org/programming7/">GRASS Programmer's Manual (C-API)</link>
          <link href="http://grass.osgeo.org/grass71/manuals/libpython/">GRASS Python library</link>
        </links>
      </event>
      <event id="3177">
        <start>10:50</start>
        <duration>00:25</duration>
        <room>AW1.121</room>
        <slug>openstandards_biggeodata</slug>
        <title>Open Standards for Big Geo Data</title>
        <subtitle/>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In Geo service terminology, coverages represent spatio-temporally varying phenomena, such as sensor, image, simulation, and statistics data; incidentally, these typically are prime Big Data contributors in practice. The OGC unified coverage model encompasses regular and irregular grids, point clouds, and general meshes. As opposed to the (abstract) coverage model of ISO 19123, the (concrete) OGC coverage and service model establishes verifiable interoperability while still grounding on ISO 19123. The OGC Web Coverage Service (WCS) comprises a modular suite for accessing large coverage assets. WCS Core provides simple data subsetting whereas extensions add optional service facets up to ad-hoc filtering and processing.&lt;/p&gt;

&lt;p&gt;By separating coverage data and service model, any service - such as WMS, WFS, SOS and WPS - can provide and consume coverages in addition to WCS. Generally, the WCS suite is appreciated by implementers due to its clear structuring and concise conformance testing, down to pixel/voxel level. Many WCS implementations are available today, such as rasdaman which has proven efficient on 130+ TB datacubes.&lt;/p&gt;

&lt;p&gt;In our talk, we present the OGC coverage data and service model with an emphasis on practical aspects. Presentation will make use of available services allowing participants to recapitulate many of the facets addressed.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2782">Peter Baumann</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3195">
        <start>11:20</start>
        <duration>00:25</duration>
        <room>AW1.121</room>
        <slug>scotty</slug>
        <title>Scotty, I need a data in three minutes! (Or we're all dead!!)</title>
        <subtitle>Just the right data at just the right time</subtitle>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Technology change has created an inflection point for geodata. Mobile devices, social media, retail transactions, and more generate a tremendous amount of data. The volume, variety, and velocity of data is ever increasing. What do we do about it?&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Technology change has created an inflection point for geodata. Mobile devices, social media, retail transactions, and more generate a tremendous amount of data. The volume, variety, and velocity of data is increasing. New technologies are being developed to handle the huge amounts of data. The problem is more complex than simply having a big relational database. This talk will present an overview of open source geospatial technologies which enable big geodata on the server and little geodata on devices and other clients to make it useful with the right context at the right time. More than technology for technology's sake, use it to do something meaningful.&lt;/p&gt;</description>
        <persons>
          <person id="2789">Andrew Ross</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3113">
        <start>11:50</start>
        <duration>00:25</duration>
        <room>AW1.121</room>
        <slug>geotrellis_spark</slug>
        <title>Distributed tile processing with GeoTrellis and Spark</title>
        <subtitle/>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;GeoTrellis is a geospatial Scala library and framework for doing high performance geospatial processing in a distributed environment. This past year the developers of GeoTrellis have created extensions to the Apache Spark cluster computing platform to ingest and process raster data stored in Accumulo and HDFS. Spark and GeoTrellis can be used to process and serve raster data through web services to create TMS tile layers that can be used on web maps. The framework can work with both spatial-only tiles, as well as spatial-temporal tiles such as climate model data.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;In this talk I'll describe the process of using GeoTrellis to ingest raster data into Accumulo, and give examples of how we can manipulate that data using spark. I will go into the architecture of the GeoTrellis core library, and how it leverages the powerful type system of Scala to make geospatial coding a lot easier. I will go into the architecture that has allowed us to geospatially enable the Apache Spark clustering engine, the difficulties we faced while working with the 3 libraries, and how we overcame those challenges. I will demonstrate working with both spatial-only and spatio-temporal raster data using the framework on an AWS cluster with Spark and Accumulo.&lt;/p&gt;</description>
        <persons>
          <person id="2755">Rob Emanuele</person>
        </persons>
        <links>
          <link href="http://lossyrob.github.io/talk-distributed-tile-processing/">The slides for a previous version of the talk I did for a Philadelphia geospatial conference.</link>
        </links>
      </event>
      <event id="3150">
        <start>12:15</start>
        <duration>00:10</duration>
        <room>AW1.121</room>
        <slug>geotrellis_geotiff</slug>
        <title>GeoTrellis and the GeoTiff File Format</title>
        <subtitle/>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;A short talk about GeoTrellis and the GeoTiff File Format. I was a Google Summer of Code student at GeoTrellis and implemented a GeoTiff reader for the project. I will present what GeoTrellis is, how I implemented the GeoTiff reader and talk a bit about the GeoTiff File Format and which compressions that are associated with it.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2745">Johan Stenberg</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3171">
        <start>12:30</start>
        <duration>00:10</duration>
        <room>AW1.121</room>
        <slug>habitat</slug>
        <title>Habitat - a programmable personal geospatial datatore</title>
        <subtitle/>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Habitat is a proof of concept project to re-purpose Cucumber style tests to process data about your location. Implemented in Python using Celery, Behave and Flask.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2780">Richard Pope</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2762">
        <start>12:45</start>
        <duration>00:25</duration>
        <room>AW1.121</room>
        <slug>daybed</slug>
        <title>Daybed</title>
        <subtitle>spatial backend as a service !</subtitle>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Daybed is a reusable Web API providing validation and storage as a service. Define your schemas, their fields and permissions using JSON, and you obtain a dedicated RESTful endpoint! It has spatial fields support, GeoJSON output and ElasticSearch indexing!&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Usually, when a Web application requires a spatial backend for storage and validation, a custom API is developed and deployed (reinvent the wheel).&lt;/p&gt;

&lt;p&gt;But with Daybed, persistence is a service. It's a minimalist and generic REST API, built with python, on top of the storage backend of your choice, like Redis, CouchDB or ElasticSearch. You can host it yourself or use the one we run at https://daybed.io!&lt;/p&gt;

&lt;p&gt;In this talk, we will present why Daybed is the perfect component for rapid application building, and how it can be used for collecting and storing geospatial data. A quick overview of its authentication and permissions system, and you will figure out you can turn any mobile app or static Web page into a collaborative application with no effort!&lt;/p&gt;

&lt;p&gt;We will also introduce daybed.js, our tiny JavaScript wrapper, to visualize data or build collaborative webmapping with only a few lines of code!&lt;/p&gt;</description>
        <persons>
          <person id="2484">Mathieu Leplatre</person>
        </persons>
        <links>
          <link href="http://spiral-project.github.io/daybed.js/examples/leaflet/">Simple Leaflet example</link>
          <link href="http://spiral-project.github.io/daybed.js/examples/spatial-search/ ">ElasticSearch bbox search</link>
          <link href="http://spiral-project.github.io/daybed-map/">Build your own map</link>
          <link href="http://spiral-project.github.io/formbuilder/">Daybed form builder</link>
        </links>
      </event>
      <event id="3254">
        <start>13:15</start>
        <duration>00:25</duration>
        <room>AW1.121</room>
        <slug>geomajas</slug>
        <title>Taking Web GIS beyond Google Maps with the Geomajas Client and Spatial Application Server</title>
        <subtitle>Mapping stuff with Java, GWT and Javascript</subtitle>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In this talk we walk you through the Geomajas web GIS framework. Main focus is on what it does today and where we see it heading in the future.
What is Geomajas and what can I do with it?
What are the main Geomajas projects and components?
Which libraries and tools are used?
How can I integrate it in existing applications and/or solutions?&lt;/p&gt;

&lt;p&gt;A must-attend session for all those interested in advanced web mapping using Java / GWT / Javascript.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2815">Frank Maes</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2961">
        <start>13:45</start>
        <duration>00:25</duration>
        <room>AW1.121</room>
        <slug>glob3</slug>
        <title>Mobile Map Technology</title>
        <subtitle>Developing Mobile Multiplatform 3d maps</subtitle>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The main capability of this library is the Multiplatform approach, it have the very same API in all environments thanks to coding translation.
Developing with Glob3 Mobile you can save time and resources when you face a mobile development having all advantages of native development (Performance, UI, Access to disk, sensors, etc) and the simplicity of an API thought for GIS developers.
During 2013-2014 G3M has been growing in capabilities and is now a solution to face the development of any map application on any device. In this presentation We will explain the architecture and the main capabilities of this library and we will show some examples and demos and use cases with the API working.
Glob3 Mobile has been developed thinking in the usability and the UI of mobile devices. Currently Glob3 Mobile is working in the next platforms: * iOS * Android * Google Glass * html5-webgl and it is planned to add others like Windows 8 or Java Desktop.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The main capability of this library is the Multiplatform approach, it have the very same API in all environments thanks to coding translation.
Developing with Glob3 Mobile you can save time and resources when you face a mobile development having all advantages of native development (Performance, UI, Access to disk, sensors, etc) and the simplicity of an API thought for GIS developers.
During 2013-2014 G3M has been growing in capabilities and is now a solution to face the development of any map application on any device. In this presentation We will explain the architecture and the main capabilities of this library and we will show some examples and demos and use cases with the API working.
Glob3 Mobile has been developed thinking in the usability and the UI of mobile devices. Currently Glob3 Mobile is working in the next platforms: * iOS * Android * Google Glass * html5-webgl and it is planned to add others like Windows 8 or Java Desktop.
Currently also g3m has been used as offline AR engine for wearable devices. The capabilities list is huge but the main are: * Raster data * Vectorial data * Point Clouds * 3D models (Buildings, cities, vehicles, ...) * 4D Data * Real Time * Simbology * Offline - Online -&gt; Cache Handling * 3D- 2D - 2,5D views * Scenarios * Animations * Cameras * Tasks
During 2014 Glob3 Mobile will become part of Location Tech (Eclipse Foundation) and will change the name and license: Glob3 Mobile --&gt; Mobile Map tools BSD -&gt; EPL A different use cases of Mobile Map Tools. Vazz: vazz.tv/start Galileo: galileo.glob3mobile.com galileo.mobilemaptools.com Aero Glasses: glass.aero/&lt;/p&gt;

&lt;p&gt;Mobile Map Tools is a library to build Native Mobile Map Apps. Visualize huge points cloud in a 3D environment is a hard task that could be face using a server-client approachment.&lt;/p&gt;

&lt;p&gt;This library has the following capabilities:&lt;/p&gt;

&lt;p&gt;Very big point cloud could be served using a streamed format&lt;br/&gt;
The points serverd save the shape of the cloud
Using LoD techniques and MMT you can see the point cloud in 3D on any mobile device or web page.
The point cloud must be pre-processed
The software developed to show this data is:&lt;/p&gt;

&lt;p&gt;A tool to import the point cloud in it's different formats
A library to save this data in a Berkeley DB
A library to pre-process fastly this points
A server to give the appropiate points to the client app
A live demo will be done during the session.&lt;/p&gt;

&lt;p&gt;Mobile Map Technology is a library developed by Glob3 Mobile Inc, and is under the Location Tech's umbrella.&lt;/p&gt;</description>
        <persons>
          <person id="2664">Manuel de la Calle Alonso</person>
        </persons>
        <links>
          <link href="http://www.glob3mobile.com">http://www.glob3mobile.com</link>
          <link href="http://pointserver.xyz">http://pointserver.xyz</link>
          <link href="https://github.com/glob3mobile">https://github.com/glob3mobile</link>
        </links>
      </event>
      <event id="2671">
        <start>14:15</start>
        <duration>00:10</duration>
        <room>AW1.121</room>
        <slug>potree</slug>
        <title>Potree - Rendering Large Point Clouds in Web Browsers</title>
        <subtitle/>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Introducing potree, an open source WebGL based point cloud renderer for large data sets.
By loading and rendering only visible regions up to a certain level of detail, hundreds of milions of points can be rendered in real time inside web browsers.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2393">Markus Schütz</person>
        </persons>
        <links>
          <link href="http://potree.org">project page</link>
          <link href="https://github.com/potree/potree">source code</link>
          <link href="https://www.youtube.com/watch?v=l_XuZ84KyGM">demo video</link>
        </links>
      </event>
      <event id="3089">
        <start>14:30</start>
        <duration>00:25</duration>
        <room>AW1.121</room>
        <slug>ol3js</slug>
        <title>OpenLayers 3: A unique web-mapping library</title>
        <subtitle/>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;OpenLayers 3 is the new version of the OpenLayers web-mapping library. We've rewritten the library from the ground up with the goal of offering a powerful, high-performance library leveraging the latest in web technologies such as Canvas and WebGL. This talk will present the latest advances of the library, focusing on aspects that make OpenLayers 3 stand out. OpenLayers 3, for example, uses techniques and algorithms that enable high-quality and high-performance vector rendering. Come learn about the optimizations and techniques OpenLayers 3 uses internally, and what makes OpenLayers 3 unique among its competitors.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2744">Éric Lemoine</person>
        </persons>
        <links>
          <link href="http://openlayers.org">OpenLayers website</link>
        </links>
      </event>
      <event id="2871">
        <start>14:55</start>
        <duration>00:15</duration>
        <room>AW1.121</room>
        <slug>ol3js_cesium</slug>
        <title>Ol3-Cesium : 3D for OpenLayers map</title>
        <subtitle>An exciting library for automatically bringing 3D to your map</subtitle>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;[Ol3-Cesium][https://github.com/openlayers/ol3-cesium] is a web library for binding an [OpenLayers3][http://openlayers.org/] map and a [Cesium][http://cesiumjs.org/] globe together.
The 3D globe is automatically set up from the OpenLayers3 map and the library takes care of synchronizing and switching between the map and the globe.
Both raster and vector layers from the map are displayed on the globe; features are positioned in 3D and styled like in the map.
Terrain and additional data may be added to the globe and advanced use is possible using the exported core functions.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;[Ol3-Cesium][https://github.com/openlayers/ol3-cesium] is an exciting web library bringing 3D to an [OpenLayers3][http://openlayers.org/] map.
A [Cesium][http://cesiumjs.org/] virtual globe is automatically created from the map and displayed side-by-side for collaborative interaction or stacked for exclusive tasks.
The globe camera and the map view (centre, resolution, rotation) are bidirectionally synchronized: interacting on one updating the other.&lt;/p&gt;

&lt;p&gt;Layers are synchronized from the map:
- ol3 raster layers show up on the globe and reuse cache when possible;
- ol3 vector layers render using the same style and may be positioned freely in 3D.
Additionally, specific data may be displayed on the globe, like terrain or vectors.&lt;/p&gt;

&lt;p&gt;Vectors are re-projected on-the-fly during synchronisation.
Since one synchronizer may not fit all needs, the library exports core functions to allow advanced or custom use.&lt;/p&gt;</description>
        <persons>
          <person id="2430">Guillaume Beraudo</person>
        </persons>
        <links>
          <link href="http://openlayers.org/ol3-cesium/examples/">Demo on project page</link>
          <link href="http://www.camptocamp.com/actualite/ol3-cesium-open-source-release/ ">CampToCamp announcement</link>
          <link href="https://github.com/openlayers/ol3-cesium">Source code</link>
          <link href="http://cesiumjs.org/2014/11/18/OpenLayers3-adds-Cesium/">Blog on Cesium</link>
        </links>
      </event>
      <event id="2984">
        <start>15:15</start>
        <duration>00:25</duration>
        <room>AW1.121</room>
        <slug>overpass</slug>
        <title>Overpass API</title>
        <subtitle>A service to query OpenStreetMap data</subtitle>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Using OpenStreetMap data almost always requires filtering for thematic extracts. Overpass API is a web service for this purpose, available at overpass-api.de. Its source code is licensed under AGPL.&lt;/p&gt;

&lt;p&gt;The open data project OpenStreetMap aims at creating a geographic database of the entire world, i.e. collecting the data necessary to make any map of what is on the ground. Starting in 2004, it has now grown to more than a million registered mappers. In most places details are mapped including each footpath. In some places even streetlamps, trees, wastebaskets, and similar things are mapped.&lt;/p&gt;

&lt;p&gt;Overpass API allows you to extract data by geographic search criteria, by subject, by structual properties or an arbitrary combination of them. In this way you can realize an always up-to-date data overlay on a slippy map, a desktop data browser, conveniently pull data from OpenStreetMap into QGIS, do quality assurance or a lot of other things.&lt;/p&gt;

&lt;p&gt;In this talk I will present Overpass API by the above mentioned example use cases. Furthermore, I will give a short overview over the components and the query language. This gives you a starting point to integrate OpenStreetMap data into your application of choice.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2680">Roland Olbricht</person>
        </persons>
        <links>
          <link href="http://wiki.openstreetmap.org/wiki/Overpass_API">Documentation</link>
          <link href="http://overpass-api.de">Public instance</link>
        </links>
      </event>
      <event id="3157">
        <start>15:45</start>
        <duration>00:25</duration>
        <room>AW1.121</room>
        <slug>tempus</slug>
        <title>Tempus: a framework for multimodal trip planning</title>
        <subtitle/>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Open source engines for trip planning are growing in popularity. We are part of the movement by creating our own engine and a framework for the development of new algorithms.
Tempus focuses on planning trips that involve all possible transport modalities, mixing private and public modes as well as shared vehicles, and on requests with multiple objectives.
It relies on well-known open source components and standards like PostGIS, QGIS, WPS, boost graph and offers tools for importing routing data from various sources, including OpenStreetMap.
This presentation will illustrate the overall modular architecture of Tempus built around a C++ core and give some insights on how to use it either as a user or as a developer of planning algorithms.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2773">Hugo Mercier</person>
        </persons>
        <links>
          <link href="https://github.com/ifsttar/Tempus">Github project repository</link>
        </links>
      </event>
      <event id="2672">
        <start>16:15</start>
        <duration>00:25</duration>
        <room>AW1.121</room>
        <slug>douglas_peucker</slug>
        <title>Douglas-Peucker updated</title>
        <subtitle>or do you want to reduce your data</subtitle>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Douglas-Peucker from the early '70 delivers excellent quality, but requests to have a polyline from start to end before reduction can start. In this modified algorithm there is no need to store all points, or to wait until the end of the polyline happens.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;For embedded system it is not practical to have to store all points of a polyline before being able to reduce the number of points. The modified algorithm describes a way to decide on the go which points are essentials (and need to be stored). With the Douglas_Peucker two criteria can be used : the maximum number of points to retain, or the maximum error tolerated. In the modified algorithm only the max error tolerated can be being. Because the algorithm cannot predict the future length of the polyline, it's not possible to apply the maximum number of points. Examples shown contains 2D and 3D cases, in comparison with the Douglas-Peucker algorithm. A brief description will introduce the same concept of the modified algorithm in time related measurements.&lt;/p&gt;</description>
        <persons>
          <person id="2396">Stephane Winnepenninckx</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3008">
        <start>16:45</start>
        <duration>00:10</duration>
        <room>AW1.121</room>
        <slug>picotcp_networks</slug>
        <title>PicoTCP on Mobile Ad Hoc networks</title>
        <subtitle/>
        <track>Geospatial</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In the growing world of the Internet of Things, gathering data from small devices is becoming more and more important. picoTCP is a dual licence open source networking stack specifically designed to target small embedded devices and facilitates a modular way to select support for different networking protocols. Recently a mesh networking solution was added to the stack, enabling support for MANETs as an additional solution for embedded networking problems. In the presentation we will point out the reasoning behind this solution, explain how to use it and show a real implementation example on a physical network.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Introduction:
In a world where even the smallest electronic devices have the ability to acquire huge amounts of data which is only relevant when it can be shared to other instances. The demand to make them interconnected is exponentially growing. While the on-board resources of these small and cheap sensor devices/nodes are growing, it has become possible to tackle such networking requirements. The possibilities of a network, consisting of such nodes, which is self configuring and highly adaptable in topology instantly become endless(see Mobile Ad Hoc Networks a.k.a. MANET). Because every node should act independent from one another and it's not mandatory for two nodes in the network to have direct Line Of Sight(LOS) connection, ad hoc wireless networks can't rely on a centralized gateway to configure and manage the network traffic. The traditional wireless networking/routing protocols are not able to comply to these needs, so another approach was required to be designed.&lt;/p&gt;

&lt;p&gt;MANET routing Challenges:
The requirements of a simple MANET on sensor nodes is by itself quite complex due to their dynamic nature. Depending on the requirements of the application it can be useful to make network topology discovered proactive or reactive. In other words one could ask the question, does a node need to have the route to his destination available when transmitting a message or can it be obtained on the fly? This naturally creates a higher latency than when a route is proactively defined and stored. This would be the case in a table driven approach which regularly exchanges topology info. In contrast, it's obvious that reactive routing protocols will respond faster on topology changes than protocols that are relying on their legacy proactive routing tables. And then there is chance to flood the network! What if for every packet sent over the network, information about the topology has to be obtained as is the case with reactive routing protocols. This will intensively decrease the throughput of the mesh network.
So, a lot of open questions need to be answered in order to optimize mesh networking on sensor nodes. So the brains of routing protocol designers started grinding to concur these challenges! As a result several RFC's on routing protocols have been designed during the last years. Two examples worth mentioning are "Optimized Link State Routing"(OLSR) and "Ad hoc On-Demand Vector routing"(AODV). These are respectively proactive and reactive routing protocols.&lt;/p&gt;

&lt;p&gt;MAC and PHY:
One should always keep in mind that in networking context the software solutions are constrained by the hardware they are targeting. There are several PHY and MAC layer possibilities of which the following two are frequently used in the mesh networking field. First we have the IEEE802.11 collection of standards which is also known as wifi, and mostly focused on high data rates. Second there is the IEEE802.15.4 standard which is the basis for Zigbee, 6LoWPAN, etc. The latter focuses more on low power devices. Depending on the needs of the application or the compliance required, the one can be preferred above the other.&lt;/p&gt;

&lt;p&gt;Routing Protocol:
Because picoTCP already supports IPv4 (more info at www.picotcp.com), the step towards developing a mesh networking solution was obvious. So the next problem was to select the best fitting protocol to our current stack implementation and mesh networking goals. Since we take RFC compliance very serious which implies that for IPv4 all devices should be able to handle a minimal datagram size of 576 bytes, the best wireless standard for IPv4 will be the 802.11 standard(wifi). Since this standard is mostly focused on high data rates, the focus went to protocols that provide high throughput and low latency behavior. From all these restrictions we came to the OLSR protocol as best fitting solution.&lt;/p&gt;

&lt;p&gt;OLSR or Optimized Link State Routing protocol is a proactive routing protocol that uses 4 types of OLSR messages to establish the link state routing tables for every node. Every OLSR supporting node will send "HELLO" messages to its neighbors to find his one hop neighbors and two hop neighbors from the responses. The router between a two hop neighbor, or multipoint relay(MPR), is to be selected by each node and added to his MPR-selector set. Only the nodes selected as MPR are responsible to send "Topology Control" (TC) messages that contain a set of links to at least all nodes in his MPR-selector set. Network flooding is optimized, because only MPRs are sending TC messages and they are using their MPRs to broadcast the towards the reset of the network, hence the Optimization in OLSR. The third type of messages are the "Multiple Interface Declaration" (MID) messages, used to transmit information about its interfaces if the node has more than one. The last message type, used in OLSR, are the "Host and Network Association" (HNA) messages, which enable the ability to inject external routing information into the MANET.&lt;/p&gt;

&lt;p&gt;Slot:
This was a summary about how picoTCP supports mesh networking, and why picoTCP has preferred OLSR as mesh routing protocol. In the presentation we will go deeper into how to use picoTCP and the several ways we simulate mesh network behavior(including a custom created Geomesh simulator and the Contiki Cooja simulator). To finalize, the results of a real life implementation on the physical Wilab-t mesh network, located at Ghent University will also be explained.&lt;/p&gt;</description>
        <persons>
          <person id="2663">Brecht Van Cauwenberghe</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="AW1.124">
      <event id="2943">
        <start>10:00</start>
        <duration>00:30</duration>
        <room>AW1.124</room>
        <slug>qucs_overview</slug>
        <title>Qucs: overview, status and roadmap</title>
        <subtitle/>
        <track>Electronic design automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This talk presents Qucs (Quite Universal Circuit Simulator) features, the current status of development and the project roadmap.&lt;/p&gt;

&lt;p&gt;Qucs is an integrated circuit simulator. The graphical user interface (GUI) is used for schematic capture and visualization of simulation results. It can simulate the large-signal, small-signal and noise behavior of the circuit. The software aims to support all kinds of circuit simulation types such as DC, AC, transient, S-parameter, noise analysis, harmonic balance analysis. Digital simulation and circuit optimization are integrated into the GUI and powered by other open-source tools (Icarus-Verilog, freeHDL, ASCO). Besides the library of components it also includes tools for the design of active and passive filters, transmission lines, attenuators and matching circuits. Interfaces for Matlab/Octave and Python are also available.&lt;/p&gt;

&lt;p&gt;The talk will provide an overview of the features and available tools along with a selection of examples. It will present the latest developments including: migration towards the latest Qt framework; new features related to the “turn-key” Verilog-A (ADMS) model compiler as well as support for other simulation engines (ngspice). The project goals are ambitious. This talk aims at presenting what Qucs can offer as well as tease the audience into thinking what is achievable with the open-source EDA tools available today.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2645">Guilherme Brondani Torri</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3060">
        <start>10:35</start>
        <duration>00:30</duration>
        <room>AW1.124</room>
        <slug>ngspice</slug>
        <title>The NGSPICE circuit simulator</title>
        <subtitle>An open platform for simulation and modelling</subtitle>
        <track>Electronic design automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Ngspice project started in 1999 from the latest implementation of of Berkeley's SPICE3 release. In more than a decade of development it has fixed and upgraded it.  Parallel execution of device code has been implemented to reduce simulation time for transient analysis. Two implementations are available: using OpenMP and CUDA. The KLU solver has been implemented to reduce simulation time of large circuits. Verilog-A models can be included at compile time using the ADMS model compiler.  This presentation will show an overview on the simulator status focusing on the major improvements over the original SPICE3 code.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2610">Paolo Nenzi</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2945">
        <start>11:10</start>
        <duration>00:15</duration>
        <room>AW1.124</room>
        <slug>compact_spice_modeling</slug>
        <title>FOSS CAD for Compact/SPICE Modeling</title>
        <subtitle/>
        <track>Electronic design automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Compact/SPICE models of circuit elements (passive, active, MEMS, RF) are essential to enable advanced IC design using nanoscaled semiconductor technologies. Compact/SPICE models are also a communication means between the semiconductor foundries and the IC design teams to share and exchange all engineering and design information. To explore all related interactions, we are discussing selected FOSS CAD tools along complete technology/design tool chain from nanascaled technology processes; thru the compact modeling; to advanced IC transistor level design support. New technology and device development will be illustrated by application examples of the FOSS TCAD tools: Cogenda TCAD and DEVSIM. Compact modeling will be highlighted by review topics related to its parameter extraction and standardization of the experimental and measurement data exchange formats. Finally, we will present two FOSS CAD simulation and design tools: ngspice and Qucs. Application and use of these tools for advanced IC design (e.g. analog/RF IC applications) directly depends the quality of the compact models implementations in these tools as well as reliability of extracted models and generated libraries/PDKs. Discussing new model implementation into the FOSS CAD tools (ngspice and Qucs as well as others) we will also address an open question of the compact/SPICE model Verilog-A standardization. We hope that this presentation will be useful to all the researchers and engineers actively involved in the developing compact/SPICE models as well as designing the integrated circuits in particular at the transistor level and then trigger further discussion on the compact/SPICE model Verilog-A standardization and development supporting FOSS CAD tools.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;FOSS CAD for Compact/SPICE Modeling
W.Grabinski and D.Tomaszewski&lt;/p&gt;</description>
        <persons>
          <person id="2648">Wladek Grabinski</person>
        </persons>
        <links>
          <link href="http://www.mos-ak.org/berkeley_2014/">FOSS CAD Session at MOS-AK/Berkeley</link>
          <link href="http://www.mos-ak.org/books/CAD_CM_Book.php">BOOK: FOSS CAD for compact modeling</link>
        </links>
      </event>
      <event id="3386">
        <start>11:30</start>
        <duration>00:25</duration>
        <room>AW1.124</room>
        <slug>analog_sim_panel</slug>
        <title>Panel Discussion on Analog Simulation</title>
        <subtitle/>
        <track>Electronic design automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;A panel discussion covering subjects related to analog circuit simulation tools. Future Verilog-A efforts will be covered. Panel members include all speakers from the analog simulation session immediately preceding the panel discussion.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2610">Paolo Nenzi</person>
          <person id="2645">Guilherme Brondani Torri</person>
          <person id="2648">Wladek Grabinski</person>
          <person id="2651">Francesco Lannutti</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2834">
        <start>12:00</start>
        <duration>00:30</duration>
        <room>AW1.124</room>
        <slug>ghdl</slug>
        <title>GHDL: a libre VHDL simulator</title>
        <subtitle/>
        <track>Electronic design automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Short presentation of GHDL, followed by a discussion.&lt;/p&gt;

&lt;p&gt;GHDL is a libre VHDL simulator.  It compiles a design using the gcc or llvm backend.  GHDL fully implements VHDL-87, VHDL-93, VHDL-02 and partially VHDL-08.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2958">Tristan Gingold</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2936">
        <start>12:35</start>
        <duration>00:15</duration>
        <room>AW1.124</room>
        <slug>icarus_vhdl</slug>
        <title>Adding VHDL support to Icarus Verilog</title>
        <subtitle/>
        <track>Electronic design automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Have you ever wondered how simulators perform their tasks? Are you
looking for a FOSS replacement for your proprietary simulator?&lt;/p&gt;

&lt;p&gt;Icarus Verilog is a part of gEDA project. It is mostly known as a FOSS
hardware description language simulator, although its capabilities
reach beyond that. The name indicates it is a Verilog simulator, many
features of SystemVerilog are already implemented and VHDL makes its
way there.&lt;/p&gt;

&lt;p&gt;If you want to hear about what else you can achieve with Icarus, how
its internal gears are running, or possible ways to extend its
functionality - feel invited.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2640">Maciej Sumiński</person>
        </persons>
        <links>
          <link href="http://iverilog.icarus.com/">Icarus Verilog official website</link>
        </links>
      </event>
      <event id="2939">
        <start>12:55</start>
        <duration>00:15</duration>
        <room>AW1.124</room>
        <slug>ohr_fpga</slug>
        <title>High-Level Open/Free FPGA development tools from OHR.</title>
        <subtitle>From production grade HDL synthesis/simulation automation to graphical DSP and beyond</subtitle>
        <track>Electronic design automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;FPGA features and resources had dramatically increased in the last years. State-of-the-art devices are now too complex to be tackled by a single individual by using standard HDL tools.&lt;/p&gt;

&lt;p&gt;The OHR community hosts and maintains a set of Free/Open high-level FPGA development tools that aims both to increase productivity and to empower resource and knowledge sharing.&lt;/p&gt;

&lt;p&gt;This tutorial provides a short introduction &amp;amp; demo for two of the main HDL tools at OHR (HDLMake and Libre-FDATool) and finally introduces some of the hottest trends in high-level FPGA design tools.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;This tutorial consist in three different blocks, one for each of the featured tools and a final one is left for conclusion and Q&amp;amp;A.&lt;/p&gt;

&lt;h1&gt;Featured Tools:&lt;/h1&gt;

&lt;h2&gt;HDLMake:&lt;/h2&gt;

&lt;p&gt;Hdlmake generates multi-purpose makefiles for HDL projects management. It supports local and remote synthesis, simulation, fetching module dependencies from repositories, creating project for multiple FPGA toolchains... All of this can be done with a makefile command or with Hdlmake directly. It supports modularity, scalability, use of revision control systems and code reuse. Hdlmake is free, open and distributed under the GPL license.&lt;/p&gt;

&lt;h2&gt;Libre-FDATool:&lt;/h2&gt;

&lt;p&gt;Libre-FDATool is a Python package aimed at helping in the analysis and design of HDL filters from high-level specifications. This Free/Libre Open Source software supports both VHDL and Verilog code generation and relies on a collection of Free scientific and EDA tools for providing advanced features -- simulation, graphics, debugging, etc.&lt;/p&gt;

&lt;h1&gt;Conclusions / Beyond HLS:&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;State-of-the-Art: new All-programmable SoCs, HLS (High-Level Synthesis) tools for FPGA, HW code accelerators...&lt;/li&gt;
&lt;li&gt;Operating System and HDL as a whole. The gateware part of an hybrid CPU+FPGA system can be handled by the Operating System just as a standard dynamic library. Proof of concept: "meta-spec", Yocto Project support for OHR SPEC (Simple PCI Express FMC Carrier).&lt;/li&gt;
&lt;/ul&gt;
</description>
        <persons>
          <person id="2642">Javier D. Garcia-Lasheras</person>
        </persons>
        <links>
          <link href="http://www.ohwr.org/projects/hdl-make/wiki">HDLMake wiki</link>
          <link href="http://www.ohwr.org/projects/libre-fdatool/wiki">Libre-FDATool wiki</link>
          <link href="http://www.ohwr.org/projects/meta-spec/wiki">Yocto Project support for SPEC</link>
        </links>
      </event>
      <event id="3125">
        <start>13:15</start>
        <duration>00:15</duration>
        <room>AW1.124</room>
        <slug>bambu</slug>
        <title>Synthesizing gateware with GCC</title>
        <subtitle>Bambu: A Free Framework for the  High-Level Synthesis of Complex Applications</subtitle>
        <track>Electronic design automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Programmable devices such as FPGAs can potentially offer very significant computational power, but implementing efficient solutions on them can be a hard task. One
of the main obstacles is the usage of hardware description language (HDL), whose knowledge is usually a rare expertise.
To overcome or at least to mitigate this issue, High Level Synthesis (HLS) has been introduced: a (semi)-automatic design flow, potentially composed of several methodologies, that
starting from a high level representation of the specification to be implemented (e.g., from its C/C++ source code implementation) produces its hardware implementation.
This talk presents Bambu a free HLS tools based on GCC developed at Politecnico di Milano, that generated synthesizable HDL description starting from ANSI specifications.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Programmable devices such as FPGAs can potentially offer very significant computational power, but implementing efficient solutions on them can be a hard task. One
of the main obstacles is the usage of hardware description language (HDL), whose knowledge is usually a rare expertise.
To overcome or at least to mitigate this issue, High Level Synthesis (HLS) has been introduced: a (semi)-automatic design flow, potentially composed of several methodologies, that
starting from a high level representation of the specification to be implemented (e.g., from its C/C++ source code implementation) produces its hardware implementation.
This talk presents Bambu a free HLS tools based on GCC developed at Politecnico di Milano, that generated synthesizable HDL description starting from ANSI specifications.
In particular, Bambu receives as input a behavioral description of the algorithm, written in ANSI C language, and generates a Verilog description of the corresponding RTL implementation as output, along with a test-bench for the simulation and validation of the behavior. This HDL description is then compatible with commercial RTL synthesis tools.
Bambu has a compiler-based interface interacting with the GNU Compiler Collection (GCC) (version 4.5, 4.6, 4.7, 4.8 and 4.9 are currently supported) and builds the internal representation in Static Single Assignment form of the initial C code.
Floating point operations are supported through FloPoCo (http://flopoco.gforge.inria.fr/), a generator of arithmetic Floating-Point Cores or through directly synthesis of a softfloat based C description.
Bambu provides the automatic generation of synthesis and simulation scripts based on XML configuration. This feature allows the automatic characterization of the resource library, providing technology-aware details during the High-Level Synthesis. The tools for RTL-synthesis currently supported are: Xilinx ISE, Xilinx VIVADO, Altera Quartus and Lattice Diamond; and simulation tools: Mentor Modelsim, Xilinx ISIM, Xilinx XSIM, Verilog Icarus and Verilator.&lt;/p&gt;</description>
        <persons>
          <person id="2479">Fabrizio Ferrandi</person>
        </persons>
        <links>
          <link href="http://panda.dei.polimi.it/">PandA project website</link>
          <link href="http://www.ohwr.org/projects/panda/wiki">PandA project hosted at Open Hardware Repository</link>
        </links>
      </event>
      <event id="3398">
        <start>13:35</start>
        <duration>00:25</duration>
        <room>AW1.124</room>
        <slug>digital_design_panel</slug>
        <title>Panel Discussion on Digital Design</title>
        <subtitle/>
        <track>Electronic design automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;A panel discussion on topics related to digital design and simulation.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2958">Tristan Gingold</person>
          <person id="2479">Fabrizio Ferrandi</person>
          <person id="2640">Maciej Sumiński</person>
          <person id="2642">Javier D. Garcia-Lasheras</person>
          <person id="2806">Tomasz Wlostowski</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3036">
        <start>14:05</start>
        <duration>00:30</duration>
        <room>AW1.124</room>
        <slug>geda_pcb</slug>
        <title>An introduction to the gEDA / PCB project</title>
        <subtitle/>
        <track>Electronic design automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;An introduction to the gEDA and PCB projects, their background, history, current status and future plans.&lt;/p&gt;

&lt;p&gt;Will likely include anecdotes from the point of view of myself, as a (now mostly inactive) core developer on both projects, and my thoughts on where open source EDA tools need to head in order to remain relevant in a world where "free", but closed commercial tools becoming ever more prevalent.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The aim of this talk would be to introduce the gEDA (and associated) projects, how its loosely structured suite of tools can fit together to form diverse EDA workflows, with some anecdotes from my point of view as both from a developer, and user of this software.&lt;/p&gt;

&lt;p&gt;The design philosophy behind the suite will be presented, along with discussion on how its modular (or fragmented?), yet flexible design has in the past created problems for those seeking to improve our user-experience for those who desire a more integrated work-flow.&lt;/p&gt;

&lt;p&gt;I will present a section on where I see the common challenges of open-source EDA, and where I see opportunities for collaboration to further common goals in this area.&lt;/p&gt;

&lt;p&gt;There may be a live demonstration of the tools in action, although at this stage I have not planned exactly what form that might take.&lt;/p&gt;</description>
        <persons>
          <person id="2720">Peter Clifton</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2770">
        <start>14:40</start>
        <duration>00:30</duration>
        <room>AW1.124</room>
        <slug>kicad</slug>
        <title>KiCad EDA</title>
        <subtitle>Where we've been, where we are, and where we hope to go.</subtitle>
        <track>Electronic design automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;A brief look at the past, present, and future of the KiCad project.  The discussion will be primarily on what near and long term future development is planned for the project as well as discussing the potential for collaboration with other EDA projects.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2508">Wayne Stambaugh</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2771">
        <start>15:15</start>
        <duration>00:15</duration>
        <room>AW1.124</room>
        <slug>one_click_bom</slug>
        <title>1clickBOM</title>
        <subtitle>A browser extension to quickly add electronic components to shopping carts</subtitle>
        <track>Electronic design automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;1clickBOM is a browser extension that allows you to simple paste from spreadsheets or visit an online BOM and then quickly add those components to shopping carts. It takes the tedium out of shopping for electronic projects online without locking you into one vendor. This presentation is a short introduction to 1clickBOM and a discussion of the design decisions taken in making it.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2377">Kaspar Emanuel</person>
        </persons>
        <links>
          <link href="http://1clickBOM.com">Project website</link>
        </links>
      </event>
      <event id="3227">
        <start>15:35</start>
        <duration>00:15</duration>
        <room>AW1.124</room>
        <slug>pcb_routing</slug>
        <title>Interactive routing algorithms in modern PCB design tools</title>
        <subtitle/>
        <track>Electronic design automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Interactive (a.k.a. push and shove) routing is a key feature of advanced PCB design software, greatly reducing the time it takes to design and modify the board.
There is however no literature on the subject available. The presentation will focus on the internals of the router implemented by CERN for the Kicad PCB editor:
- efficient routing geometry storage and obstacle detection,
- shove &amp;amp; hug algorithm based on octagonal primitives and force propagation,
- optimization and trace smoothing techniques,
- length tuning and differential pair routing.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2806">Tomasz Wlostowski</person>
        </persons>
        <links>
          <link href="http://www.ohwr.org/projects/cern-kicad/wiki/WorkPackages">CERN Kicad project page</link>
        </links>
      </event>
      <event id="3038">
        <start>15:55</start>
        <duration>00:15</duration>
        <room>AW1.124</room>
        <slug>cad_3d</slug>
        <title>3D modelling, CAD, and its relevance to PCB design</title>
        <subtitle/>
        <track>Electronic design automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;A talk on the utility of 3D modelling to PCB design, and a brief review of where open-source tools currently stand compared to commercial offerings. Having introduced the ideas, and why we may desire to add 3D functionality to our software tools, I will attempt to give a very brief introduction to solid modelling (3D CAD), and compare the requirements for rendering graphics vs. working with engineering models. I would aim to touch upon the subjects of BREP models (vs. surface models), and interchange formats such as STEP (AP203 / AP214), and their complexity.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2720">Peter Clifton</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3107">
        <start>16:15</start>
        <duration>00:15</duration>
        <room>AW1.124</room>
        <slug>edacore</slug>
        <title>edacore: Less work for everybody</title>
        <subtitle>Crowdsourced parameterized parts library</subtitle>
        <track>Electronic design automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Each EDA tool currently has its own parts library, even(!) the open source EDA packages. This lack of reuse is not very efficient, and certainly not state-of-the-art when compared to the collaboration and cooperation taking place in the source code.&lt;/p&gt;

&lt;p&gt;Let's fix that - I would like to start the edacore project with the aim to fulfill the part library needs of not only open source EDA packages, but ideally all of the industry. Sounds ambitious? You bet. Maybe it'll actually work out in the end.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The purpose of this event is to quickly introduce the fairly simple project idea and then to gather collaborators who care about creating a universal parts library, flexible enough to work for almost every use case, and finally to do a bit of brainstorming around what the edacore data model must take into account.&lt;/p&gt;

&lt;p&gt;At least one representative with a major semiconductor vendor has already expressed interest in populating edacore using their in-house data. I imagine that other vendors would also be interested. Anything that helps sell chips is good, and perhaps we can have dialogue such that providing information will be very easy for as many vendors as possible.&lt;/p&gt;

&lt;p&gt;The project might turn out a total flop, but we will not know unless we try...&lt;/p&gt;</description>
        <persons>
          <person id="385">Peter Stuge</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3399">
        <start>16:35</start>
        <duration>00:25</duration>
        <room>AW1.124</room>
        <slug>pcb_tools_panel</slug>
        <title>Panel discussion on PCB design tools</title>
        <subtitle/>
        <track>Electronic design automation</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Panel discussion on PCB design tools.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="385">Peter Stuge</person>
          <person id="2377">Kaspar Emanuel</person>
          <person id="2508">Wayne Stambaugh</person>
          <person id="2720">Peter Clifton</person>
          <person id="2806">Tomasz Wlostowski</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="AW1.125">
      <event id="2659">
        <start>09:00</start>
        <duration>00:15</duration>
        <room>AW1.125</room>
        <slug>sdrintro</slug>
        <title>SDR Track: Introduction</title>
        <subtitle>Words of welcome, and a brief introduction of our schedule.</subtitle>
        <track>Software defined radio</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Our opening talk for the SDR devroom.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;To highlight our agenda and introduce the steering committee.&lt;/p&gt;</description>
        <persons>
        </persons>
        <links>
        </links>
      </event>
      <event id="2765">
        <start>09:15</start>
        <duration>01:00</duration>
        <room>AW1.125</room>
        <slug>gnuradio</slug>
        <title>Introduction to Using GNU Radio</title>
        <subtitle/>
        <track>Software defined radio</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;GNU Radio is an expansive ecosystem of libraries, hardware interfaces, third-party applications, and community members of all types. With all of these parts, we know it's difficult to understand where to begin. In this lecture, I will provide an overview of the ecosystem and walk through a set of examples that use GNU Radio to explore the wireless space.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Given the huge range of capabilities, available tools, library of third-party applications, and size of the community, this lecture covers a basic introduction to GNU Radio. We will explore, through some historical context, the use of GNU Radio to build some simple applications. Although simple, a key to using GNU Radio is through exploration of the tools and available features, and so the introductory material is meant to overcome the basic difficulties of just getting to know what GNU Radio is and what it can do. With this knowledge that provides an exposure to the library, webpages, tools, and community, we think that other users can continue to explore the space of capabilities and applications for much more advanced features.&lt;/p&gt;</description>
        <persons>
          <person id="1623">Tom Rondeau</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3138">
        <start>10:15</start>
        <duration>00:15</duration>
        <room>AW1.125</room>
        <slug>sdr_rds_tmc</slug>
        <title>First Steps in Receiving Digital Information with RDS/TMC</title>
        <subtitle/>
        <track>Software defined radio</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The Radio Data System (RDS) is a digital subcarrier on ordinary FM radio broadcasts that is used to convey a bunch of information including station name, time, alternate frequencies, and optionally traffic information with the Traffic Message Channel (TMC) protocol.
Given its ubiquity, narrow bandwidth demands, and frequency band, RDS might be a good first digital project for SDR newcomers, extending the 'Hello World' of SDR, i.e., the FM receiver.
RDS can be received with very cheap hardware like the RTL-SDR and simple antennas making the technology accessible for everybody.&lt;/p&gt;

&lt;p&gt;In this talk, I will give a short introduction in RDS / TMC and present the current state of the GNU Radio RDS project.
Besides the receiving part, we will also have a brief look in the transmit side that allows you to create your own small radio station including RDS and TMC messages.
The information is hopefully just enough to whet your appetite and helps to get you started.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1776">Bastian Bloessl</person>
        </persons>
        <links>
          <link href="https://www.youtube.com/watch?v=05i9C5lhorY">Receiver Demo</link>
          <link href="http://bastibl.net/rds-tmc/">Blog Post about RDS Updates</link>
          <link href="http://youtu.be/ukhrIl4JHbw?t=8m48">HAK5 Episode covering RDS</link>
          <link href="https://github.com/bastibl/gr-rds">Github Project Page</link>
          <link href="http://en.wikipedia.org/wiki/Radio_Data_System">Wikipedia Page</link>
        </links>
      </event>
      <event id="2731">
        <start>10:30</start>
        <duration>00:30</duration>
        <room>AW1.125</room>
        <slug>iot_sdr</slug>
        <title>Internet of #allthethings</title>
        <subtitle>Using GNURadio Companion to Interact with an IEEE 802.15.4 Network</subtitle>
        <track>Software defined radio</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The purpose of this talk is to demonstrate and explain how to use and modify GNURadio and GNU Radio Companion to interact with consumer devices on an IEEE 802.15.4 network. Accompanying the talk will be slides documenting the hardware, software, and network architectures for the demonstration, with specific attention to GNU Radio hacking and rapid prototyping of software to interface with most commercially available SDRs.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;This was a big year for the Internet of Things. Both Apple and Google announced their venture into the Home Automation consumer market. Having reliable and extensible tools to interact with the IEEE 802.15.4 spectrum is incredibly important for developers and engineers of wireless products, as well as for security researchers.&lt;/p&gt;

&lt;p&gt;Using off-the-shelf SDR equipment (e.g. the USRP B200 from Ettus Research), as well as off-the-shelf Home Automation hardware and software, developers can easily interact with an IEEE 802.15.4 network and do everything from pretending to be a light bulb to packet sniffing and network management.&lt;/p&gt;

&lt;p&gt;This talk will go over some of the challenges encountered in designing such a node with the help of GNU Radio, GNU Radio Companion, and freely available 802.15.4 code.&lt;/p&gt;</description>
        <persons>
          <person id="2465">Chris Friedt</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3114">
        <start>11:00</start>
        <duration>00:30</duration>
        <room>AW1.125</room>
        <slug>so_sdr_much_dsp</slug>
        <title>Rapid GNU Radio GPU Algorithm Prototyping from Python</title>
        <subtitle>with gr-theano, gr-channels, and friends</subtitle>
        <track>Software defined radio</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Theano is an exciting relatively new open source library which was developed by the machine learning community to accelerate the training of Deep Neural networks and other mathematical algorithms built on scipy by generating compiled kernels for the CPU and the GPU using the CUDA compiler and simple python algorithm definitions.   Since GNU Radio provides native python blocks which execute work functions directly on scipy-style input and output vectors joining these two technologies is a magical approach which allows for the extremely rapid definition of work block mathematical kernels, and the automated compilation and offload onto massively parallel graphics processing unit hardware.  By using this approach we will demonstrate how some highly concurrent and computationally expensive algorithms can be implemented extremely concisely and executed efficiently using graphics processors to accelerate GNU Radio channel models and other blocks with minimal effort.
For more information on Theano see: http://www.iro.umontreal.ca/~lisa/pointeurs/theano_scipy2010.pdf and http://arxiv.org/pdf/1211.5590.pdf&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2757">Tim O’Shea</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2950">
        <start>11:30</start>
        <duration>00:30</duration>
        <room>AW1.125</room>
        <slug>spectrumsharing</slug>
        <title>Spectrum sharing applications with GNURadio</title>
        <subtitle/>
        <track>Software defined radio</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;There are various cognitive radio models in literature which enable unlicensed users to exploit under-utilized licensed spectrum. This talk will explain the spectrum exploitation problem, some insight to the state of the art solutions keeping SDR implementations in mind. The presentation will also cover some of the practical interference learning schemes and how they can be used in these spectrum sharing scenarios.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2654">Sreeraj Rajendran</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3164">
        <start>12:00</start>
        <duration>00:30</duration>
        <room>AW1.125</room>
        <slug>sdr_arithmetic</slug>
        <title>Arithmetic based implementation of a quadrature FM Demodulator</title>
        <subtitle>SDR in GnuRadio</subtitle>
        <track>Software defined radio</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;One of the key component in many GnuRadio projects is the quadrature frequency demodulator.
This functionality allows to calculate the real analog output of a frequency modulated signal from
the IQ-signal, which is mainly captured using HF hardware (e.g. dvb-t dongle, USRP, etc.) by a
carrier frequency (band pass domain) and transform it to the base band domain. The most known
implementations of the FM-demodulator are based on trigonometric functions. These functions
require a high computation effort. Some implementation of “tuned” trigonometric function, which
were downsized for FM-demodulation reduce the computation effort a little.
A new proposal of a so called arithmetic FM-Demodulator allows to avoid completely the usage of
any trigonometric function and speed up the computation process in many times.
In the presentation I will introduce mathematical background for the arithmetic FM-Demodulator,
show the differences and limitations to the current implementation in GnuRadio Version.
Further Philipp will present our result, we had achieved in our lab.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2776">Denis Bederov</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2986">
        <start>12:30</start>
        <duration>00:30</duration>
        <room>AW1.125</room>
        <slug>viterbi</slug>
        <title>Viterbi's little Helper</title>
        <subtitle>Coprocessor strategies for Forward Error Correction</subtitle>
        <track>Software defined radio</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Forward Error Correction (FEC) is a vital part of every communication scheme. Convolutional Error Codes can provide the protection of the data to drive the communication system close to the Shannon Limit. But due to the complexity of the decoders, it is challenging to implement these algorithms in software for use in software defined radios (SDR). Available coprocessors, such as graphic processor units (GPU) and single instruction multiple data architectures (SIMD) can dramatically enhance the throughput of such software based receivers. Strategies to start implementing Viterbi- and Maximum A Posteriori (MAP) Decoders on these coprocessors are presented in this talk. Potential tripping hazards are identified. The effects on the throughput of these algorithms are analyzed and shown.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Convolutional Codes have been known for a long time. Viterbi established his algorithm to decode convolutional encoded data in the year 1967 [1]. SDR has also been established since the late 90’s and early 00’s. But still the implementation of convolutional decoders, such as the Viterbi- or MAP-algorithm, in software has always been a problem. Both algorithms rely on a Hidden Markoff Model as the encoder is simply a Mealy Machine. So if one surveys every possible state transition caused by a bit stream, a trellis structure is created. For every encoded information bit you have to consider all possible transitions from one state to another [1][2]. This leads to a high complexity and implementations of these algorithms suffer from a heavy computational burden.&lt;/p&gt;

&lt;p&gt;The Viterbi Algorithm tries to relax these conditions by applying a dynamic programming approach to the trellis structure [3]. In this approach only the strongest path survives to reduce the overhead generated by analyzing all possible paths through the trellis. Still the computational effort is very high.&lt;/p&gt;

&lt;p&gt;Up until now the technology used in SDRs has not been able to handle the computational burden of these algorithms. Implementations generally have suffered from a low throughput that was not suitable for state of the art communication systems (i.e. 3GPPP LTE or WLAN). Therefor these systems still used fixed hardware chips, such as ASICs, to manage the high throughput that these systems require.&lt;/p&gt;

&lt;p&gt;With the increasing clock rates of General Purpose Processors (GPP) and the higher density of units inside the architecture, implementing these algorithms is starting to become more feasible. Especially additional architectural features such as SIMD architectures and multiple processor cores on one chip have gained increasing importance when implementing digital signal processing algorithms in software [4].&lt;/p&gt;

&lt;p&gt;Another interesting field is the use of coprocessors found in common computers. In most cases this is going to be a GPU. GPU vendors also provide libraries and software development kits (SDK) to use the GPU for general computations and signal processing [5]. This specialized processors and libraries can be efficiently used to accelerate algorithms that can be massively parallelized.&lt;/p&gt;

&lt;p&gt;This talk will cover implementation constraints that occur when implementing FEC and DSP algorithms on SIMD processors and GPUs. It will highlight some of the tripping hazard that newcomers have to avoid when trying to make an efficient use of these coprocessors. Exemplary cases for both architectures are analyzed to show, how the proper use of these architectures enhances a software defined communication system.&lt;/p&gt;

&lt;p&gt;REFERENCES
[1] A. Viterbi, “Error bounds for convolutional codes and an asymptotically
optimum decoding algorithm,” Information Theory, IEEE Transactions
on, vol. 13, no. 2, pp. 260–269, April 1967.&lt;/p&gt;

&lt;p&gt;[2] L. Hanzo, T. H. Liew, and B. L. Yeap, Turbo Coding, Turbo Equalisation
and Space-Time Coding for Transmission over Wireless Channels.
Wiley, 2002.&lt;/p&gt;

&lt;p&gt;[3] J. Forney, G.D., “The viterbi algorithm,” Proceedings of the IEEE,
vol. 61, no. 3, pp. 268–278, March 1973.&lt;/p&gt;

&lt;p&gt;[4] U. Santoni and T. Long, Signal Processing on Intel Architecture:
Performance Analysis using Intel Performance Primitives,
[Online]. Available: http://www.intel.com/content/dam/doc/whitepaper/
signal-processing-on-intel-architecture.pdf, 2014.&lt;/p&gt;

&lt;p&gt;[5]NVIDIA: OpenCL Programming Guide for the CUDA Architecture, 2009. Version 2.3.&lt;/p&gt;</description>
        <persons>
          <person id="2658">Jan Kraemer</person>
        </persons>
        <links>
          <link href="http://github.com/spectrejan">Github Account with relevant Code</link>
        </links>
      </event>
      <event id="3159">
        <start>13:00</start>
        <duration>00:45</duration>
        <room>AW1.125</room>
        <slug>rfnocfosphor</slug>
        <title>RFNoC: Theory and Practice</title>
        <subtitle>RFNoC architecture overview and its application to RTSA display acceleration</subtitle>
        <track>Software defined radio</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;RFNoC (RF Network-on-Chip) is a framework that allows easy and rapid development of FPGA signal processing systems, with the same FPGA and host code to be used across multiple devices and applications.&lt;/p&gt;

&lt;p&gt;Its general architecture will be presented first and then the current implementation state of a practical RFNoC block designed to accelerate RTSA-like (fosphor) spectrum visualization will be described.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1632">Sylvain Munaut</person>
          <person id="2887">Matt Ettus</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2911">
        <start>13:45</start>
        <duration>00:30</duration>
        <room>AW1.125</room>
        <slug>hamsdr</slug>
        <title>To The Moon And Back. Software Defined Radio and High Power transmissions.</title>
        <subtitle>How to do cool things and stay legal.</subtitle>
        <track>Software defined radio</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Today, GNURadio enthusiasts are in the same situation as radio electronics enthusiasts about 90 years ago: Many ideas sound very promising, but international regulations and national laws prohibit extended experimenting. Radio Amateurs such as Nobel Price winner Joe Taylor (K1JT) have demonstrated that digital signal processing allows moonbounce transmissions also to the private hacker, but also many more thrilling experiments such as airplane scatter and the active use of Amateur Radio satellites. Most, however, require a little more power than those 10 dBm produced by the USRP series. This talk shows how easy it is to make use of the definitions of international Amateur Radio regulations as part of the ITU ruleset and how to get a license according to national laws - and to experiment with GNURadio -and- with high power.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;In this talk I will present the technology that is necessary to transmit to the moon and back. I will show how to use Joe Taylor's WSJT suite of protocols. Based on these applications I will explain what the ITU Radio Regulations article 25 defines about private experiments and how the RR25 is implemented in national laws. I will explain in detail which privileges a license holder enjoys and how these privileges will boost the possibilities of a GNURadio hacker.&lt;/p&gt;</description>
        <persons>
          <person id="2625">Markus Heller</person>
        </persons>
        <links>
          <link href="http://physics.princeton.edu/pulsar/k1jt/wsjtx.html">Joe Taylor's pages</link>
          <link href="http://www.arrl.org/news/moonbounce-for-everyone-courtesy-of-the-arecibo-radio-telescope">Moonbounce at Arecibo</link>
          <link href="http://www.uba.be/en/belgian-rules-and-regulations">Belgian Amateur Radio law</link>
          <link href="http://www.gesetze-im-internet.de/bundesrecht/afug_1997/gesamt.pdf">German Amateur Radio law</link>
        </links>
      </event>
      <event id="3077">
        <start>14:15</start>
        <duration>00:30</duration>
        <room>AW1.125</room>
        <slug>rpisdr</slug>
        <title>Some Results of experiments using Raspberry Pi as a transmitter for HF</title>
        <subtitle/>
        <track>Software defined radio</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The focus is layed on the results of experiments with a HF-Transmitter consisting of a pure Raspberry Pi. The Pi uses a digital coding and 4-FSK-Modulation for these experiments. There are also shown some measurement results and there are given  some criteria about the quality of a RaspberryPi as a transmitter. Harmonics and mixer products are discussed and ideas, how to avoid them. It is compared with some simple experiments with GnuRadio on effects of digital interpolation and mixing.
Finally some results of short wave transmission with the output power of 10 mW in WSPR-mode is shown.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2613">Michael Hartje</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3032">
        <start>14:45</start>
        <duration>00:30</duration>
        <room>AW1.125</room>
        <slug>oai</slug>
        <title>Inside OpenAirInterface</title>
        <subtitle/>
        <track>Software defined radio</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;We provide an overview of the OpenAirInterface.org (OAI) 3GPP LTE SDR MODEM and protocol stack for x86-based systems. We focus on the objectives, some of the history of the project and its primary technical aspects. We also provide information regarding the newly created Software Foundation around OAI to encourage open-source development for 5G radio systems in conjunction with the imminent standardization phase.&lt;/p&gt;</abstract>
        <description>&lt;h2&gt;OpenAirInterface today&lt;/h2&gt;

&lt;p&gt;OpenAirInterface (OAI) currently provides a standard-compliant implementation under a GNU GPLv3 license of a subset of Release 10 LTE for terminal (UE), basestation (eNodeB), and core network (EPC - MME, HSS, SGw and PGw) on standard Linux-based computing equipment (Intel x86 PC architectures). It  can be used in conjunction with standard RF laboratory equipment available in many labs (i.e. National Instruments/Ettus USRP and soon PXIe platforms) in addition to custom RF hardware provided by EURECOM to implement these functions to a sufficient degree to allow for real-time interoperation with commercial devices.  Some industrial users have reported working OAI-based systems integrated with commercially-deployable remote radio-head equipment and have provided demonstrations at major industrial tradeshows (Mobile World Congress Asia 2014, Mobile World Congress Barcelona in 2013, IMIC 2013). The current major industrial users of OpenAirInterface for collaborative projects are Agilent, China Mobile, IBM, Alcatel-Lucent, Thales, National Instruments and Orange.  The primary future objective is to provide an open-source reference implementation which follows the 3GPP standardization process starting from Rel-13 and the evolutionary path towards 5G and that is freely-available for experimentation on commodity laboratory equipment.&lt;/p&gt;

&lt;p&gt;We detail some of the inner workings of OAI, in particular SIMD optimizations for real-operation and efficient numerical simulation of radio systems as well as information regarding tools used in the development of the protocol stack. We also provide some use cases of OAI experimental research as well as some the methodologies used for proof-of-concept design (simulation, testing and deployment).&lt;/p&gt;

&lt;h2&gt;A bit on the need for open-source tools for 5G cellular evolution&lt;/h2&gt;

&lt;p&gt;Open-source has made a very significant impact in the extremities of current networks, namely in the terminals due to the Android ecosystem and in cloud infrastructure due, in part, to the OpenStack ecosystem.  The OpenAirInterface Software Foundation aims to provide a similar ecosystem for the core (EPC) and access-network (EUTRAN) of 3GPP cellular systems with the possibility of interoperating with closed-source equipment in either portion of the network. In addition to the huge economic success of the open-source model, the Foundation will be a tremendous tool used by both industry and academia. More importantly it will ensure a much-needed communication mechanism between the two in order to bring academia closer to complex real-world systems which are controlled by major industrial players in the wireless industry.  In the context of the evolutionary path towards 5G, there is clearly the need for open-source tools to ensure a common R&amp;amp;D and prototyping framework for rapid proof-of-concept designs.&lt;/p&gt;

&lt;h2&gt;About the Foundation&lt;/h2&gt;

&lt;p&gt;The Foundation is a non-profit organization ("Fonds de Dotation") founded by EURECOM, a world-renowned research institute in telecommunications and creator of OAI. EURECOM has been encouraged by the European Commission to extend OpenAirInterface to help in the definition of 5G systems. To this end, the Foundation will help drive innovation in 5G by following the standard as it is being drafted and, through quick interaction with 3GPP, will leverage the crowdsourcing effect both from industrial and academic users.  It strives to make OpenAirInterface become the de facto  reference implementation for new 3GPP standards through its open-source policy starting from Release 13 LTE.  The resulting development can be used in  both publicly-funded collaborative projects as well as industry-driven initiatives aiming to demonstrate 5G features at the earliest possible stage. Moreover, the results can be replicated in several locations independently through the combination of open-source and commodity hardware.  This then becomes a truly distributed experimental facility with a very large number of potential contributors.&lt;/p&gt;</description>
        <persons>
          <person id="2716">Raymond Knopp</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2963">
        <start>15:15</start>
        <duration>00:30</duration>
        <room>AW1.125</room>
        <slug>oss_lte</slug>
        <title>Open Source LTE</title>
        <subtitle>EPCs and eNodeBs and UEs oh my</subtitle>
        <track>Software defined radio</track>
        <type>devroom</type>
        <language/>
        <abstract></abstract>
        <description></description>
        <persons>
          <person id="2669">Paul Sutton</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2732">
        <start>15:45</start>
        <duration>00:30</duration>
        <room>AW1.125</room>
        <slug>iiosdr</slug>
        <title>Using the Linux IIO framework for SDR</title>
        <subtitle>A hardware abstraction layer</subtitle>
        <track>Software defined radio</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This presentation will discuss the IIO framework in the context of Software-Defined-Radio and how it can be used as a generic and efficient transport of data to and from the hardware. It will start with a basic introduction to the IIO framework itself and than go on to discuss the SDR related bits in more detail. The presentation will cover the low-level bits and ideas of the API, the existing userspace applications and libraries up to the GNU Radio integration.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The Linux kernel Industrial IO (IIO) framework is responsible for handling sensors or converters of all kinds and variations. The framework acts as a hardware abstraction layer where kernel device drivers handle the low-level details of communicating with the hardware. A standard API is exposed from kernel- to userspace and generic requests made by userspace applications are translated into hardware specific requests by the framework and drivers. Having a standard API makes it possible for applications to discover the features of the connected hardware at runtime and to be written in a device independent way, which can greatly improves code re-usability.&lt;/p&gt;

&lt;p&gt;This presentation will discuss the IIO framework in the context of Software-Defined-Radio and how it can be used as a generic and efficient transport of data to and from the hardware. It will start with a basic introduction to the IIO framework itself and than go on to discuss the SDR related bits in more detail. The presentation will cover the low-level bits and ideas of the API, the existing userspace applications and libraries up to the GNU Radio integration.&lt;/p&gt;

&lt;p&gt;The presentation will conclude with a live demonstration that shows how the IIO framework can be used to efficiently stream data from a embedded FPGA SDR receiver board to GNU Radio running on a laptop for further processing.&lt;/p&gt;

&lt;p&gt;The intention of the presentation is to make more people in the SDR community familiar with and knowledge about the IIO API in the hopes of further establishing IIO as a standard tool that can be used to separate hardware access from data processing. This should aid in being able to create generic hardware independent software.&lt;/p&gt;</description>
        <persons>
          <person id="2467">Lars-Peter Clausen</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2930">
        <start>16:15</start>
        <duration>00:30</duration>
        <room>AW1.125</room>
        <slug>xcorr</slug>
        <title>The power of cross-correlating: from GPS reception to passive RADAR using SDR</title>
        <subtitle/>
        <track>Software defined radio</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;CDMA systems rely on encoding data streams radiated by multiple emitters on the same carrier frequency with (ideally) orthogonal codes. Recovering the signal from each emitter requires identifying the code assiociated with
each source, which hence also requires recovering the carrier to account for relative emitter/receiver motion (Doppler shift), thermal drift and oscillator bias. We demonstrate this concept with the reception of GPS signal -- a constellation of satellites orbiting 20000 km over the surface of the earth -- with 20 euro worth of equipment centered on a DVB-T receiver designed for receiving neighbouring television signals. We extend the concept to passive radar, in which a radiofrequency emitter (television, broadcast radio) signal reflected on a mobile target is used for identifying the velocity and position of the target. In this approach, no active source is needed: RADAR measurement is only a matter of correlating the direct and reflected signal, after identifying the Doppler induced frequency shift.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1813">Jean-Michel Friedt</person>
        </persons>
        <links>
          <link href="http://jmfriedt.free.fr/efts_gps.pdf">Slides of an internal presentation related to the considered topic</link>
        </links>
      </event>
    </room>
    <room name="AW1.126">
      <event id="3395">
        <start>09:00</start>
        <duration>00:30</duration>
        <room>AW1.126</room>
        <slug>opening</slug>
        <title>Opening</title>
        <subtitle/>
        <track>Open source design</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Opening remarks for the Open Source Design devroom&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2364">Roy Scholten</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3298">
        <start>09:30</start>
        <duration>00:30</duration>
        <room>AW1.126</room>
        <slug>session_1</slug>
        <title>Building the Open Source Design community</title>
        <subtitle/>
        <track>Open source design</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Design and good UX gets more and more important in open source projects. We need to work together, across projects, to deliver the best experience.&lt;/p&gt;

&lt;p&gt;In the spirit of open source and sharing code, we should also share our design work. We need to gather, share ideas, exchange how we approach problems, what works and what doesn’t.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Some of the topics we should connect about and also build a body of knowledge for other projects:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;How to get started&lt;/li&gt;
&lt;li&gt;Unique challenges in open source as designers&lt;/li&gt;
&lt;li&gt;How to work together with developers&lt;/li&gt;
&lt;li&gt;Building a design team&lt;/li&gt;
&lt;li&gt;How to make it easy for others to get started&lt;/li&gt;
&lt;li&gt;Resources: tools, blogs, websites, …&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;And outreach we can do:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Open Source conferences to attend and present at&lt;/li&gt;
&lt;li&gt;Cross-invitations to conferences of other projects&lt;/li&gt;
&lt;li&gt;Help projects which need design help&lt;/li&gt;
&lt;li&gt;Work with universities to get students working on open source design&lt;/li&gt;
&lt;/ul&gt;
</description>
        <persons>
          <person id="401">Jan-Christoph Borchardt</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3124">
        <start>10:15</start>
        <duration>00:30</duration>
        <room>AW1.126</room>
        <slug>session_2</slug>
        <title>The Problem of Representativity</title>
        <subtitle>Challenges of User Centred Work  in FLOSS Projects</subtitle>
        <track>Open source design</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Presenting challenges, experiences and a possible solution for problems we face in FLOSS, when we try to understand our users.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Usability or User Experience essentially is optimizing a software for users needs. To accomplish this, we need to know who the users are, what they think, do and want to achieve with our tool.&lt;/p&gt;

&lt;p&gt;In Free Software projects this kind of work often is especially difficult. Our work can be distributed freely, so we do not know who or even how many people are using our product. And we usually do not have enough money to do market or customer research to fill this gaps. Finally, developers have become good to ward off anything that doesn't scratch their own itches. And without real user data, we often lack "objective" arguments to win developers to implement changes needed.&lt;/p&gt;

&lt;p&gt;With this talk, I want to reflect on my experiences with user research and user driven design in different FLOSS projects, esp. KDE and LibreOffice. Based on this, I will present an idea, how tooling could possibly improve the situation. And, of course, I want your feedback on all of this!&lt;/p&gt;</description>
        <persons>
          <person id="2761">Björn Balazs</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3192">
        <start>11:00</start>
        <duration>00:30</duration>
        <room>AW1.126</room>
        <slug>session_3</slug>
        <title>User-land and developer-land chat</title>
        <subtitle/>
        <track>Open source design</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Now more than ever, users clamor for software that respects their privacy and protects their security. Free software's natural advantage is that it's almost always the best option to safeguard users in a world where proprietary software so often betrays them. Users want options and we know developers want to provide them, so what are we missing?  Two free software activists, one developer and one community liaison, take turns asking each other questions about their experiences and goals.  All the questions about intent, process, and getting user feedback that you've been wondering about will finally be answered.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Now more than ever, users clamor for software that respects their privacy and protects their security. Free software's natural advantage is that it's almost always the best option to safeguard users in a world where proprietary software so often betrays them. Users want options and we know developers want to provide them, so what are we missing?&lt;/p&gt;

&lt;p&gt;When an alternative to a proprietary system becomes available, people don't seem to stick with it. Users arrive and things break, features that seem basic are missing, and the channels through which they might ask for help are hard to find or non-existent. They're wondering, "Who did you build this for? Why is it so annoying to use?" Meanwhile, developers put their time and energy into building technology to free their users and are left wondering, "Why aren't people just using this? It's not &lt;em&gt;really&lt;/em&gt; that hard to figure out."&lt;/p&gt;

&lt;p&gt;Two free software activists, one developer and one community liaison, take turns asking each other questions about their experiences and goals. All the questions about intent and process that you've been wondering about will finally be answered. At MediaGoblin, we've worked hard to keep the lines of communication between developers and users open from the beginning. This public conversation between MediaGoblin's technical founder and community liaison will replicate some of those conversations for the audience. Our back-and-forth interview will share what we have learned about how free software projects can get users to show up and, more importantly, stay.&lt;/p&gt;</description>
        <persons>
          <person id="1062">Christopher Webber</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3202">
        <start>11:45</start>
        <duration>00:30</duration>
        <room>AW1.126</room>
        <slug>session_4</slug>
        <title>Accessible Design in Open Source</title>
        <subtitle/>
        <track>Open source design</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Design is not simply skin deep, it interacts with deeper layers in software programs. And it is not just for people who point and click to use applications. It also affects people who cannot distinguish certain colours, who cannot use a mouse, who are confused by complex user interfaces, etc.
What can designers and developers in open source projects do to make their software more accessible? What do they need to know about people with disabilities? What tools are available to help them? What are example projects that have worked to improve accessibility?&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2784">Christophe Strobbe</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3257">
        <start>12:30</start>
        <duration>00:30</duration>
        <room>AW1.126</room>
        <slug>session_5</slug>
        <title>Bootstrapping user experience design work in your open source project</title>
        <subtitle/>
        <track>Open source design</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;How to get started bringing user experience design practices into open source projects using Drupal as a case study.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;If you want to grow the user base of your open source project, or even just want to make things simpler for your existing users, then one of the ways you can do that is by making your app easier to use. Topics that we'll discuss:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Ways to make the case for the need of a good user experience&lt;/li&gt;
&lt;li&gt;How to get started making good design part of your project&lt;/li&gt;
&lt;li&gt;About the challenges of designing in open source&lt;/li&gt;
&lt;li&gt;How to foster collaboration between designer and developer&lt;/li&gt;
&lt;li&gt;What you can do to attract (more) designers to your project&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Since 2007 there has been a dedicated ux design team working on improving the usability and design of the Drupal content management system. Roy Scholten has been part of this effort since its beginning.&lt;/p&gt;</description>
        <persons>
          <person id="2364">Roy Scholten</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2726">
        <start>13:15</start>
        <duration>00:30</duration>
        <room>AW1.126</room>
        <slug>session_9</slug>
        <title>UI design for open data</title>
        <subtitle/>
        <track>Open source design</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Good design can increase the value of open data to the public and industry professionals. But what is open data and how can it be used? The focus of this talk is using design to aid the release of knowledge from within cultural institutions. I’ll be discussing the challenges of designing for complex UIs in general and how we can use narrative to inform and guide the user through abstract interactions.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;How can design help us communicate data easily to users? Where does this stem from? What methods of design are easy for users to engage with? What should we be trying to achieve with these designs?&lt;/p&gt;

&lt;p&gt;The cultural sector is a big adopter of open data and semantic web technologies. They have embraced the ideas and are weaving them into everything they do. So, who is doing what? What data sets are there available? And how have these been presented to the public.&lt;/p&gt;

&lt;p&gt;Using case studies from the cultural sector, we will explore the practical challenges associated with complex UI designs. Looking at work-in-progress through to finished products we will discuss best practice, finding innovation, and the challenges of working with data sets.&lt;/p&gt;</description>
        <persons>
          <person id="2460">Hollie Lubbock</person>
        </persons>
        <links>
          <link href="http://www.slideshare.net/HollieLubbock/ui-design-for-open-data-v2-nov-2014 ">Talk slides</link>
        </links>
      </event>
      <event id="3204">
        <start>14:00</start>
        <duration>00:30</duration>
        <room>AW1.126</room>
        <slug>session_7</slug>
        <title>The challenges of open mobile design</title>
        <subtitle>productivity vs content consumption &amp; vision vs design by commitee</subtitle>
        <track>Open source design</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Designing in the open has inherent difficulties as the danger of producing a camel always lurks. At the same time the status quo in mobile UI is consumption-oriented. These are the big challenges we face when working on Glacier UI for nemomobile and I believe they are worth talking about.&lt;/p&gt;

&lt;p&gt;This talk starts with a brief introduction on ways to handle the risk of losing the vision and coherence of the design while still fostering participation, and how we are trying to do that on the nemomobile project. Being friendly and accepting proposals and at the same time keeping a grip on the focus of the design, in a project that lives exclusively on contributors' free time: compromises, solutions and ideals. A quick overview of the tools and workflow follows, and the rest of the presentation delves into the specifics of mobile OS interface design and how we try to evolve a mobile UI that enables productivity on a small screen as opposed to mere content consumption, with Glacier UI.&lt;/p&gt;

&lt;p&gt;For more information on nemomobile and Glacier UI visit http://play.qwazix.com/grog/&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2794">Michael Demetriou</person>
        </persons>
        <links>
          <link href="http://play.qwazix.com/grog/">The official design blog of nemomobile</link>
        </links>
      </event>
      <event id="3353">
        <start>14:45</start>
        <duration>00:30</duration>
        <room>AW1.126</room>
        <slug>session_8</slug>
        <title>LibreOffice Design Team</title>
        <subtitle>What do we do, and how you can get involved</subtitle>
        <track>Open source design</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;LibreOffice 4.4 has got many user interface improvements - come and hear what we have done to make it more usable &amp;amp; more beautiful, and how you can speed up the changes by getting involved!&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="317">Jan Holesovsky</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3115">
        <start>15:30</start>
        <duration>00:30</duration>
        <room>AW1.126</room>
        <slug>session_6</slug>
        <title>Every pixel hurts</title>
        <subtitle>A quest for open UX design</subtitle>
        <track>Open source design</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Design is still a pretty closed process, so I started exploring ways of opening the design process, just as the coding process has been fully opened through collaboration tools, community building, pair acceptance and sharing knowledge. The design community does not have a strong collaboration history. But, since the appearance of the latest UX practices, there is an opportunity to fully open up the process, as UX is based on research and more graphic designers are moving into the UX field.&lt;/p&gt;

&lt;p&gt;We already know there is a lack of UX practice in FOSS projects, so this talk is a further exploration on why such a gap exists, and a collection of ideas and tools that could (hopefully) empower both sides to put a bridge over it.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;I will give an overview of some problems around implementing UX design on FOSS projects and a suggested roadmap for doing so.&lt;/p&gt;

&lt;p&gt;I'll also tell my short but valuable experience contributing UX to Diaspora, the drawbacks and lessons learned in this process.&lt;/p&gt;

&lt;p&gt;Last, I'm making a call for designers to join a broader community, I'm trying to build an ecosystem for open source UX, to foster designers, coders, and interested people all over the world, build tools for opening the design process and connect projects with ux teams worldwide.&lt;/p&gt;</description>
        <persons>
          <person id="2756">Pablo Cúbico</person>
        </persons>
        <links>
          <link href="http://vispress.com/fosdem2015">Presentation slides</link>
          <link href="http://diaspora-site.vispress.com/">Ongoing work for Diaspora Foundation site.</link>
        </links>
      </event>
      <event id="3396">
        <start>16:15</start>
        <duration>00:30</duration>
        <room>AW1.126</room>
        <slug>closing</slug>
        <title>Closing</title>
        <subtitle/>
        <track>Open source design</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Closing remarks for the Open Source Design devroom&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2363">Bernard Tyers</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="UA2.114 (Baudoux)">
      <event id="3451">
        <start>09:00</start>
        <duration>00:15</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>mysql_welcome</slug>
        <title>Welcome to MySQL &amp; Friends Devroom</title>
        <subtitle/>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Welcome to the MySQL &amp;amp; Friends Devroom&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="580">Frédéric Descamps</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3293">
        <start>09:15</start>
        <duration>00:20</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>proxysql</slug>
        <title>ProxySQL : High Availability and High Performance Proxy for MySQL</title>
        <subtitle/>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;ProxySQL is a new proxy (currently under development) that aims to become the first open source proxy in the MySQL ecosystem able to provide HA and high performance with no changes in the application, using several built-in features and integration with clustering software.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;ProxySQL is a new proxy (currently under development) that aims to become the first open source proxy in the MySQL ecosystem able to provide HA and high performance with no changes in the application, using several built-in features and integration with clustering software.
Features under development are:
- read/write split ;
- queries caching ;
- queries filtering and rewrite ;
- logging ;
- transparent reconnect ;
- connection pooling ;
- built-in key/value storage ;
- integration with clustering solution like MHA for planned and/or automatic failover;
- support for master-slave setups (MySQL replication) or multi-masters (NDB or Galera) .&lt;/p&gt;</description>
        <persons>
          <person id="1992">René Cannaò</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3247">
        <start>09:40</start>
        <duration>00:20</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>web_mapping_mysql</slug>
        <title>Web mapping with MySQL</title>
        <subtitle>An introduction to MySQL GIS</subtitle>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Web maps are everywhere these days, and there are a lot of frameworks
that can display a map. But you still have to provide the data
yourself. This talk teaches you how to use MySQL with its GIS
functions in the database back end for your maps.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;MySQL GIS is getting a boost in 5.7 with InnoDB R-trees, new GIS
functions and more accurate results. This talk presents the new
functionality by leading the audience through a step by step guide to
making a simple web map service.&lt;/p&gt;

&lt;p&gt;The target audience is MySQL users that want to learn the basics of
how to display their data in a map. Users that already know MySQL GIS
will learn about the new features in 5.7.&lt;/p&gt;</description>
        <persons>
          <person id="2520">Norvald H. Ryeng</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3249">
        <start>10:05</start>
        <duration>00:20</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>mysql_gtid</slug>
        <title>Using MySQL Global Transaction IDs in Production</title>
        <subtitle/>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;MySQL 5.6 introduced Global Transaction IDs to make the reconfiguration of replication straightforward. The key benefit is that you can instantly and reliably change your replication topology if a node goes down or if the current topology no longer fits your needs. But of course operating a GTID-based cluster brings new challenges: old habits no longer work, tools have changed, and new issues have appeared.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;MySQL 5.6 introduced Global Transaction IDs to make the reconfiguration of replication straightforward. The key benefit is that you can instantly and reliably change your replication topology if a node goes down or if the current topology no longer fits your needs. But of course operating a GTID-based cluster brings new challenges: old habits no longer work, tools have changed, and new issues have appeared.&lt;/p&gt;

&lt;p&gt;In this session, you will learn about using GTIDs in production, including:
- How to execute the daily DBA tasks related to GTID-based replication, such as monitoring replication status or recovering from replication errors
- The new options for high availability and the tools that can help you
- What can go wrong when using GTIDs&lt;/p&gt;</description>
        <persons>
          <person id="1970">Stephane Combaudon</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3268">
        <start>10:30</start>
        <duration>00:20</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>pseudo_gtid</slug>
        <title>Pseudo GTID and easy replication management</title>
        <subtitle/>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Pseudo GTID and easy replication management&lt;/p&gt;

&lt;p&gt;This session introduces a technique called “Pseudo GTID” which allows easy refactoring of replication topologies, and makes balanced, deeply nested topologies achievable, safe and productive.&lt;/p&gt;

&lt;p&gt;Managing large replication topologies introduces difficult questions: do you place all your slaves directly under the master? Do you setup intermediate masters thus creating deep replication trees? How do you synchronize sibling slaves when their master dies? How do you recover replication of a slave if its intermediate master is gone?&lt;/p&gt;

&lt;p&gt;MySQL’s Global Transaction ID (GTID) comes to solve the above. However GTID comes with its own limitations and not always or not easily applicable.&lt;/p&gt;

&lt;p&gt;Pseudo GTID is a non intrusive solution that utilizes standard replication, and turns your existing replication topology into a GTID-like topology, allowing you to repoint slaves however you like.&lt;/p&gt;

&lt;p&gt;We will quickly discuss the problems incurred by standard binary log file &amp;amp; position setup, and the limitations of GTID, Pseudo-GTID injection. We will present the algorithm and implementation for utilizing Pseudo GTID to freely repoint slaves.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2443">Shlomi Noach</person>
        </persons>
        <links>
          <link href="http://code.openark.org/blog/mysql/refactoring-replication-topology-with-pseudo-gtid">More about Pseudo GTID</link>
          <link href="https://github.com/outbrain/orchestrator">orchestrator</link>
        </links>
      </event>
      <event id="3219">
        <start>10:55</start>
        <duration>00:20</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>mysql_group_replication</slug>
        <title>Zooming in on the New MySQL Group Replication Plugin</title>
        <subtitle/>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;MySQL Group Replication is a recent MySQL plugin that brings together
group communication techniques and database replication, providing
both a high availability and a multi-master update everywhere replication
solution.&lt;/p&gt;

&lt;p&gt;At its core is a set of group communication primitives that act as the
building blocks to create reliable, consistent and dependable messaging
between the servers in the group. This allows the set of MySQL servers
to coordinate themselves and act as a consistent and replicated state
machine - in which transactions commit in the same order on every
server. As a consequence, the group itself is fault-tolerant, and so
is the service provided by the group - the MySQL database service.&lt;/p&gt;

&lt;p&gt;In addition to HA, the plugin provides multi-master update everywhere
with row-level conflict detection. This builds on the fact that the
servers in the group have to agree on how to progress the replicated
state machine and so also check for conflicts.&lt;/p&gt;

&lt;p&gt;Come and learn about the technical details of the exciting and popular
MySQL Group Replication plugin and discuss how this fits in the overall
picture of MySQL HA solutions.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;MySQL Group Replication is a recent MySQL plugin that brings together
group communication techniques and database replication, providing
both a high availability and a multi-master update everywhere replication
solution.&lt;/p&gt;

&lt;p&gt;At its core is a set of group communication primitives that act as the
building blocks to create reliable, consistent and dependable messaging
between the servers in the group. This allows the set of MySQL servers
to coordinate themselves and act as a consistent and replicated state
machine - in which transactions commit in the same order on every
server. As a consequence, the group itself is fault-tolerant, and so
is the service provided by the group - the MySQL database service.&lt;/p&gt;

&lt;p&gt;In addition to HA, the plugin provides multi-master update everywhere
with row-level conflict detection. This builds on the fact that the
servers in the group have to agree on how to progress the replicated
state machine and so also check for conflicts.&lt;/p&gt;

&lt;p&gt;Come and learn about the technical details of the exciting and popular
MySQL Group Replication plugin and discuss how this fits in the overall
picture of MySQL HA solutions.&lt;/p&gt;</description>
        <persons>
          <person id="1347">Luis Soares</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3102">
        <start>11:20</start>
        <duration>00:20</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>docker_and_mysql</slug>
        <title>Docker and MySQL</title>
        <subtitle>Fun and bad practice</subtitle>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;15 minutes?
Be prepared to get a full 45 min. talk into 15 minutes! \o/&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What is Docker (Container Virtualization)&lt;/li&gt;
&lt;li&gt;How to use Docker (new way to think infrastructure)&lt;/li&gt;
&lt;li&gt;How to use Docker with MySQL.&lt;/li&gt;
&lt;li&gt;Run Docker in production?&lt;/li&gt;
&lt;li&gt;Why does Galera &lt;em&gt;not&lt;/em&gt; fit into Docker.&lt;/li&gt;
&lt;li&gt;Why Galera should fit into Docker.&lt;/li&gt;
&lt;li&gt;Making Docker and Galera fit.&lt;/li&gt;
&lt;/ul&gt;
</abstract>
        <description>&lt;p&gt;Do you really expect a full description for a 15 minute talk?&lt;/p&gt;

&lt;p&gt;erkan :)&lt;/p&gt;</description>
        <persons>
          <person id="1995">Erkan Yanar</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3280">
        <start>11:45</start>
        <duration>00:20</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>mysql_auth_plug</slug>
        <title>Understanding &amp; using authentication plugins</title>
        <subtitle/>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In our ecosystem, we have the commercial MySQL Enterprise PAM/Active Directory plugins (which are not the focus of this talk). But we also have the PAM authentication plugin, two versions by Percona and MariaDB - find out what's different and how to use them including connecting against an LDAP service.&lt;/p&gt;

&lt;p&gt;New in MariaDB 10.1 (and to be backported to 5.5, 10.0 too) will be the Kerberos authentication plugin that will also be able to work with MySQL/Percona Server.&lt;/p&gt;

&lt;p&gt;Quickly learn how to integrate PAM and Kerberos plugins into your workflow.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1193">Colin Charles</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2494">
        <start>12:10</start>
        <duration>00:20</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>moving_to_nosql</slug>
        <title>Moving to the NoSQL side: MySQL JSON functions</title>
        <subtitle/>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Data is everywhere. User comments, preferences, online games features, all that small chunks of information which clients need to communicate with its servers use JSON format now. This format can be read into an object using parser built-in in all modern clients. But what about server side? What about information which should be stored for future use? Do you still need to manually parse JSON data to be able to effectively search through? Do you still need to spend time retrieving documents, load parse library and process? Not anymore! In this session I will present set of functions which manipulate with data in JSON format inside MySQL server. These functions search, modify and validate JSON data for you.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;JSON UDFs is a set of UDF functions which perform queries using JSON language. This MySQL Labs project available at http://labs.mysql.com/ Further information about JSON UDF functions exists on author's blog at https://blogs.oracle.com/svetasmirnova/tags/json&lt;/p&gt;

&lt;p&gt;I presented first public version of functions last year. Since than 3 minor and 1 major releases of the functions were provided. I hardly worked on feature requests, sent by the users, implemented 4 new functions, accepted 1 contribution. In this session I will tell about the functions: what do they do, how to install them, will say few words about future plans.&lt;/p&gt;</description>
        <persons>
          <person id="2247">Sveta Smirnova</person>
        </persons>
        <links>
          <link href="https://blogs.oracle.com/svetasmirnova/tags/json">Author's blog</link>
          <link href="http://labs.mysql.com/">MySQL Labs</link>
          <link href="http://www.slideshare.net/SvetaSmirnova/mysql-json-functions">First public version of functions</link>
        </links>
      </event>
      <event id="2779">
        <start>12:35</start>
        <duration>00:20</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>undelete</slug>
        <title>Undelete rows from the binary log</title>
        <subtitle>a hacking session</subtitle>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;After the nice blog post of Scott Noyes, I decided to dig a bit more on the topic of undelete rows
from the binary log.&lt;/p&gt;

&lt;p&gt;This is a more detailed 101 session that explain how to find all events to change and show how to
deal with that using easy python commands.&lt;/p&gt;

&lt;p&gt;We will also see how to un-insert and un-update events.&lt;/p&gt;

&lt;p&gt;See https://github.com/lefred/MyUndelete&lt;/p&gt;

&lt;p&gt;It also covers different version of MySQL, from 5.5 to 5.6 and MariaDB.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="580">Frédéric Descamps</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3250">
        <start>13:00</start>
        <duration>00:20</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>multi_thread_replication</slug>
        <title>Multi-threaded replication in MySQL 5.6 and 5.7</title>
        <subtitle/>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Replication is used everywhere with MySQL. But applying writes in a single thread is often a bottleneck: replicas have a hard time keeping up with the master that can execute writes in parallel. Enter MySQL 5.6 and you can use several threads to apply writes on replicas as long as you have several schemas. MySQL 5.7 goes even further: by introducing a logical clock and by changing the scheduling logic, you can apply writes in parallel in a single schema.&lt;/p&gt;

&lt;p&gt;Come to this session to learn all you need to be comfortable with multi-threaded replication.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Replication is used everywhere with MySQL. But applying writes in a single thread is often a bottleneck: replicas have a hard time keeping up with the master that can execute writes in parallel. Enter MySQL 5.6 and you can use several threads to apply writes on replicas as long as you have several schemas. MySQL 5.7 goes even further: by introducing a logical clock and by changing the scheduling logic, you can apply writes in parallel in a single schema.&lt;/p&gt;

&lt;p&gt;The result is of course a much better replication throughput, but this feature also raises a lot of questions:
- How does it work internally?
- Does it play well with GTIDs?
- How can you monitor replication status?
- How do you recover from a replication error?
- If you want to take a backup from a replica, how can you make sure you will get a consistent snapshot?&lt;/p&gt;

&lt;p&gt;Come to this session to learn all you need to be comfortable with multi-threaded replication.&lt;/p&gt;</description>
        <persons>
          <person id="1970">Stephane Combaudon</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3217">
        <start>13:25</start>
        <duration>00:20</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>new_replication57</slug>
        <title>The New MySQL Replication Features in MySQL 5.7 and Beyond </title>
        <subtitle/>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;MySQL replication is the foundation for both scalability and high
availability for many of the world’s busiest services, in particular,
those that operate at scale on the Web. In fact, some of the largest
and highest profile online applications trust their data to MySQL and
regard MySQL Replication as the key technology to ensure that data is
always available, even in the event of catastrophic disasters.&lt;/p&gt;

&lt;p&gt;MySQL Replication strives to keep on meeting the ever tougher
requirements of online services so that it can be deployed together
with them in symbiotic harmony. In fact, in recent years we have
seen an exponential development in MySQL, in particular in
replication.&lt;/p&gt;

&lt;p&gt;MySQL 5.6 was a major step forward, with fabulous replication
features, but the work continues and MySQL 5.7 is set to be another
ground breaking release.  The next generation of replication features
are scattered over several technical areas, including: better
semi-synchronous replication; enhanced multi-threaded slave
performance; improved monitoring; online configuration changes;
options for fine tuning the replication stream performance; support
for more advanced topologies; developer friendly frameworks and much
more. This is just the tip of the iceberg. In fact, in the lab we
have more exciting news such as the MySQL Group Replication plugin,
a plugin that brings group communication techniques and database
replication together.&lt;/p&gt;

&lt;p&gt;Seize the opportunity to learn about the new MySQL Replication
features' internals, the technical details and the roadmap. Come and
learn what is already there in MySQL 5.7 and what's still in the
making.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;MySQL replication is the foundation for both scalability and high
availability for many of the world’s busiest services, in particular,
those that operate at scale on the Web. In fact, some of the largest
and highest profile online applications trust their data to MySQL and
regard MySQL Replication as the key technology to ensure that data is
always available, even in the event of catastrophic disasters.&lt;/p&gt;

&lt;p&gt;MySQL Replication strives to keep on meeting the ever tougher
requirements of online services so that it can be deployed together
with them in symbiotic harmony. In fact, in recent years we have
seen an exponential development in MySQL, in particular in
replication.&lt;/p&gt;

&lt;p&gt;MySQL 5.6 was a major step forward, with fabulous replication
features, but the work continues and MySQL 5.7 is set to be another
ground breaking release.  The next generation of replication features
are scattered over several technical areas, including: better
semi-synchronous replication; enhanced multi-threaded slave
performance; improved monitoring; online configuration changes;
options for fine tuning the replication stream performance; support
for more advanced topologies; developer friendly frameworks and much
more. This is just the tip of the iceberg. In fact, in the lab we
have more exciting news such as the MySQL Group Replication plugin,
a plugin that brings group communication techniques and database
replication together.&lt;/p&gt;

&lt;p&gt;Seize the opportunity to learn about the new MySQL Replication
features' internals, the technical details and the roadmap. Come and
learn what is already there in MySQL 5.7 and what's still in the
making.&lt;/p&gt;</description>
        <persons>
          <person id="1347">Luis Soares</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2923">
        <start>13:50</start>
        <duration>00:20</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>flexviews</slug>
        <title>Materialized Views for MySQL</title>
        <subtitle>Using Flexviews for MySQL</subtitle>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Materialized Views store the results of a MySQL query in a table.  When data in the database changes, Flexviews materialized views can be updated efficiently using the row change information that has been captured, instead of building the whole view again.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Materialized Views store the results of a MySQL query in a table.  When data in the database changes, Flexviews materialized views can be updated efficiently using the row change information that has been captured, instead of building the whole view again.  The row change information is captured using FlexCDC, a change data capture tool for MySQL.  Since the contents of the view are stored in tables, indexes can be added to the views and they can be accessed in milliseconds instead of potentially minutes or hours to run the SQL statement that underlies the views.&lt;/p&gt;

&lt;p&gt;Flexviews is part of Swanhart-Tools and includes both the change data capture utility, and a small SQL API for creating and maintaining the views.&lt;/p&gt;

&lt;p&gt;This talk will introduce Flexviews, the SQL API and FlexCDC.&lt;/p&gt;</description>
        <persons>
          <person id="1978">Justin Swanhart</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3291">
        <start>14:15</start>
        <duration>00:20</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>mysql_char</slug>
        <title>Character encoding: breaking and unbreaking your data</title>
        <subtitle/>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Character encoding configuration in MySQL has always been a bit confusing. With too many options to set, unclear relationships between them, and the default settings that make MySQL incompatible with most languages, it is a headache to many users, many of whom end up with broken data. This lecture will provide an overview of the character set support in MySQL, guidelines on how to use it correctly, and will demonstrate several methods of detecting and repairing mangled data.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1191">Maciej Dobrzanski</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3034">
        <start>14:40</start>
        <duration>00:20</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>mysql_gdb</slug>
        <title>gdb tips and tricks for MySQL DBAs</title>
        <subtitle>How gdb can help you to solve MySQL problems</subtitle>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;From getting backtraces, SQL statements executed by threads at the moment of crash to changing some of the read only server variables on the fly... Sometimes gdb is your last resort, and few tricks from experts may help.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;I'd like to show and discuss typical use cases of gdb for a production MySQL DBA. Some of them were already discussed in blog posts like the following:&lt;/p&gt;

&lt;p&gt;http://www.percona.com/blog/2012/09/09/obtain-last-executed-statement-from-optimized-core-dump/
http://www.percona.com/blog/2013/11/11/how-to-extract-all-running-queries-including-the-last-executed-statement-from-a-core-file/
http://mysqlbugs.blogspot.com.au/2012/09/how-to-obtain-all-executing-queries.html
http://dom.as/2009/02/15/poor-mans-contention-profiling/
http://dom.as/2010/01/02/read-ahead/
http://dom.as/2009/07/30/evil-replication-management/
http://www.percona.com/blog/2010/03/23/too-many-connections-no-problem/
http://dom.as/2009/12/29/when-bad-things-happen/&lt;/p&gt;

&lt;p&gt;and some are even well known as a separate tools, like pt-pmp. But quick review, real life use cases demonstration and discussion may help attendees to know the limitations, outcomes and benefits of attaching gdb to a (hopefully) live MySQL server as a last resort of solving some problems or getting additional useful information for further troubleshooting before restarting it.&lt;/p&gt;</description>
        <persons>
          <person id="2718">Valerii Kravchuk</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3272">
        <start>15:05</start>
        <duration>00:20</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>benchmark_r_gpplot2</slug>
        <title>Visualizing benchmark data with R and gpplot2</title>
        <subtitle/>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;When I talk or write about benchmarking, a repeated question I get asked is how to make the graphs. For some of those graphs, check the links below.&lt;/p&gt;

&lt;p&gt;https://archive.fosdem.org/2014/schedule/event/lepeterborosrulez/
http://www.percona.com/blog/2014/08/12/benchmarking-exflash-with-sysbench-fileio/&lt;/p&gt;

&lt;p&gt;In this talk, I show how to make those graphs with R and ggplot2, and how to prepare the benchmarking data for that.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2827">Peter Boros</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3274">
        <start>15:30</start>
        <duration>00:20</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>capacity_metrics</slug>
        <title>Capacity metrics in daily MySQL checks</title>
        <subtitle/>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;How to ensure capacity for your MySQL servers? We will quickly walk through the potential issues which can affect database capacity and see how we can detect them on the early stages.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="549">Vlad Fedorkov</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2493">
        <start>15:55</start>
        <duration>00:20</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>pfs_troubleshooting</slug>
        <title>Performance Schema for MySQL Troubleshooting</title>
        <subtitle/>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Performance Schema in version 5.6, released in February, 2013, is really powerful tool which can help DBA to find why every trickiest issue started to occur. Version 5.7 introduces even more instruments and tables. And while all these give you great power, you can stuck choosing which instrument to use. In this session I will start from typical problems description, then guide you how to use Performance Schema to find out what causes the issue, what is the reason for wrong behavior and how information received can help you to solve particular problem.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;With 552 instruments in version 5.6 and 797 in version 5.7 as well as with 52 vs 75 tables Performance Schema is really powerful tool which can help to find source of almost every problem your MySQL Server can run into. But at the same time it becomes not easy to find out which instrumentation and which table can help in each and every case. Traditionally Performance Schema sessions teach about what is in the tables. I will, in contrast, start from the issue, then show which instruments and tables can help to solve it.&lt;/p&gt;</description>
        <persons>
          <person id="2247">Sveta Smirnova</person>
        </persons>
        <links>
          <link href="http://www.slideshare.net/SvetaSmirnova/performance-schema-for-mysql-troubleshooting">Slides from similar seminar in Russia</link>
        </links>
      </event>
      <event id="3235">
        <start>16:20</start>
        <duration>00:20</duration>
        <room>UA2.114 (Baudoux)</room>
        <slug>enomem</slug>
        <title>ENOMEM: Will databases ever stop asking for more memory</title>
        <subtitle/>
        <track>MySQL and friends</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Perennial issues with memory have been plaguing everyone since forever.
Nowhere is this more evident than in the context of databases, whose
memory requirements have exploded with BigData, and also due to rise of
faster low-latency storage media. This talk explores the memory issues
databases face when they scale, MySQL/InnoDB/XtraDB, PostGreSQL, Cassandra,
Redis are mostly considered for this talk.&lt;/p&gt;

&lt;p&gt;In short, this talk, will try to cover all the possible rough edges a database
runs into, in regards with memory at scale. The audience, especially the
database devops, should be able to understand possible memory issues here, and
strategies to either avoid them, or fix them in their applications, or in the
design of their database systems itself.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Perennial issues with memory have been plaguing everyone since forever.
Nowhere is this more evident than in the context of databases, whose
memory requirements have exploded with BigData, and also due to rise of
faster low-latency storage media. This talk explores the memory issues
databases face when they scale, MySQL/InnoDB/XtraDB, PostGreSQL, Cassandra,
Redis are mostly considered for this talk.&lt;/p&gt;

&lt;p&gt;Few areas covered are like:&lt;/p&gt;

&lt;p&gt;a) Sharing and Merging:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* Kernel Same Page Merging (KSM) is one of the memory deduplication methods available today which allows to reduce memory footprint of virtualized instances, especially when some of them  share identical read-only mounts and/or are built from near-identical (CoW) images. 
* Databases should themselves be able to manage this with MADV_MERGEABLE/MADV_UNMERGEABLE.
* Transparent Huge Pages - While this has helped with database buffer pools, the CPU requirement may have been non-trivial here. MADV_NOHUGEPAGE/MADV_HUGEPAGE can be used here by databases to avoid any gotchas.
* Memory ballooning to switch hot and cold database instances during upgrades and migration.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;b) Balancing of memory nodes and NUMA:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* While kernel is increasingly providing enhanced NUMA balancing, it also helps if applications are more NUMA-aware and have predictable allocations and workloads. While some implementations are forcing equal interleaved allocation for better protection against reclaim, with non-optimal thread placement, this can result in non-trival foreign accesses. Partitioned node-local buffer pools  and thread pools, for instance in MySQL can help here.

* With newer and exotic boxes with non-uniform memory access (covered in talks in http://collaborationsummit2014.sched.org/event/43ba89be563fcf17dc3ee8449c26f60a#.U8wrfKZX-DI), it is becoming increasingly important to both take advantange of these and not allow for performance degradation with scale.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;c) Containers and cgroups&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* While using docker or LXC, or running inside chroots from systemd-nspawn, cgroups, memcg in particular can be leveraged to fence the memory bandwidth of each. 
* Slices from systemd
* Migrations and multiple instances
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;d) Memory pressure and rest&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* This is about dirty memory pressure and its impact over I/O, particularly in multi-threaded paths.
* PostgreSQL is one of the affected here.
* Stalls and query latency: Latency from fsync.
* vmsplice and page cache: write without read in append-type logs without O_DIRECT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;e) O_DIRECT idiosyncrasies&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* Does O_DIRECT alleviate issues with dirty memory pressure completely?
* Handling of flushing by applications and room for improvement.
    * InnoDB is specifically considered.
    * Flushing heuristics in XtraDB to avoid LRU stalls.
* Filesystems and AIO 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;g) OOM and Application notifications&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* Can application register with OOM notifier and ramp down their memory usage accordingly?
* Do cgroups help here? 
* Prevention strategies used - thresholds
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;h) Memory overcommit and its implications&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* Assumptions made by databases about memory
* OS_MAP_POPULATE for memory pools and consequences with NUMA balancing
* Malloc failures, avoiding memory starvation and OOM.
* Static (allocated at startup) and dynamic (growing with connections) memory allocations.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;i) Madvise usage&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* Databases which depend on kernel for managing page cache and dirty pages (than with O_DIRECT), can use madvise like:
    # MADV_HWPOISON for testing of memory exceptions in application code.
    # MADV_DONTNEED, MADV_SEQUENTIAL and MADV_WILLNEED to provide hints to readahead path.
    # MADV_DONTDUMP for smaller coredumps (with InnoDB, which otherwise will produe several GB coredumps).
    # MADV_SEQUENTIAL for backup tools. 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;j) Few (Mis)understood sysctls&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* vm.swappiness and OOM
* vm.vfs_cache_pressure
* vm.dirty*
* vm.zone_reclaim_mode 
* vm.overcommit_ratio  and many others
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In short, this talk, will try to cover all the possible rough edges a database runs into, in regards with memory at scale. The audience, especially the database devops, should be able to understand possible memory issues here, and strategies to either avoid them, or fix them in their applications, or in the design of their database systems itself. Some of the issues brought up in the database/kernel interlock at Linux CollabSummit -  http://collaborationsummit2014.sched.org/event/4a8b09eac20eff750fb96b90093050d7#.U8xB-6ZX-DI - will also be discussed, with updates, if any.&lt;/p&gt;

&lt;p&gt;There is no single cookbook for this since it is dependent on various factors like the platform (VM, baremetal or containers), UMA or NUMA systems, for which appropriate methods like cgroups, NUMA balancing, affinities can be used. An important factor to consider here is that memory is not a standalone piece but fits into the jigsaw of CPU and I/O, thus affecting them and be affected by them. Hence, those will be given due consideration while devising solutions, especially ones related to cgroups. Nothing is without side-effects however, so impacts of any measures and related overheads will also be discussed and ways in which they can be circumvented, if any. Finally, memory impact of MySQL on OS and vice-versa will be glossed over.&lt;/p&gt;</description>
        <persons>
          <person id="1274">Raghavendra Prabhu</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="UB2.147">
      <event id="3320">
        <start>11:00</start>
        <duration>01:45</duration>
        <room>UB2.147</room>
        <slug>lpi_3</slug>
        <title>LPI Exam Session 3</title>
        <subtitle/>
        <track>Certification</track>
        <type>certification</type>
        <language/>
        <abstract>&lt;h3&gt;LPI offers discounted certification exams at FOSDEM&lt;/h3&gt;</abstract>
        <description>&lt;p&gt;As in previous years, the Linux Professional Institute (LPI) will offer discounted certification exams to FOSDEM attendees.
LPI offers level 1, level 2 and level 3 certification exams at FOSDEM with an almost &lt;strong&gt;50% discount&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;For further information and instructions see &lt;a href="https://fosdem.org/certification"&gt;https://fosdem.org/certification&lt;/a&gt;.&lt;/p&gt;</description>
        <persons>
          <person id="1083">LPI Team</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3321">
        <start>14:00</start>
        <duration>01:45</duration>
        <room>UB2.147</room>
        <slug>lpi_4</slug>
        <title>LPI Exam Session 4</title>
        <subtitle/>
        <track>Certification</track>
        <type>certification</type>
        <language/>
        <abstract>&lt;h3&gt;LPI offers discounted certification exams at FOSDEM&lt;/h3&gt;</abstract>
        <description>&lt;p&gt;As in previous years, the Linux Professional Institute (LPI) will offer discounted certification exams to FOSDEM attendees.
LPI offers level 1, level 2 and level 3 certification exams at FOSDEM with an almost &lt;strong&gt;50% discount&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;For further information and instructions see &lt;a href="https://fosdem.org/certification"&gt;https://fosdem.org/certification&lt;/a&gt;.&lt;/p&gt;</description>
        <persons>
          <person id="1083">LPI Team</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="UD2.218A">
      <event id="2680">
        <start>09:00</start>
        <duration>00:25</duration>
        <room>UD2.218A</room>
        <slug>http/2_right_now</slug>
        <title>HTTP/2 right now</title>
        <subtitle>How we got here, some basics, what Mozilla does and what's next!</subtitle>
        <track>Mozilla</track>
        <type>devroom</type>
        <language/>
        <abstract></abstract>
        <description>&lt;p&gt;HTTP/2 is the new version of the web's most important and used protocol. Version 2 is due to be out very soon after FOSDEM and I want to inform the audience about what's going on with the protocol, why it matters to most web developers and users and not the last what its status is at the time of FOSDEM.&lt;/p&gt;

&lt;p&gt;Daniel is employed by Mozilla and works in the httpbis group within IETF and works with several HTTP/2 implementations. He's perhaps most known as the maintainer and lead developer of curl and libcurl.&lt;/p&gt;</description>
        <persons>
          <person id="362">Daniel Stenberg</person>
        </persons>
        <links>
          <link href="http://daniel.haxx.se/http2/">HTTP2 explained, Daniel's huge document on http2</link>
        </links>
      </event>
      <event id="3065">
        <start>09:30</start>
        <duration>00:25</duration>
        <room>UD2.218A</room>
        <slug>firefox_os_web_apis</slug>
        <title>Firefox OS web API's</title>
        <subtitle>New cool web apis and their impact</subtitle>
        <track>Mozilla</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Webapi's are key to firefox app developement this talk will go through the new webapi available in release 2.0 and their impact on Firefox OS architecture. We will go deeper in Gecko and Gonk to see how new webapi can be added with new features in the Gonk/Gecko layer.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2435">Loïc Cuguen</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2701">
        <start>10:00</start>
        <duration>00:25</duration>
        <room>UD2.218A</room>
        <slug>using_firefox_to_debug_web_apps_on_any_device</slug>
        <title>Using Firefox to debug web apps on any device</title>
        <subtitle>Introducing the Firefox Developer Tools Adapter</subtitle>
        <track>Mozilla</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Debugging mobile apps in a world of multiple platforms will always be a classic case of "write once, debug everywhere". A monoculture avoids this problem, but brings a boatload of others, so there is really no way around that. Once we come to terms with this fact however, we can start demanding more from the tools that we use to do said debugging. Do we really have to become proficient in a multitude of tools, one for each platform that we intend to deploy on? How often must we context-switch and app-switch in order to get things done?&lt;/p&gt;

&lt;p&gt;The Firefox Developer Tools Adapter presents a unique approach to the aforementioned problem. In this talk we will dive into the design and implementation of the Adapter, explain why it is a valuable addition to the mobile developer's toolchest and discuss how it can be used to solve real-life problems.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2428">Panagiotis Astithas</person>
        </persons>
        <links>
          <link href="https://developer.mozilla.org/en-US/docs/Tools/Firefox_Tools_Adapter">Docs on MDN</link>
          <link href="https://github.com/campd/fxdt-adapters">Source code</link>
        </links>
      </event>
      <event id="2754">
        <start>10:30</start>
        <duration>00:25</duration>
        <room>UD2.218A</room>
        <slug>keeping_secrets_with_javascript</slug>
        <title>Keeping secrets with JavaScript</title>
        <subtitle>An Introduction to the WebCrypto API</subtitle>
        <track>Mozilla</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;With the web slowly maturing as a platform the demand for cryptography in the browser has risen, especially in a post-Snowden era. Many of us have heard about the upcoming Web Cryptography API but at the time of writing there seem to be no good introductions available. We will take a look at the proposed W3C spec and its current state of implementation.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2488">Tim Taubert</person>
        </persons>
        <links>
          <link href="https://www.youtube.com/watch?v=yf4m9LdO1zI">Video</link>
          <link href="https://speakerdeck.com/ttaubert/keeping-secrets-with-javascript-an-introduction-to-the-webcrypto-api">Slides</link>
        </links>
      </event>
      <event id="3061">
        <start>11:00</start>
        <duration>00:25</duration>
        <room>UD2.218A</room>
        <slug>whats_new_in_firefox</slug>
        <title>What's new in Firefox?</title>
        <subtitle/>
        <track>Mozilla</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Let's review together what happened with Firefox in 2014 and where we are headed in 2015.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2729">Florian Quèze</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2736">
        <start>11:30</start>
        <duration>00:25</duration>
        <room>UD2.218A</room>
        <slug>participation_metrics_at_mozilla</slug>
        <title>Participation metrics at Mozilla</title>
        <subtitle>A story of systems and data</subtitle>
        <track>Mozilla</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Community builders need data to measure growth, track volunteer contributions and measure success. Over the past year we have been pioneering the way we gather data about participation in Mozilla by defining contribution types, crafting pathways, building large scale systems, and publishing data. In this talk we will be giving the overview of the efforts so far and the way forward.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2302">Pierros Papadeas</person>
        </persons>
        <links>
          <link href="https://wiki.mozilla.org/Contribute/Systems">Systems and Data Working Group of Mozilla</link>
          <link href="https://wiki.mozilla.org/Baloo">Baloo - participation tracking system</link>
          <link href="http://areweamillionyet.org/">Public dashboard of Mozilla contributors</link>
        </links>
      </event>
      <event id="2679">
        <start>12:00</start>
        <duration>00:25</duration>
        <room>UD2.218A</room>
        <slug>maintaining_growing_technical_community</slug>
        <title>Maintaining &amp; growing a technical community</title>
        <subtitle>Mozilla Developer Network</subtitle>
        <track>Mozilla</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;How do you support a diverse community, acknowledge many different voices and perspectives, be open and inclusive, and still get things done (especially when you can’t force anyone to do anything)? What motivates people to not only start contributing to a project but to continue to contribute? Why on earth would anyone, including developers, do work they are not paid for? In this session, I’ll share what I’ve learned (and keep learning) by working with, in, and for volunteer communities; including how to be more transparent, create opportunity, and broadly share ownership.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The Mozilla Developer Network is an open-source documentation wiki for web developers, which is written by really passionate, smart, and inspiring people. Most are not paid employees of Mozilla. All of them are helping make the web a better place by coding, writing, and reviewing articles.&lt;/p&gt;

&lt;p&gt;How do you support a diverse community, acknowledge many different voices and perspectives, be open and inclusive, and still get things done (especially when you can’t force anyone to do anything)? What motivates people to not only start contributing to a project but to continue to contribute? Why on earth would anyone, including developers, do work they are not paid for? In this session, I’ll share what I’ve learned (and keep learning) by working with, in, and for volunteer communities; including how to be more transparent, create opportunity, and broadly share ownership.&lt;/p&gt;</description>
        <persons>
          <person id="2406">Ali Spivak</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2686">
        <start>12:30</start>
        <duration>00:25</duration>
        <room>UD2.218A</room>
        <slug>reaching_more_users_through_better_accessibility</slug>
        <title>Reaching more users through better accessibility</title>
        <subtitle>Using Firefox OS to test your apps for better accessibility and usability of your mobile web application</subtitle>
        <track>Mozilla</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In this hands-on presentation, Marco will demonstrate how to use the screen reader built into Firefox OS and other tools to help create more usable, more accessible web applications. Such applications have a much better chance of reaching a broader audience. In addition, they will help developers to write more semantic and more maintainable code.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;About 20% of the population world-wide have a disability. Disabilities include blindness or visual impairment, deaf or hard of hearing, people with motor impairments, people with dyslexia, and others. For years, there have been assistive technologies such as screen readers for the blind, magnifiers for visually impaired, subtitles or sign language captionings for videos, switches or other assistive devices for people with motor impairments, and many more to help those 20 % come onto the web and participate just as their non-disabled friends and family members do.&lt;/p&gt;

&lt;p&gt;In addition, the demographic development suggests that by the year 2030, half the population in Europe, the U.S. and Canada will be age 60 and older. Those commonly called "silver surfers" will also benefit from bigger touch targets, better contrast and other usability techniques traditionally associated with accessibility, even when they do not have any disability themselves at all.&lt;/p&gt;

&lt;p&gt;As mobile devices spread throughout the world, and Firefox OS sets new standards in affordability and availability in many countries that did not have access to smartphones before, it is more and more important that web applications offered on those devices are usable by the broadest range of users possible.&lt;/p&gt;

&lt;p&gt;This presentation aims to provide some basic easy checks and testing techniques to help you as a developer of a mobile web application to apply good programming practices so your app can reach more users than you ever thought possible. Marco will show how you can use a Firefox OS device and Firefox itself to do these easy checks and take good techniques home to put to use straight away.&lt;/p&gt;</description>
        <persons>
          <person id="2410">Marco Zehe</person>
        </persons>
        <links>
          <link href="https://wiki.mozilla.org/Accessibility/Mobile/ScreenReader">A brief introduction with videos to the Firefox OS screen reader</link>
        </links>
      </event>
      <event id="3085">
        <start>13:00</start>
        <duration>00:25</duration>
        <room>UD2.218A</room>
        <slug>privacy_features_for_firefox_for_android</slug>
        <title>Privacy features for Firefox for Android</title>
        <subtitle>Supporting privacy on the mobile web with built-in features and add-ons</subtitle>
        <track>Mozilla</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Firefox for Android aims to give users control of their privacy on the mobile web. In addition to many built-in privacy features, Firefox also supports add-ons, which can give users even more privacy options. In this session, I'll talk about different privacy features that we've been adding to the browser, highlight a few privacy add-ons that are available, and demonstrate how easy it is to create new add-ons yourself.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2527">Margaret Leibovic</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3071">
        <start>13:30</start>
        <duration>00:25</duration>
        <room>UD2.218A</room>
        <slug>spidermonkey_garbage_collection_update</slug>
        <title>SpiderMonkey garbage collection update</title>
        <subtitle/>
        <track>Mozilla</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;An overview of the progress we've made in the last two years development on the SpiderMonkey GC implementing generational collection and starting work on compacting.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The rough outline of the talk will be:
  Generational GC&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;movitation: performance
the generational hypothesis
implementation details:
  exact rooting
  heap postbarriers
results
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;  Compacting GC&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;motivation: more free memory
implementation details
  relocation and fixup
  selecting arenas to relocate
results
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Talk will be 20 minutes.&lt;/p&gt;</description>
        <persons>
          <person id="2708">Jon Coppeard</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3110">
        <start>14:00</start>
        <duration>00:25</duration>
        <room>UD2.218A</room>
        <slug>superturbocharging_firefox_os_app_development_with_node_firefox</slug>
        <title>Superturbocharging Firefox OS app development with node-firefox</title>
        <subtitle/>
        <track>Mozilla</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Did you know that every Gecko runtime can be debugged and controlled remotely using the Firefox DevTools remote protocol?&lt;/p&gt;

&lt;p&gt;In this talk we'll look into the architecture of debuggable runtimes, how to speak protocol.js and how we're using it to build a series of node modules that together act like a WebIDE command line counterpart, but might also be incorporated into existing typical web development workflows using tools such as Gulp or Grunt. We'll also talk about the challenges that we've faced when taking this from a hack into a solid product, and some of the most promising features that this work makes possible: faster app development and filling the gaps on the Firefox OS Cordova/PhoneGap plugins.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2754">Soledad Penadés</person>
        </persons>
        <links>
          <link href="https://github.com/mozilla/node-firefox">node-firefox in GitHub</link>
        </links>
      </event>
      <event id="2994">
        <start>14:30</start>
        <duration>00:50</duration>
        <room>UD2.218A</room>
        <slug>the_future_of_javascript</slug>
        <title>The Future of JavaScript</title>
        <subtitle>EcmaScript 6 and even more</subtitle>
        <track>Mozilla</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;EcmaScript 6 aka Harmony, the next version of the JavaScript language, is now feature frozen and the publication is expected around March 2015. Now is a good time to take a closer look at the new version. It brings new powerful features to the language, making it easier and nicer than ever to program with JavaScript. This includes (but isn't limited to) generators, destructuring patterns, function improvements, classes. The best thing is that you don't have to wait to try them. A lot of these new shiny language improvements are already present in Firefox. If we look a bit further down the path, preparation has already started for EcmaScript 7. The next big thing could be SIMD, Typed Objects ...&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2688">Benjamin Bouvier</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3090">
        <start>15:30</start>
        <duration>00:25</duration>
        <room>UD2.218A</room>
        <slug>servo_the_parallel_web_browser_and_you!</slug>
        <title>Servo (the parallel web browser) and YOU!</title>
        <subtitle>A beginner's guide to contributing to Servo</subtitle>
        <track>Mozilla</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Servo is a Mozilla project with a small team and big ambitions! Learn how you can contribute to it using Rust, Python, and JavaScript, and watch a worked example of implementing a missing web technology in the browser of the future.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2172">Josh Matthews</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2806">
        <start>16:00</start>
        <duration>00:25</duration>
        <room>UD2.218A</room>
        <slug>firefox_os_tricorder</slug>
        <title>Firefox OS Tricorder</title>
        <subtitle>Reading device sensor data in JavaScript</subtitle>
        <track>Mozilla</track>
        <type>devroom</type>
        <language/>
        <abstract></abstract>
        <description></description>
        <persons>
          <person id="142">Robert Kaiser</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2714">
        <start>16:30</start>
        <duration>00:25</duration>
        <room>UD2.218A</room>
        <slug>building_open_html5_games_for_firefox_os</slug>
        <title>Building open HTML5 games for Firefox OS</title>
        <subtitle>HTML5 Game Development for the Firefox OS Mobile Platform</subtitle>
        <track>Mozilla</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;HTML5 is the future of mobile gaming because of the uniqueness of the technology - you don't need any plugins to run the games and you can play them on any device with the browser. Firefox OS is an open, mobile operating system built entirely with JavaScript - a perfect platform for HTML5 games. Join my talk if you want to learn how to build HTML5 games quickly and effectively, use the advantages of Firefox OS over the other platforms and promote, monetize and distribute your games in the wild.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2429">Andrzej Mazur</person>
        </persons>
        <links>
          <link href="http://end3r.com/speaking/">My speaking experience</link>
        </links>
      </event>
    </room>
    <room name="K.3.201">
      <event id="3308">
        <start>09:00</start>
        <duration>00:10</duration>
        <room>K.3.201</room>
        <slug>intro</slug>
        <title>Introduction</title>
        <subtitle/>
        <track>Microkernels</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Introduction to Microkernels devroom&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1138">Vasily A. Sartakov</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3297">
        <start>09:10</start>
        <duration>00:50</duration>
        <room>K.3.201</room>
        <slug>sel4</slug>
        <title>seL4: Present and Future</title>
        <subtitle/>
        <track>Microkernels</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;seL4, a member of the L4 family of microkernels, and the world’s highest-assured operating system kernel, has recently joined the FLOSS community. This talk will provide an overview of what seL4 is, what it can and cannot do, and where we see it heading in the future.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;I will start of briefly summarising the concept of a microkernel, and the core principles which characterise the L4 microkernel family. I will then introduce the core concepts of seL4, and what distinguishes it functionally from other L4 kernels.&lt;/p&gt;

&lt;p&gt;What makes seL4 really special is its formal verification. I will explain what this is, and what exactly we have proved about seL4, and discuss what this means in practice, especially as far as security, safety and reliability are concerned. I will also indicate where we are planning to take seL4, i.e. a high-level summary of our on-going research and development projects.&lt;/p&gt;

&lt;p&gt;Having covered the technical aspects, I will discuss the development process of the seL4 ecosystem, both past and present. I will specifically discuss the licensing status of various bits of this ecosystem, and how it is likely to develop. In particular I will indicate suggest the best way for the community to contribute to this ecosystem, and help develop it to the benefit of us all.&lt;/p&gt;

&lt;p&gt;NOTE: Lecture will be provided via Skype&lt;/p&gt;</description>
        <persons>
          <person id="2838">Gernot Heiser</person>
        </persons>
        <links>
          <link href="http://sel4.systems">sel4</link>
        </links>
      </event>
      <event id="3208">
        <start>10:00</start>
        <duration>01:00</duration>
        <room>K.3.201</room>
        <slug>toro</slug>
        <title>A dedicated kernel named TORO</title>
        <subtitle/>
        <track>Microkernels</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In systems with high-grade multiprocessing, we have identified two bottlenecks: in the accessing of the memory bus and in the shared resources. To deal with these issues, we propose a dedicated kernel named TORO that is optimized to run a single multi-threading application. TORO is demonstrating an innovative operating system by integrating at the same ring level both kernel and the user application server. In addition, the accessing to resources (e.g., Filesystem, Networking, Memory) is dedicated to specific processor. Then, only the CPU where is dedicated the resource is allowed to access to the instance
of the resource. As a result of this design, the kernel provides direct access to all resources without any overhead, and therefore maximizes
performance for the overall system. To sum-up the approach, in TORO, the threads of the user application server are distributed evenly on all CPUs and running independently in parallel. The memory model chosen is NUMA without pagination. During the initialization, the memory is divided proportionally for each processor installed on the system. When a thread needs memory, the memory allocator returns a free block of memory depending on which CPU the thread is running. In the same way, TORO can dedicate resources to specific processor, i.e., a FileSystem. This only CPU then can access to
this instance of FileSystem. The scheduler is based on the cooperative threading model, therefore due to this design, TORO can migrate threads
between CPUs and send messages between threads without using any lock instruction.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;I am Matias Vara (http://www-sop.inria.fr/members/Matias.Vara_Larsen/), founder and main developer of TORO (http://sourceforge.net/projects/toro/, http://torokerneleng.blogspot.com/) since 2006. Currently, I am doing a PhD in Computer Science at INRIA, Nice, France.
FOSDEM is a very good place to discuss general purpose operating systems vs. dedicated operative systems. This discussion can be motivated by showing the characteristics of TORO by highlighting the main differences with a general purpose OS. The talk will take around 25 minutes.&lt;/p&gt;</description>
        <persons>
          <person id="2450">Matias  Vara</person>
        </persons>
        <links>
          <link href="http://torokerneleng.blogspot.com">Main site of TORO project</link>
          <link href="http://sourceforge.net/projects/toro/">TORO in sourceforge</link>
          <link href="http://www-sop.inria.fr/members/Matias.Vara_Larsen/">Personal page of Matias Vara</link>
        </links>
      </event>
      <event id="2729">
        <start>11:00</start>
        <duration>00:30</duration>
        <room>K.3.201</room>
        <slug>flk</slug>
        <title>The FLK project</title>
        <subtitle>Security by the language, no MMU, no processes</subtitle>
        <track>Microkernels</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;EIFFEL the language and SCOOP(*) allow the creation of a kernel without neither MMU nor processes but secured.&lt;/p&gt;

&lt;p&gt;The removal of MMU and processes improves the switching time of contexts and minimize the memory cost of concurrency. The kernel provides unlimited concurrency and native synchronisation/acquiring of multiple resources.&lt;/p&gt;

&lt;p&gt;The security is primarily given through EIFFEL's exports at the API level and is enforced by tightly coupling the kernel and the compiler. The low-level unsafe API are available only available to the kernel.&lt;/p&gt;

&lt;p&gt;(*) SCOOP: Simple Concurrent Object-Oriented Programming&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The common state of the art is focused on POSIX implementation: C programming, processes, threads, mutexes, etc... But this has some issues: one stack per thread with strong separation of processes made by the use of MMU.&lt;/p&gt;

&lt;p&gt;By changing the language, this concepts are becoming obsoletes and the issues disappearing. But the security remains and even more is enforceable at an API level.&lt;/p&gt;

&lt;p&gt;SCOOP, the Simple Concurrent Object-Oriented Programming, is expressing the concurrency inside the language (without need of IPC or IDL) by linking (sub)systems to abstract processors.&lt;/p&gt;

&lt;p&gt;Each of the SCOOP abstract processor has its own isolated memory. The FLK (http://flhq.org) implementation ensures the isolation of the memory at the language level. This done, no MMU is no more needed. Yes, the memory is managed by the kernel, but using only one common addressing space, a flat model.&lt;/p&gt;

&lt;p&gt;SCOOP provides the model of synchronizing multiple resources. This synchronisation is native and is made using Rhee's algorithm that can be distributed. Having this avoid any need of mutexes, semaphores.&lt;/p&gt;

&lt;p&gt;Conversely, this model tends to multiply the count of abstract processor in a way that can not be implemented using threads because of their weight. But it allows to change the underlying mechanism. Abstract processors are not executed within a private context/stack but on the current execution context that crosses processors.&lt;/p&gt;

&lt;p&gt;New security behaviours tends to include security at the API level. The coupling of the compiler with the kernel allow to enforce this behaviour at compile time, installation time and (if very paranoiac) at runtime.&lt;/p&gt;</description>
        <persons>
          <person id="1784">José Bollo</person>
        </persons>
        <links>
          <link href="https://docs.eiffel.com/book/solutions/concurrent-eiffel-scoop">Overview of SCOOP</link>
          <link href="https://docs.eiffel.com/">Documentation on eiffel</link>
          <link href="http://netsrv.csc.ncsu.edu/export/modular-algorithm.pdf">Rhee algorithm multiple resource allocation</link>
          <link href="http://http://flhq.org">Site of the project</link>
        </links>
      </event>
      <event id="2876">
        <start>11:30</start>
        <duration>01:00</duration>
        <room>K.3.201</room>
        <slug>hurd</slug>
        <title>Along the GNU Hurd RPC way</title>
        <subtitle>A starting guide to contributing to the GNU Hurd</subtitle>
        <track>Microkernels</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;It is not so obvious to newcomers to the Hurd project how to follow execution path from their application to actual behavior in the Hurd translators. This talk will guide them through the involved RPCs, thus providing a starting guide into the GNU Hurd architecture, and hopefully, to contributing fixes or new features!&lt;/p&gt;</abstract>
        <description>&lt;p&gt;With monolithic kernels, the path from application source code to actual implementation in the kernel is very simple: only the system call layer needs to be understood.  In a multiserver system such as the GNU Hurd, this is not so simple, since one for a start has to understand which server one is actually talking to, and how RPCs work.  Once this is cleared up, it becomes way easier to know where to contribute fixes and features!&lt;/p&gt;

&lt;p&gt;This talk will thus take a few examples of typical application operations (opening and reading a file, opening and working with a socket) and go through the RPC path, to illustrate how translators are involved and where the eventual implementations actually reside.&lt;/p&gt;

&lt;p&gt;It will also be an opportunity to give the latest news about the GNU/Hurd project.&lt;/p&gt;</description>
        <persons>
          <person id="1133">Samuel Thibault</person>
        </persons>
        <links>
          <link href="http://www.gnu.org/software/hurd/">http://www.gnu.org/software/hurd/</link>
          <link href="http://www.debian.org/ports/hurd/">http://www.debian.org/ports/hurd/</link>
        </links>
      </event>
      <event id="3309">
        <start>12:30</start>
        <duration>00:30</duration>
        <room>K.3.201</room>
        <slug>diner</slug>
        <title>Networking (lunch)</title>
        <subtitle/>
        <track>Microkernels</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Networking at Lunch&lt;/p&gt;</abstract>
        <description></description>
        <persons>
        </persons>
        <links>
        </links>
      </event>
      <event id="3022">
        <start>13:00</start>
        <duration>00:45</duration>
        <room>K.3.201</room>
        <slug>deadlock</slug>
        <title>Autopsy of a multiserver deadlock in the HelenOS filesystem layer</title>
        <subtitle/>
        <track>Microkernels</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;A detailed walk through the analysis of a deadlock in the HelenOS filesystem layer involving IPC communication and spread across four server processes. The talk will focus on demonstrating how a problem like this can be root caused from within the same running HelenOS instance that was affected by it, relying solely on its own observability features.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;A detailed walk through the analysis of a deadlock in the HelenOS filesystem layer involving IPC communication and spread across four server processes. The talk will focus on demonstrating how a problem like this can be root caused from within the same running HelenOS instance that was affected by it, relying solely on its own observability features.&lt;/p&gt;</description>
        <persons>
          <person id="604">Jakub Jermář</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3027">
        <start>13:45</start>
        <duration>00:45</duration>
        <room>K.3.201</room>
        <slug>l4re</slug>
        <title>Facing the Reality: What's new in the L4Re Operating System</title>
        <subtitle/>
        <track>Microkernels</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;L4Re is an operating system based on the L4Re microkernel. The development of the last 12 months has been driven by real-world requirements. Noteworthy features are power management capabilities and the ARM virtualization support.&lt;/p&gt;

&lt;p&gt;In the first part of the talk we will give a brief overview of what's new in the L4Re OS followed by an update on the changes and improvements to the virtualization support we made over the last year.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2015">Adam Lackorzynski</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2789">
        <start>14:30</start>
        <duration>00:50</duration>
        <room>K.3.201</room>
        <slug>mm</slug>
        <title>What Could Microkernels Learn from Monolithic Kernels (and Vice Versa)</title>
        <subtitle/>
        <track>Microkernels</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Some developers of both microkernel and monolithic operating systems view the design of their system as absolutely superior to the other design. This black-white thinking and "holy war" attitude, while understandable to a certain degree, makes it hard to to acknowledge that one size does not necessarily fit all. Rather than striving for an unreachable goal of creating the best operating system design for all possible use cases it is vital to understand and reflect the trade-offs of the use cases at hand. This talk focuses on a few features and properties of the current monolithic operating systems that could be an inspiration for the current microkernel operating systems and vice versa. The talk should also initiate a discussion about some "non-goals" of microkernel operating systems that are nevertheless sometimes presented as goals of microkernel operating systems, to the detriment of its own cause.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="605">Martin Děcký</person>
        </persons>
        <links>
          <link href="http://www.helenos.org/">HelenOS web site</link>
          <link href="http://trac.helenos.org/">HelenOS development wiki</link>
        </links>
      </event>
      <event id="2886">
        <start>15:30</start>
        <duration>00:45</duration>
        <room>K.3.201</room>
        <slug>genode</slug>
        <title>Introducing a radically componentized GUI architecture</title>
        <subtitle/>
        <track>Microkernels</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Modern graphical user interfaces must be both extremely versatile and beautiful to be appealing for users. Current GUIs try to fulfil those requirements at the cost of extremely high complexity, which puts the privacy and security of the user at risk. The talk will introduce a new component-based GUI architecture that puts security in the front seat while aiming at highly customizable user experiences.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;GUIs face the challenge to appeal to users with vastly different tastes. Visually, each user seems to have different preferences, which current-generation GUIs try to address with theming engines. But also conceptually, different groups of users prefer different concepts. For example, a window manager might support floating windows, tiled windows, tabbed windows, and virtual desktops. In order to be appealing to a large user base, it has to support as many of those concepts as possible. As another example, modern widget tool kits such as Qt5 try to accommodate all kinds of applications with a huge library of features. The richness of features, however, comes at a price, which is the overwhelming complexity of current-generation GUI systems. Large parts of the GUI are shared among graphical applications including both privacy-sensitive as well as potentially malicious programs. In the presence of malware, the complexity becomes a large attack surface. But how can this be avoided?&lt;/p&gt;

&lt;p&gt;The talk will introduce a new architecture that applies microkernel construction principles to split the GUI into an arrangement of components such that the highly complex elements are stuffed away in sand boxes where they cannot do any harm. The security-critical parts are encapsulated into tiny components that do not even rely on a C runtime. Their ultra-low complexity and rigid interfaces mitigate the chance for attacks. At the same time, the architecture provides large degrees of freedom with respect to the virtual presentation and the window-layout management.&lt;/p&gt;

&lt;p&gt;The key components and their relationship will be explained and demonstrated live during the talk.&lt;/p&gt;</description>
        <persons>
          <person id="607">Norman Feske</person>
        </persons>
        <links>
          <link href="http://genode.org">Genode OS Framework</link>
        </links>
      </event>
      <event id="3509">
        <start>16:15</start>
        <duration>00:20</duration>
        <room>K.3.201</room>
        <slug>ucloud</slug>
        <title>Cloud services on top of uKernel </title>
        <subtitle/>
        <track>Microkernels</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Despite the diversity of microkernel project, most of them are experimental and research. Some of them are positioned as embedded systems, some other as general purpose desktop system. We want to add in this diversity additional project. In contrast with most other, we are interested in network services for clouds. We want to build guest system based on microkernel for providing various network services like cluster file system, key-value store and web server.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;This presentation will describe work-in-progress status of process development cloud services on top of microkernels. We will describe main idea, rationale and motivation, main architecture and early results. The talk will provide description and guidance of porting key-value store Redis on top of Genode, development levedb-based in memory KVS on top of L4Re, deployment and use of network services in virtual environment.&lt;/p&gt;</description>
        <persons>
          <person id="1138">Vasily A. Sartakov</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="K.3.401">
      <event id="3508">
        <start>09:05</start>
        <duration>00:45</duration>
        <room>K.3.401</room>
        <slug>go_at_coreos</slug>
        <title>Go at CoreOS</title>
        <subtitle>This session will discuss using Go to build products that make distributed computing as stress-free as installing a Linux distribution.</subtitle>
        <track>Go</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;At CoreOS, we chose to write everything in Go at a time when Python was the language of choice for Linux distributions. It had been almost 10 years since a new Linux distro was created. With the entrance of the cloud era, moving deeply into distributed computing based on Linux containers and multi-core machines, we needed a language that would allow our developers to iterate rapidly and create self-contained components that were not tangled in a web of software dependencies on the operating system. Go was the clear choice because it would enable us to build applications quickly and produce standalone binaries.&lt;/p&gt;

&lt;p&gt;With thousands of hours of Go experience, this session will dive into the trenches on Go at CoreOS. It will explore four major projects written in Go: etcd, fleet, rocket and flannel. Attendees will learn tips and tricks for using Go for building and shipping products. Learn the ways Go enables CoreOS to build simple tools to solve a large variety of infrastructure automation tasks, and create high performance components for distributed systems.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;This talk will cover some of the major projects written in Go at CoreOS, including etcd, fleet, rocket and flannel.
etcd is a highly-available key value store for shared configuration and service discovery, that can be used as a lock service (e.g. for leader election) or for distributed configuration. etcd uses the Go standard library extensively, and the session will detail how we used Go to make our raft implementation lightweight and easy to navigate.
Fleet is a distributed init system that extends systemd to the cluster level. The session will explore how fleet uses Go to provide both event-driven and reconcilation-based orchestration of units in a cluster.
Rocket is a new container runtime and the first implementation of the appc specification. Developing in Go allowed Rocket to go from concept to functional product in a rapid timeframe.
Finally, flannel is an etcd-backed overlay network fabric for Linux containers. Flannel leverages Go’s ability to seamlessly integrate with C code, to provide maximal performance in critical paths but retain the safety of higher level abstractions and ability to leverage existing Go libraries.&lt;/p&gt;</description>
        <persons>
          <person id="2960">Jonathan Boulle</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3135">
        <start>09:50</start>
        <duration>00:45</duration>
        <room>K.3.401</room>
        <slug>go_web_security_scanner</slug>
        <title>Finding Bad Needles in Worldwide Haystacks</title>
        <subtitle>Experience of using Go for a large-scale web security scanner</subtitle>
        <track>Go</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Over the last year, we have been using Go to improve the accuracy and quality of our web security scanning system that has become part of our Continuous Development pipeline and now checks all Yahoo websites and changes to them.  We would like to present several components of the scanner and share some of our experiences, results, and lessons from using Go for web scanning at a large scale.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Go has caught our attention after the 1.0 release  with the approachable learning curve, clean syntax, good HTTP library and built-in concurrency/syncronization primitives and overall a promise of a good match for our tasks. As a warm-up and initial study, we wrote a dead link scanner to plow through thousands of sites and find a number of "bad needles" (404s) - all while running on a single server.  Encouraged, we proceeded with converting several parts of the security scanning system to Go.&lt;/p&gt;

&lt;p&gt;We started with "webseclab" - set of tests for the scanner and framework to do experiments and proof of concepts/demos. It is similar in spirit to the recently released "firing range", webgoat or DVWA ("Damn Vulnerable Web Application") but thanks to the Go implementation may have special or even unique features.It is extremely easy to fire up (no dependencies and no Tomcat setup or such needed) which allows you to turn any random VM or host into a functional web security "lab". Also, switching between Go's text and html templates, we get "for free" - with just a few lines of extra code - a set of "fixed" tests where the injections are neutralized by proper output escaping which comes especially useful for training and communicating with developers.  The webseclab is optimized for rapid addition of new tests and cases - we have been using it to "resurrect" already fixed issues reported through the BugBounty program and quickly convert HTTP dumps into realistic tests ready to be used for scanner improvement.&lt;/p&gt;

&lt;p&gt;The next stage of the still ongoing conversion was rewrite of the analysis engine.  We named it "contextdetect" as the task of defining the HTML context is crucial for that piece, and here Go has helped us to a break-through.  Gone are painful and fragile layers of regexps and scripting logic that were used to simulate HTML parsing and context detection - but still lead to bouts of either false positives or false negatives.  We use net/html HTML5 parser [1] to define the HTML context where the injection happens and evaluate it accordingly.  We also use Robert Krimen's Javascript parser "otto" [1] to check whether an injection breaks the Javascript (likely bad) or not.  Using real parsers allowed us to reduce the number of annoying false positives close to zero and make the life of the tool's users more pleasant - while still finding the real issues (as continously verified with the webseclab).  We also implemented in Go a web services wrapper that distributes the work to a number of redundant scanning workers and used "go test" for functional smoke test of the scanner.&lt;/p&gt;

&lt;p&gt;In the process of development in our CD environment, we had several challenges with the build process as the standard "go get" approach was off-limits for us and we have a strict requirement to mirror all the 3rd party code used for builds internally.  Currently we are using the Android REPO tool to maintain description of the dependencies as well as specify the GOPATH-compatible workspace - we will discuss our considerations of the involved tradeoffs.&lt;/p&gt;

&lt;p&gt;While not everyone may have to be as obsessed with defending against XSS and other badness as we are, we hope that our experience will be helpful and encouraging for others who need to do large-scale web or network verification, quality assurance, or investigations.  Let's go make the web a better and safer place! :)&lt;/p&gt;

&lt;p&gt;[1] https://godoc.org/golang.org/x/net/html
[2] https://godoc.org/github.com/robertkrimen/otto&lt;/p&gt;</description>
        <persons>
          <person id="2714">Dmitry Savintsev</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2881">
        <start>10:35</start>
        <duration>00:45</duration>
        <room>K.3.401</room>
        <slug>mongo_go</slug>
        <title> Moving MongoDB components to Go</title>
        <subtitle>We love Go and this train is unstoppable!</subtitle>
        <track>Go</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;MongoDB is one of the most popular databases in the world to date and we love Go. As part of MongoDB package comes a set of tools and utilities that allow the user to perform several different tasks on MongoDB like exporting data, important, collecting stats etc. Part of the ecosystem around MongoDB is also MMS(MongoDB Management Service) which allows users to monitor, backup and automate their MongoDB deployments using a centralized SaaS service.
MMS agents are already Go applications and we are also migrating MongoDB tools to Go codebase, among other internal tools.  This is potentially the largest distribution of Go applications to date in an opensource project!&lt;/p&gt;</abstract>
        <description>&lt;p&gt;This talk explains why we’ve undergone such code base change, our expectations and the actual benefits that we are already seeing due to this change:
better code base
better testability
better deployment / multiplatform (goodbye  #IFDEF statements in C++ code base)
better performance
The talk is oriented to people looking to make a similar task of changing their current apps to Go, people looking to understand the pros and cons (mostly pros) of using Go for such set of utilities and agents and for people interested in understanding how to manage a Go code base distribution.&lt;/p&gt;</description>
        <persons>
          <person id="2602">Norberto Leite</person>
        </persons>
        <links>
          <link href="https://github.com/mongodb/mongo-tools">git repository of go mongodb tools</link>
        </links>
      </event>
      <event id="3131">
        <start>11:30</start>
        <duration>00:45</duration>
        <room>K.3.401</room>
        <slug>cockroachdb_go</slug>
        <title>CockroachDB</title>
        <subtitle>Towards an Open-Source Spanner</subtitle>
        <track>Go</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Many NoSQL databases come with a focus on performance, availability and scalability, sacrificing strong consistency guarantees along the way. In effect, this shifts the burden of providing consistency to the application, and often results in complex and error-prone application logic.
Just a few years ago, an intense effort by Google resulted in Spanner - a globally distributed, replicated datastore that puts transactions back where they belong: right into the heart of the database.&lt;/p&gt;

&lt;p&gt;CockroachDB is a grass-roots effort to bring to the table the guarantees of Spanner (and more) in an open source scalable database that is easy to deploy and, despite the name, quite attractive to have around.
In the talk, I'll introduce you to the team behind CockroachDB and the current state of the art, briefly discuss consistency &amp;amp; Spanner and then dive into a tour of what's under the hood.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2766">Tobias Schottdorf</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2790">
        <start>12:15</start>
        <duration>00:45</duration>
        <room>K.3.401</room>
        <slug>http2_go</slug>
        <title>HTTP/2 for Go</title>
        <subtitle>Overview of HTTP/2 and the design of Go's support for it</subtitle>
        <track>Go</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Brad Fitzpatrick gives an overview of HTTP/2 (its design and advantages) and then discusses the design of Go's http2 package.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1877">Brad Fitzpatrick</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3512">
        <start>13:00</start>
        <duration>00:45</duration>
        <room>K.3.401</room>
        <slug>go_modern_enterprise</slug>
        <title>Go and the modern enterprise</title>
        <subtitle/>
        <track>Go</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Successful, tech-related, consumer-oriented companies with "hockey stick" growth -- companies like Twitter, Netflix, Spotify, and SoundCloud -- represent what might be called the "modern enterprise".&lt;/p&gt;

&lt;p&gt;These organizations run microservice architectures which are continuously built and deployed, deeply instrumented, data-driven, and can fundamentally change from day to day. The open-source software stacks they use gain recognition, contributors, and momentum.&lt;/p&gt;

&lt;p&gt;Go has many advantages in this kind of environment, and seems well-posed for becoming its &lt;em&gt;de facto&lt;/em&gt; language. But we're definitely not there yet.&lt;/p&gt;

&lt;p&gt;This talk is an experience report of Go in the "modern enterprise" of SoundCloud, and my opinion of what needs to happen with the language and ecosystem for it to gain real mindshare in that environment.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2975">Peter Bourgon</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2839">
        <start>14:00</start>
        <duration>00:45</duration>
        <room>K.3.401</room>
        <slug>bleve</slug>
        <title>bleve - text indexing for Go</title>
        <subtitle/>
        <track>Go</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Nearly every application today has a search component.  But delivering high quality search results requires a long list of text analysis and indexing techniques.  With the bleve library, we bring advanced text indexing and search to your Go applications.  In this talk we'll examine how the bleve library brings powerful text indexing and search capabilities to Go applications.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;This talk will start with a brief introduction to text search concepts.  We'll discuss the importance of choosing the right analyzer for your text.  Then we'll look at examples that demonstrate how to index your existing data model.  Finally we'll look at how you can integrate advanced features, like result highlighting and faceting, to complete the user experience.&lt;/p&gt;

&lt;p&gt;Introduction to text search concepts  (5 minutes)
Mapping a typical data model for search (10 minutes)
Executing searches including highlighting and faceting (15 minutes)&lt;/p&gt;</description>
        <persons>
          <person id="2251">Marty Schoch</person>
        </persons>
        <links>
          <link href="http://www.blevesearch.com/">Bleve</link>
        </links>
      </event>
      <event id="3513">
        <start>14:45</start>
        <duration>00:45</duration>
        <room>K.3.401</room>
        <slug>state_of_go</slug>
        <title>The State of Go</title>
        <subtitle/>
        <track>Go</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Andrew Gerrand takes a look at the Go project and community and gives an overview of where we're at in February 2015.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1479">Andrew Gerrand</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3461">
        <start>15:30</start>
        <duration>01:30</duration>
        <room>K.3.401</room>
        <slug>go_lightning_talks</slug>
        <title>Go Lightning Talks</title>
        <subtitle>The Go community on Go</subtitle>
        <track>Go</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Members of the Go community give short presentations of on various topics.&lt;/p&gt;

&lt;p&gt;To sign up to give a lightning talk, visit the Go Devroom throughout the day.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1479">Andrew Gerrand</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="K.4.201">
      <event id="3431">
        <start>09:30</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>cache2k</slug>
        <title>Cache2k, Java caching turbo charged</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The development of cache2k has two streams: It is a robust cache implementation and provides features we miss from other products, on the other hand it is a research area to try out new caching algorithms and implementations to achieve the best performing in-memory Java cache that is available today.&lt;/p&gt;

&lt;p&gt;The talk will start with some real-world scenarios and challenges and how the cache can help, making it the pivotal point in an application to manage data resources and provide them on time. The second part of the talk will be about modern and adaptive caching algorithms and why you should not implement yet another "LRU cache" by yourself.&lt;/p&gt;

&lt;p&gt;This talk should encourage to use more caching to speed up applications and, of course, to hack and improve existing caching products. There is still much to achieve!&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2915">Jens Wilke</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3432">
        <start>10:00</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>zero</slug>
        <title>Sustaining the zero assembler port in OpenJDK: An inside perspective of CPU specific issues</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;OpenJDK comes with a zero assembler port called Zero. Back in 2009 when Zero was originally developed by Gary Benson, OpenJDK was available only on x86, x86_64 and SPARK. Despite recent JIT ports, such as the AArch64 and ppc/aix port, Zero still remains relevant for many Linux distributions. For example, at Red Hat we build and use the OpenJDK zero variant on PPC/PPC64 and s390/s390x. What's more it's a useful tool for getting new JIT ports built from source using free software.&lt;/p&gt;

&lt;p&gt;This talk will give a brief summary what Zero is and how it works. It will cover some of the recently discovered issues with sustaining the Zero port, how we try to catch them early and it will explain our experience with pushing
fixes upstream. There will also be examples how this effort benefits the OpenJDK ecosystem as a whole.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2909">Severin Gehwolf</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3433">
        <start>10:30</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>icedtea_web</slug>
        <title>IcedTea-Web goes offline and beyond</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Future of java applets and javaws is dark. Chrome have already cut down NPAPI. Most of the banks  moved from java to javascript for they internet banking. The javaws will suffer a lot by introducing jigsaw modules. What is remaining? The "physical applets" of course! Seriously - the "killing"  feature of applets is that they do not work offline. But similarly to javaws - they can! IcedTea-Web is now removing this boundaries, and what more, it will also allow you to detach applet out from browser - by jnlp shortcut, or by lunching html page by javaws directly. Apart of this, ITW is now  JDK independent and you can run those features on any OpenJDK, even on
Oracle or IBM JDKs.
And except serving you web application comfortably online, ITW allows you to lock this application - even "signed ones"  in sandbox. And of course there is Jogamp project - the awt-less  plugin - How I wish to see it merged upstream!-)
&lt;strong&gt;&lt;em&gt; Long story short, more security and much much more freedom &lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2917">Jiri Vanek</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3434">
        <start>11:00</start>
        <duration>00:50</duration>
        <room>K.4.201</room>
        <slug>life_in_the_trenches</slug>
        <title>Life in the trenches</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;We've been working on OpenJDK for a long time now and we've gained a lot of experience working on the code itself and, perhaps more importantly, working with the Java team inside Oracle.  This talk is about our experiences trying make one of the largest ever external contributions to OpenJDK, the AArch64 port.&lt;/p&gt;

&lt;p&gt;I'll talk about how the OpenJDK contribution process works, and how it doesn't work, and how important it is to gain the trust of people inside Oracle's Java team.  I'll discuss the strange asymmetry of being an external contributor to a project but not being able to know all of what is going on.  I'll try my best to explain the baffling role of Projects and JEPs.  I'll speculate about the future of OpenJDK and how it must change as more people outside Oracle contribute significant slabs of code, and how we must have more external patch reviewers.&lt;/p&gt;

&lt;p&gt;Finally, I'll open up the floor for discussion.  I'm sure we'll have a lot to talk about.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="719">Andrew Haley</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3141">
        <start>12:00</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>invoke_binder</slug>
        <title>InvokeBinder</title>
        <subtitle>Literal Programming for Method Handles</subtitle>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;As one of the earliest adopters of Method Handles, I've had to build many of my own tools. InvokeBinder is one of them, providing a literal (or fluent) API for Method Handles that allows site-forward adaptation, name-based argument list manipulation, and many bonuses usually too complicated to write by hand. I'd like to demonstrate its features and enlist others to help me improve it.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="743">Charles Nutter</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3435">
        <start>12:30</start>
        <duration>00:50</duration>
        <room>K.4.201</room>
        <slug>shenandoah</slug>
        <title>Shenandoah - Project overview</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Garbage Collection pauses make it hard for Java applications to meet quality of service guarantees.  No matter how fast your application processes requests, a 30 second GC pause is going to ruin any guarantees you might want to make.&lt;/p&gt;

&lt;p&gt;Shenandoah is a new GC algorithm designed to address this issue. We take a simple approach that allows us to do more work while your Java program is running so we can substantially reduce the time the JVM is paused.  Our goal is to be able to garbage collect 100gb+ heaps in under 10ms.&lt;/p&gt;

&lt;p&gt;This talk will focus on the current status of the project, the goals we've met so far, and what we are hoping to achieve in the coming year.  We might even share some performance numbers.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="740">Roman Kennke</person>
          <person id="2913">Christine H Flood</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3436">
        <start>13:30</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>trends_java</slug>
        <title>What Three Big Development Trends Mean for Java</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;As with the past few years, we'll start by examining via various statistical benchmarks where Java is today and how it is performing relative to its competition. We'll mine various communities use and discussion of Java to try and determine where Java ranks today versus its historical performance.&lt;/p&gt;

&lt;p&gt;With that foundation set, we'll examine three important developer trends and the opportunities - or threats - they present to Java. From the convenience of cloud to the challenges of application lifecycles to the fatigue of fragmentation, we'll walk through the basics of the choices and challenges developers are facing today with an eye towards their implications for Java.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="229">Steve O’Grady</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3437">
        <start>14:00</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>java_modules</slug>
        <title>Java 9: Make Way for Modules!</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Java 9 will introduce a standard module system to the platform in order to modularize the platform itself, improve performance and security, and simplify the development and maintenance of large applications.  In this session we'll discuss how these changes will impact developers in general and those who work on the JDK in particular.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="218">Mark Reinhold</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3438">
        <start>14:30</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>jcp_state_of_the_union</slug>
        <title>JCP State of the Union &amp; Progress Report</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The Java Community Process (JCP) program has made significant changes over the last several years in order to increase community participation in the development of Java Specification Requests (JSR) and to enable greater transparency for the community into the JSR expert groups. Reforms to the JCP through JCP.Next as well as through the Adopt-a-JSR programs have enabled this involvement from the community that is vital to the success of Java. The free and open source community now have greater opportunities for contributions and feedback . We will discuss the current state of the nation on these programs and ask for feedback and suggestions for greater participation moving forward through the ongoing JCP.Next effort, specifically JSR 364, Broadening JCP Membership and JSR 358, A major revision to the Java Community Process.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1288">Heather VanCura</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3439">
        <start>15:00</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>crowd_testing</slug>
        <title>The Wisdom Of Crowd Testing OpenJDK</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;In the beginning, there were bugs. In order to find them faster, before  a JDK release, the OpenJDK Adoption Group began a quality outreach effort. Initially focused on JDK 8, the effort expanded to cover JDK 7  Updates, JDK 8 Updates and JDK 9 OpenJDK Projects. It now lists dozens of open source projects and communities that participate in testing early access builds of the JDK, report issues they find, and help get them resolved in time.&lt;/p&gt;

&lt;p&gt;In this session, you'll learn what worked, and what didn't, and what you can do to join the OpenJDK crowd testing fun with your own open source project to help us find showstopper bugs before they can bite.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="718">Dalibor Topić</person>
          <person id="2916">Rory O’Donnell</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3440">
        <start>15:30</start>
        <duration>00:25</duration>
        <room>K.4.201</room>
        <slug>adoption_group_qa</slug>
        <title>OpenJDK Adoption Group Q&amp;A</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;There's a ton of stuff going on in OpenJDK, projects, repositories, bug database, experiments. This is a lot of potential fun, but the entrance barrier for newcomers is extremely high, and it's easy to get lost and not enjoy the fun anymore. In order to help people wanting to contribute keep track of this intricate forest of development and find their way out, the Adoption Group was created (http://openjdk.java.net/groups/adoption/).&lt;/p&gt;

&lt;p&gt;This session is an exchange between few of the hackers directly involved with the Adoption Group and the public. We will indeed discuss some of the projects we are currently involved with - like the planned global hack days for jsonp, jigsaw and tools that use jigsaw and http 2.0 with language interoperability - but above all we will answer questions the audience may have in relation to getting involved with OpenJDK, both from a technical perspective and a social one, so that next year you can sit together with us helping even more people to jump on the fun!&lt;/p&gt;

&lt;p&gt;If you need help organising your next hackday, or you are completelylost tying to get started with OpenJDK, this is the session for you!&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="222">Mario Torre</person>
          <person id="274">Martijn Verburg</person>
          <person id="718">Dalibor Topić</person>
          <person id="2051">Daniel Bryant</person>
          <person id="2052">Mani Sarkar</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3441">
        <start>16:00</start>
        <duration>01:00</duration>
        <room>K.4.201</room>
        <slug>governing_board</slug>
        <title>Meet the Governing Board</title>
        <subtitle/>
        <track>Java</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Meet the OpenJDK Governing Board, Q&amp;amp;A session&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="218">Mark Reinhold</person>
          <person id="719">Andrew Haley</person>
          <person id="1345">Georges Saab</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
    <room name="K.4.401">
      <event id="2769">
        <start>10:00</start>
        <duration>00:30</duration>
        <room>K.4.401</room>
        <slug>llvm_lldb_port</slug>
        <title>Porting LLDB to a new Target</title>
        <subtitle/>
        <track>LLVM toolchain</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;At Mentor Embedded/CodeSourcery, we have recently ported LLDB to debug programs
for a very specialized processor. This port required a lot of customization in
LLDB. We introduced a new connection mechanism to the target and handled new
object file and symbols formats.&lt;/p&gt;

&lt;p&gt;In this talk, I will describe our experience of porting LLDB. I will explain
how to make use of the Plugin architecture of LLDB to customize its behaviour.
Finally, I will discuss in details how to write the following plugins.&lt;/p&gt;

&lt;p&gt;i) Process plugin to add a new way to connect to target&lt;/p&gt;

&lt;p&gt;ii) ObjectFile plugin to handle a new object file format&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2505">Hafiz Abid Qadeer</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2780">
        <start>10:40</start>
        <duration>00:30</duration>
        <room>K.4.401</room>
        <slug>llvm_arm</slug>
        <title>A closer look at ARM code quality</title>
        <subtitle/>
        <track>LLVM toolchain</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;A closer look at ARM code quality&lt;/p&gt;

&lt;p&gt;The ARM LLVM backend has been around for many years and generates high quality code, yet there are still standard benchmarks where GCC is generating more efficient code than LLVM.
The goal of this talk is to get a better understanding of why the GCC-generated code for those benchmarks is executing more efficiently and also about finding out what we need to do on the LLVM side to address those code generation deficiencies.
This talk presents current performance numbers for the SPEC CPU benchmark suites on ARM, comparing the performance of LLVM and GCC, with the main focus on the SPEC CPU integer benchmarks.
To dive a little bit deeper, we will also have a closer look at the generated assembly code of selected benchmarks where LLVM is performing worse than GCC and use the results of this performance analysis to point out potential code generation opportunities for LLVM.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2522">Tilmann Scheller</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3042">
        <start>11:20</start>
        <duration>00:30</duration>
        <room>K.4.401</room>
        <slug>llvm_internal_asm</slug>
        <title>Extending the internal assembler</title>
        <subtitle>How to add a new CPU feature</subtitle>
        <track>LLVM toolchain</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Using LLVM on a new CPU or a new platform may require changes to the internal
assembler. A common use case is the support of new instructions for a new CPU.
In this talk I show how to add a complete new CPU feature, using the MIPS Octeon
variant as an example.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;LLVM has an integrated assembler in the MC layer. If a CPU vendor adds new
instructions then it is necessary to extend the instruction description in order
to use the new instructions at least in inline assembly. It would be even better
if these instructions are also considered by the code generation. In this talk I
show how to add a new CPU feature, new instructions and instruction aliases. I
also demonstrate how the new instructions are selected by the code generation.
As example I use the Octeon instructions which I added to the MIPS backend for
the LLVM 3.5 release.&lt;/p&gt;</description>
        <persons>
          <person id="1708">Kai Nacke</person>
        </persons>
        <links>
          <link href="http://www.redstar.de">My homepage</link>
        </links>
      </event>
      <event id="3145">
        <start>12:00</start>
        <duration>00:30</duration>
        <room>K.4.401</room>
        <slug>llvm_movicompile</slug>
        <title>moviCompile: An LLVM based compiler for heterogeneous SIMD code generation</title>
        <subtitle/>
        <track>LLVM toolchain</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Numerous applications in communication and multimedia domains show significant data-level parallelism (DLP). The amount of
DLP varies between applications in the same domain or even within a single application. Most architectures support a single vector-,
SIMD-width which may not be optimal. This may cause performance and energy inefficiency. We propose the use of multiple
(heterogeneous) vector-widths to better serve applications with varying DLP. The SHAVE (Streaming Hybrid Architecture Vector
Engine) VLIW vector processor is an example of such an architecture. SHAVE is a unique VLIW processor
that provides hardware support for native 32-bit (short) and 128-bit (long) vector operations. Vector arithmetic unit (VAU) supports
128-bit vector arithmetic of 8/16/32 − bit integer and 16/32 − bit floating point types. Scalar arithmetic unit (SAU) supports 32-bit
vector arithmetic of 8/16 − bit integer and 16 − bit floating point types.&lt;/p&gt;

&lt;p&gt;The moviCompile compiler is an LLVM based commercial compiler targeting code generation for SHAVE processor family.
The moviCompile compiler is capable of SIMD code generation for 128-bit (long) and 64-bit vector operations. This work focuses
on compiler backend support for 32-bit (short) vector operations. More specifically, this work aims to generate SIMD code for
short vector types (e.g. 4 x i8, 2 x i16, 2 x f16) that can be executed on 32-bit SAU next to the 128/64-bit SIMD code. As a
result, moviCompile is able to generate heterogeneous assembly code consisting of both short and long vector SIMD operations.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2771">Erkan Diken</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3087">
        <start>12:40</start>
        <duration>00:30</duration>
        <room>K.4.401</room>
        <slug>llvm_c2</slug>
        <title>The C2 programming language</title>
        <subtitle>Using Clang not like it's supposed to be used.</subtitle>
        <track>LLVM toolchain</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;C2 is a new programming language that been under development since 2011. It attempts to maintain the spirit of C, while considerable raising development speed. C2 also adds some greate features and tools to developers. This talk will zoom in on 'problems' in C, the solution chosen in C2 and the implementation on top of Clang/LLVM.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;The C programming language has been around for a long time and is one of the main 'open-source' languages that is used today. The C2 project attempts to build on the success of C, while keeping the spirit of C intact. C2 doesn't change the abstraction level (like C++/Java/etc), but it does change the way code is structured . This will greatly accelerates development cycles and at the same time increase run-time speed as well. One major change is the removal of the use of #include's to access code in other files. The C2 language was first introduced at Fosdem '13.&lt;/p&gt;</description>
        <persons>
          <person id="1316">Bas van den Berg</person>
        </persons>
        <links>
          <link href="http://c2lang.org">C2 Website</link>
        </links>
      </event>
      <event id="2768">
        <start>13:20</start>
        <duration>01:00</duration>
        <room>K.4.401</room>
        <slug>llvm_openmandriva</slug>
        <title>OpenMandriva's switch to clang as its default compiler</title>
        <subtitle>OpenMandriva's experiences with switching the default compiler to clang</subtitle>
        <track>LLVM toolchain</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;OpenMandriva Lx has switched its default compiler to clang.&lt;/p&gt;

&lt;p&gt;This talk will be about our experiences with the switch, problems we've run into, and their solutions.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;OpenMandriva Lx has switched its default compiler to clang.&lt;/p&gt;

&lt;p&gt;This talk will be about our experiences with the switch, problems we've run into, and their solutions.&lt;/p&gt;</description>
        <persons>
          <person id="2501">Bernhard Rosenkränzer</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3454">
        <start>14:30</start>
        <duration>00:40</duration>
        <room>K.4.401</room>
        <slug>llvm_aarch64</slug>
        <title>LLVM's AArch64 support - history &amp; status.</title>
        <subtitle/>
        <track>LLVM toolchain</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;AArch64 is ARM's 64-bit architecture.  I'll present a short
history of how the AArch64 support in LLVM was implemented, a
summary of which general AArch64 features are well supported by
LLVM and a summary of which areas need more work.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2926">Kristof Beyls</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3005">
        <start>15:20</start>
        <duration>00:20</duration>
        <room>K.4.401</room>
        <slug>llvm_clone</slug>
        <title>Code clone detection in LLVM compiler infrastructure</title>
        <subtitle>LLVM: built-in scalable code clone detection based on semantic analysis</subtitle>
        <track>LLVM toolchain</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;We have proposed LLVM based method of code clones detection. The method is used as built-in instrument for LLVM. It can analyze and compare source code quality. Semantic mistakes arising during software development process can be detected by the compiler in early stages. As well it can be used for automatic refactoring.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Two code fragments are called clones if they are identical by some similarity function. Code clones detection has number of applications. It can be used for semantic mistakes detection, automatic refactoring, code quality improvements and optimizations. There are several methods for code clones detection. Textual [1] and lexical [2] approaches are not capable to detect all clone types [3]. The Algorithms based on abstract syntax tree [4] and metrics [5] have low accuracy. The algorithms based on program dependence graph (PDG) [6] allow reaching high accuracy. But these algorithms have large computational complexity, which makes them unusable for real world projects analysis.
This paper describes scalable and accurate method of code clones detection, which allow analyze million lines of source code (written in C/C++). As well it describes architecture of the tool based on this method. The tool has two basic parts. The first part is designed as LLVM pass [7] and responsible for PDGs generation. The second part designed as LLVM tool [7], which analyzes PDGs to detect clones.
The method based on PDG and has some extra features, which makes it capable for large scale projects analysis. Dependence graphs are constructed at compile-time based on intermediate representation (bitcode) of LLVM [7] (first part). This approach has number of advantages compared with analogical methods [8]. Source code parses only once (during compilation). No need for extra analysis of dependencies between compilation modules. When all graphs are generated second part of tool split them to subgraphs. Then clone detection algorithm runs for pair of these subgraphs. Therefore it is important to split graphs so that every possible clone was located inside one subgraph. Existed methods split PDG to weakly connected components. Some of them split to subgraphs, which are intersected with each other in limited number of vertices [9]. Two algorithms were designed for graphs’ partitioning. Theses improve the number of detected clones. The first method divides PDG to relatively equal pieces. Second one splits PDG to subgraphs, where corresponding source code has sequential order. &lt;br/&gt;
 Scalability was achieved by composition of two types of algorithms. The first type of algorithms tries to prove if two graphs do not have enough large isomorphic subgraphs. These algorithms have liner complexity. Up to 80% of PDGs are processed by them [9]. Other 20% are analyzed with approximate algorithms of maximal isomorphic subgraphs detection. They have high accuracy and computational complexity.
Target machine of testing was Intel Core i3 CPU 540 with 8 GB RAM. Mozilla Firefox (3.8 million lines of С/С++ code) – was analyzed in 8h, detected 98 clones, 7 of them were false positive (manual analysis). LLVM+CLANG (1.3 million lines of С/С++ code) – was analyzed in 6h, detected 51 clones, 2 of them were false. OpenSSL (280 000 lines of С/С++ code) – was analyzed in ~200 second, 107 clones are detected.&lt;/p&gt;

&lt;p&gt;References
1.Ducasse S. [at al.] A language independent approach for detecting duplicated code // Software Maintenance. –  1999. –  109– 118p.
2.Kamiya T. [at al.] CCFinder : A multilinguistic token-based code clone detection system for large scale source code // Software Engineering. –  2002. –  654–670p.
3.Chanchal K. [at al.] Comparison and evaluation of code clone detection techniques and tools: A qualitative approach // Science of Computer Programming.  –  2009.  V. 74 . –  470–  495p.
4.Jiang L.  [at al.] DECKARD : Scalable and accurate tree-based detection of code clones // Software Engineering. –  2007. –  96-105p.
5.Mayrand J. [at al.] Experiment on the automatic detection of function clones in a software system using metrics // Software Maintenance. –  1996. –  244– 253p.
6.Komondoor R. [at al.] Using slicing to identify duplication in source code // 8th International Symposium on Static Analysis. –  2001. –  40–56p.
7.www.llvm.org
8.M. Gabel, L. Jiang, Z. Su, Scalable detection of semantic clones, in: Proceedings of the 30th International Conference on Software Engineering, ICSE 2008,2008,pp.321–330
9.Baker B. [at al.] On finding duplication and near-duplication in large software systems // Reverse Engineering. – 1995. – 86–95p.&lt;/p&gt;</description>
        <persons>
          <person id="2677">Sevak Sargsyan</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2880">
        <start>15:50</start>
        <duration>01:00</duration>
        <room>K.4.401</room>
        <slug>llvm_pnacl</slug>
        <title>LLVM on the Web</title>
        <subtitle>Using Portable Native Client to run Clang/LLVM in the Browser</subtitle>
        <track>LLVM toolchain</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Thanks to its featureful, portable, and modern codebase, Clang/LLVM is rapidly becoming the toolchain of choice for developers worldwide. Recently, its portability has allowed Clang/LLVM to be ported to run inside the Chrome web browser, by way of another LLVM derived technology called Portable Native Client. Working in tandem with several other browser based development tools, the path has been opened to full in-browser software development. This talk explores the unique challenges of porting Clang/LLVM to the browser.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Native Client (NaCl) is an open-source technology that allows native machine code to run securely sandboxed in the browser. Two layers of sandboxing, a static verification inner sandbox combined with Chrome’s outer process sandbox, ensure users can safely run untrusted applications. Portable Native Client builds on this foundation by providing a portable LLVM IR derived wire format which is seamlessly compiled and run on the fly. Support for venerable, cornerstone POSIX APIs—files, processes, sockets, terminal I/O— is then built on top of an I/O layer called PPAPI with security limitations that mirror the constraints of Javascript.&lt;/p&gt;

&lt;p&gt;Come learn about: porting Clang/LLVM to Native Client, bridging the gap between POSIX and the Web, measuring performance, and connecting Clang/LLVM with other FOSS tools in our in-browser development environment, including editors, interpreters, and build tools. Watch a demonstration of in-browser C/C++ development to discover how the Web can dramatically increase the reach and impact of the LLVM project by frictionlessly putting its tools in the hands of developers and users everywhere.&lt;/p&gt;</description>
        <persons>
          <person id="2253">Brad Nelson</person>
        </persons>
        <links>
          <link href="http://gonacl.com/">NaCl Info</link>
          <link href="https://developer.chrome.com/native-client/io2014">Talk focused on GCC based tools</link>
        </links>
      </event>
    </room>
    <room name="K.4.601">
      <event id="3515">
        <start>11:00</start>
        <duration>00:50</duration>
        <room>K.4.601</room>
        <slug>d3d9_wine</slug>
        <title>Wine Development Updates, Performance and the D3D9 State Tracker</title>
        <subtitle/>
        <track>Graphics</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Wine has seen gradual improvements in its support for games and game performance over the year. This talk gives an overview over the past changes, upcoming work as well as the opportunities and problems of the Direct3D9 implementation in Mesa.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="1284">Stefan Dösinger</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3478">
        <start>12:00</start>
        <duration>00:50</duration>
        <room>K.4.601</room>
        <slug>kms_atomic</slug>
        <title>Atomic Mode-Setting</title>
        <subtitle>What it is and how to convert your driver</subtitle>
        <track>Graphics</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Atomic mode-setting has been discussed and designed for literally years. Now it's finally there. Most of the prerequisites have been merged into the mainline kernel. The first drivers are being converted and the final versions of the user-space IOCTL are being drafted. With it come all sorts of new, exciting features. But there are also confusing aspects to it.&lt;/p&gt;

&lt;p&gt;This talk will give a brief history of how kernel mode-setting (KMS) evolved, explain some of the shortcomings of the current KMS API and how atomic mode-setting will make everything better.&lt;/p&gt;

&lt;p&gt;The focus of the talk will be on how to convert existing kernel drivers to support atomic mode-setting based on lessons learned from going through the conversion of the Tegra DRM driver.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2954">Thierry Reding</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3315">
        <start>13:00</start>
        <duration>00:50</duration>
        <room>K.4.601</room>
        <slug>d3d9</slug>
        <title>Native D3D9 on Mesa</title>
        <subtitle>Gallium Nine : the status</subtitle>
        <track>Graphics</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;While OpenGL can fit D3D9 translation, native support has several advantages.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;After explaining several of the reasons a native D3D9 support in Mesa is desirable,
and doing some comparisons with wine conversion to OpenGL,
we'll focus on the status on Gallium Nine today :&lt;/p&gt;

&lt;p&gt;What has been done ? What works ? What is remaining to be done ? What is the future of Gallium Nine ?&lt;/p&gt;</description>
        <persons>
          <person id="2120">Axel Davy</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="2903">
        <start>14:00</start>
        <duration>00:50</duration>
        <room>K.4.601</room>
        <slug>tegra</slug>
        <title>Supporting Nouveau on the Tegra K1 System-on-chip</title>
        <subtitle/>
        <track>Graphics</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;Although Tegra K1 uses the same Kepler architecture as NVIDIA desktop cards that Nouveau already supports, there are other challenges that need to be addressed before Nouveau can drive K1's graphic acceleration: the fact that the GPU does not reside on the PCI bus requires architectural changes in the Nouveau core. The absence of dedicated GPU memory directly interferes with the way Nouveau is used to do memory management and leads to potentially sub-optimal behavior. Also, in a system where all devices share the same system memory, PRIME support is mandatory to perform any useful work and the relevance of a driver-agnostic memory allocator becomes perceptible.&lt;/p&gt;

&lt;p&gt;This talk will discuss these challenges, and in particular the consequences of using a unified memory architecture, in the hope of triggering discussions that will help improving the general support of GPU architectures for new mobile platforms.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="2618">Alexandre Courbot</person>
        </persons>
        <links>
          <link href="https://www.youtube.com/watch?v=-De1poBzx4Y">Xwayland and ioquake3 running on Tegra K1 with Nouveau</link>
        </links>
      </event>
      <event id="2755">
        <start>15:00</start>
        <duration>00:50</duration>
        <room>K.4.601</room>
        <slug>libinput</slug>
        <title>Replacing Xorg input-drivers with libinput</title>
        <subtitle/>
        <track>Graphics</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;This presentation will discuss the plans to move Xorg to use libinput too through an input driver called xf86-input-libinput, as well as the status of this move. xf86-input-libinput is scheduled to be the default Xorg input driver for Fedora 22.&lt;/p&gt;</abstract>
        <description>&lt;p&gt;Currently xorg uses a 1 driver per input device model, this makes it impossible to do things like middle button scrolling on the trackpoint on laptops where the trackpoint buttons are softbuttons on the touchpad. Besides this the xf86-input-synaptics driver was never really designed for multi-touch touchpads and this causes various issues.&lt;/p&gt;

&lt;p&gt;For Wayland we've been working on a new improved input stack, which is to be shared by all compositors and lives inside libinput. This talk is about switching the xf86-input-* part of the Xorg input stack over to libinput by using a wrapper called xf86-input-libinput.&lt;/p&gt;

&lt;p&gt;This talk will focus on the process and status of making this switch, can we make the switch without loosing any features, what updates are needed to the control-panel-applets of various desktop-environments to work with this new stack ?&lt;/p&gt;</description>
        <persons>
          <person id="80">Hans de Goede</person>
        </persons>
        <links>
        </links>
      </event>
      <event id="3460">
        <start>16:00</start>
        <duration>00:50</duration>
        <room>K.4.601</room>
        <slug>tamil</slug>
        <title>The Tamil Driver</title>
        <subtitle>Early hacking on the Mali T-series GPUs.</subtitle>
        <track>Graphics</track>
        <type>devroom</type>
        <language/>
        <abstract>&lt;p&gt;The Tamil driver is to the Mali T series GPUs what the lima driver is for the older Mali M200/400/450 GPUs.&lt;/p&gt;

&lt;p&gt;Libv did the preliminary command stream REing work in September 2013, by creating a command stream tracer (capable of capture and replay) and by exposing the binary shader compiler. Over the 2014 end of year period, he then spent some time decyphering various renders, and he will hopefully be showing off the first few native renders at FOSDEM.&lt;/p&gt;</abstract>
        <description></description>
        <persons>
          <person id="577">Luc Verhaegen</person>
        </persons>
        <links>
        </links>
      </event>
    </room>
  </day>
</schedule>
